{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Alex_combined new4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lhqfKMMj3P0E"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashutosh96/LearnCompressibleDNN/blob/master/Alex_combined_new4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSfX6Wa68OiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # ! pip uninstall -y tensorflow\n",
        "# # ! pip uninstall -y tf-nightly\n",
        "# # ! pip install -q -U tf-nightly-gpu\n",
        "# # ! pip install --pre \"tensorflow==1.15.*\"\n",
        "# # ! pip install -q tensorflow-model-optimization\n",
        "\n",
        "# # Execute this if running data visualization parts of code\n",
        "# ! pip install scipy==1.1.0\n",
        "# ! pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12JhuhyXb48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7fb1fe15-442d-4166-adb8-a8f7e10ac7e6"
      },
      "source": [
        "# To execute notebook, run this block and import block, and jump directly to \n",
        "# Implement AlexNet section. Execute training, pruning and quantization blocks \n",
        "# can be skipped if not needed for the experiment. Rest of the blocks should be \n",
        "# executed in sequence.\n",
        "\n",
        "# Revision history:\n",
        "# 4. Cleaner code(automated different layers training in L1BP)\n",
        "# 3. Ensemble experiments added. All layers except first 3 layers trained from random initialization.\n",
        "# 2. L1BP model trained starting from last layer to first. \n",
        "# 1. Full AlexNet-Cifar10 implementation, L1BP trained from first to last layer\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLT3bnt-O1md",
        "colab_type": "text"
      },
      "source": [
        "# 0. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUbzmzs-675",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "384f1e29-b8ac-4468-b7fb-a2a957700130"
      },
      "source": [
        "\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import layers\n",
        "from scipy.sparse import csr_matrix\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from tensorflow.contrib.model_pruning.python import pruning\n",
        "import pickle\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from tqdm import tnrange\n",
        "from time import sleep\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.ops.gradients_impl import _hessian_vector_product as HessVecProd\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H95jWRW8Oij",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 1. MNIST Dataset\n",
        "In the first part of the assignment, we use the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. There are 70,000 images, and each image has 784 features. This is because each image is 28×28=784 pixels, and each feature simply represents one pixel's intensity, from 0 (white) to 255 (black). The following figure shows a few images from the MNIST dataset to give you a feel for the complexity of the classification task.\n",
        "\n",
        "<img src=\"https://github.com/ashutosh96/LearnCompressibleDNN/blob/master/figs/1-mnist.png?raw=1\" style=\"width: 300px;\"/>\n",
        "\n",
        "To begin the assignment, first, use `mnist_data.read_data_sets` and download images and labels. It return two lists, called `mnist.test` with 10K images+labels, and `mnist.train` with 60K images+labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x596eEx28Oil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "36b341cb-2f67-49f4-abe0-daa5fe33aa8b"
      },
      "source": [
        "# TODO: Replace <FILL IN> with appropriate code\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
        "\n",
        "mnist = mnist_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "mnist.train.num_examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-c236175adf19>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG_7W-do8OjJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 2. Train a multi-layer network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d1-0jvp8OjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_5l(X,l_sizes):\n",
        "    XX = tf.reshape(X,[-1,784])\n",
        "\n",
        "    w = []\n",
        "    b = []\n",
        "    l = [XX]\n",
        "    for i in range(len(l_sizes)-2):\n",
        "        with tf.variable_scope('Layer_'+str(i+1)) as scope:\n",
        "            w.append(tf.Variable(tf.random_uniform(shape=[l_sizes[i], \n",
        "            l_sizes[i+1]], minval=-0.2, maxval=0.2, dtype=tf.float32,name=(\"W\"+str(i+1)))))\n",
        "            b.append(tf.Variable(tf.ones([l_sizes[i+1]])*0.1))\n",
        "            l.append(tf.nn.relu(tf.matmul(l[-1], pruning.apply_mask(w[-1],scope)) + b[-1],name=scope.name))\n",
        "    i+=1\n",
        "    with tf.variable_scope('Layer_'+str(i+1)) as scope:\n",
        "        w.append(tf.Variable(tf.random_uniform(shape=[l_sizes[i], \n",
        "        l_sizes[i+1]], minval=-0.2, maxval=0.2, dtype=tf.float32,name=(\"W\"+str(i+1)))))\n",
        "        b.append(tf.Variable(tf.ones([l_sizes[i+1]])*0.1))\n",
        "        Y_hat = tf.matmul(l[-1], pruning.apply_mask(w[-1],scope)) + b[-1]\n",
        "        # store identity op with name so it can be recovered from meta save\n",
        "        model_output =  tf.identity(Y_hat, name=\"model_output\") \n",
        "\n",
        "    l.append(Y_hat)\n",
        "    return l "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSwLUS_T8OjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9806d75f-80c2-4c88-ccb2-024f5a4c6d9f"
      },
      "source": [
        "# m_shapes = [[784,200,100,60,30,10],\n",
        "#             [784,200,100,70,40,10],\n",
        "#             [784,200,130,80,50,10],\n",
        "#             [784,200,150,90,60,10],\n",
        "#             [784,250,180,120,60,10]]\n",
        "m_shapes = [[784,200,100,60,30,10],\n",
        "            [784,200,100,70,40,10],\n",
        "            [784,200,130,80,50,10],\n",
        "            [784,200,150,90,60,10],\n",
        "            [784,250,150,100,50,10]]            \n",
        "save_names = [('5L2_mnist_'+str(i)+'.ckpt') for i in range(len(m_shapes))]\n",
        "file_path = 'drive/My Drive/Colab Notebooks Old/ensemble_exp/'\n",
        "\n",
        "for i in range(len(m_shapes)):\n",
        "    reset_graph()\n",
        "    X = tf.placeholder(tf.float32, [None, 784],name='X')\n",
        "    model = model_5l(X,m_shapes[i])\n",
        "    Y = tf.placeholder(tf.float32, [None, 10],name='Y')\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # remove variable learning rate!!!??\n",
        "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model[-1])\n",
        "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "    # beta = 0.01\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_step = optimizer.minimize(cross_entropy)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    lr_min = 0.0001\n",
        "    lr_max = 0.005\n",
        "    decay_speed = 2000\n",
        "    n_epochs = 2000\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for epoch in range(n_epochs):\n",
        "            # batch_xs, batch_ys = mnist.train.next_batch(200)\n",
        "            batch_xs = mnist.train.images\n",
        "            batch_ys = mnist.train.labels\n",
        "            temp = lr_min+(lr_max-lr_min)*np.exp(epoch/decay_speed)\n",
        "            sess.run(train_step, feed_dict={X:batch_xs, Y:batch_ys, learning_rate:temp})\n",
        "            if epoch%200 == 0:\n",
        "                print(sess.run([cross_entropy],{X:batch_xs, Y:batch_ys}))\n",
        "\n",
        "        #Save the model\n",
        "        save_path = saver.save(sess, file_path+save_names[i])\n",
        "        print(\"Model saved in path: %s\" % save_path)\n",
        "        #Analyze test performance\n",
        "        correct_prediction = tf.equal(tf.argmax(model[-1],1), tf.argmax(Y,1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "        print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.2187161]\n",
            "[0.005136001]\n",
            "[0.00027231552]\n",
            "[8.518354e-05]\n",
            "[3.9518956e-05]\n",
            "[2.1727612e-05]\n",
            "[1.31828765e-05]\n",
            "[8.547723e-06]\n",
            "[5.7872685e-06]\n",
            "[4.0354034e-06]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_0.ckpt\n",
            "0.9735\n",
            "[2.0421455]\n",
            "[0.0015606845]\n",
            "[0.00014074583]\n",
            "[4.7544996e-05]\n",
            "[2.2481432e-05]\n",
            "[1.2528443e-05]\n",
            "[7.663716e-06]\n",
            "[4.9766563e-06]\n",
            "[3.3699405e-06]\n",
            "[2.3546322e-06]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_1.ckpt\n",
            "0.9745\n",
            "[2.2451067]\n",
            "[0.001723097]\n",
            "[0.0001449233]\n",
            "[4.940928e-05]\n",
            "[2.3556666e-05]\n",
            "[1.3188878e-05]\n",
            "[8.086501e-06]\n",
            "[5.2516107e-06]\n",
            "[3.570353e-06]\n",
            "[2.508654e-06]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_2.ckpt\n",
            "0.9735\n",
            "[2.3762264]\n",
            "[0.0019322701]\n",
            "[0.0001184532]\n",
            "[3.8224414e-05]\n",
            "[1.7742452e-05]\n",
            "[9.862373e-06]\n",
            "[6.008641e-06]\n",
            "[3.8900594e-06]\n",
            "[2.636658e-06]\n",
            "[1.8376429e-06]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_3.ckpt\n",
            "0.9728\n",
            "[2.2277255]\n",
            "[0.0008777641]\n",
            "[9.054599e-05]\n",
            "[3.1876567e-05]\n",
            "[1.5341668e-05]\n",
            "[8.621651e-06]\n",
            "[5.310927e-06]\n",
            "[3.46499e-06]\n",
            "[2.3569528e-06]\n",
            "[1.6519961e-06]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_4.ckpt\n",
            "0.9745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y6jVm_N8OjN",
        "colab_type": "text"
      },
      "source": [
        "### Pruning the trained 5 layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLxVoamm8OjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d00b0f24-526e-4397-e1e7-69125313b4a7"
      },
      "source": [
        "# m_shapes = [[784,200,100,60,30,10],\n",
        "#             [784,200,100,70,40,10],\n",
        "#             [784,200,130,80,50,10],\n",
        "#             [784,200,150,90,60,10],\n",
        "#             [784,250,180,120,60,10]]\n",
        "m_shapes = [[784,200,100,60,30,10],\n",
        "            [784,200,100,70,40,10],\n",
        "            [784,200,130,80,50,10],\n",
        "            [784,200,150,90,60,10],\n",
        "            [784,250,150,100,50,10]]         \n",
        "file_path = 'drive/My Drive/Colab Notebooks Old/ensemble_exp/'            \n",
        "load_names = [('5L2_mnist_'+str(i)+'.ckpt') for i in range(len(m_shapes))]\n",
        "save_names = [('5L2_mnist'+str(i)+'_pruned90.ckpt') for i in range(len(m_shapes))]\n",
        "target_sparsity = 0.90\n",
        "\n",
        "for i in range(len(m_shapes)):\n",
        "    reset_graph()\n",
        "    # Define model\n",
        "    X = tf.placeholder(tf.float32, [None, 784],name='X')\n",
        "    model = model_5l(X,m_shapes[i])\n",
        "    Y = tf.placeholder(tf.float32, [None, 10],name='Y')\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    # Reset global step op\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    reset_global_step_op = tf.assign(global_step, 0)\n",
        "\n",
        "    # Define pruning hparams\n",
        "    pruning_hparams = pruning.get_pruning_hparams()\n",
        "    pruning_hparams.begin_pruning_step = 0\n",
        "    pruning_hparams.end_pruning_step = 500\n",
        "    pruning_hparams.pruning_frequency = 1\n",
        "    pruning_hparams.sparsity_function_end_step = 500\n",
        "    pruning_hparams.target_sparsity = target_sparsity\n",
        "    print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
        "\n",
        "    # Create a pruning object using the pruning specification, sparsity seems to have priority over the hparam\n",
        "    p = pruning.Pruning(pruning_hparams, global_step=global_step)\n",
        "    prune_op = p.conditional_mask_update_op()\n",
        "\n",
        "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model[-1])\n",
        "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "    train_step = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(cross_entropy, global_step=global_step)\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "    n_epochs = 1000\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "\n",
        "        sess.run(init)\n",
        "        # Restore original trained weights\n",
        "        saver.restore(sess, file_path+load_names[i])\n",
        "\n",
        "        correct_prediction = tf.equal(tf.argmax(model[-1],1), tf.argmax(Y,1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "        print(\"Accuracy of original model: \",sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "    \n",
        "        sess.run(reset_global_step_op)\n",
        "        print(\"Starting with retraining\")   \n",
        "        for epoch in range(n_epochs):\n",
        "            # batch_xs, batch_ys = mnist.train.next_batch(200)\n",
        "            batch_xs = mnist.train.images\n",
        "            batch_ys = mnist.train.labels\n",
        "            sess.run(prune_op)\n",
        "            sess.run(train_step, {X:batch_xs, Y:batch_ys})\n",
        "            if epoch%200 == 0:\n",
        "                print(sess.run([cross_entropy],{X:batch_xs, Y:batch_ys}))\n",
        "                print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
        "\n",
        "        #Save trained model\n",
        "        save_path = saver.save(sess, file_path+save_names[i])\n",
        "        print(\"Model saved in path: %s\" % save_path)\n",
        "        print(\"Accuracy after retraining \\n\",sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=500,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.9,sparsity_function_begin_step=0,sparsity_function_end_step=500,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_0.ckpt\n",
            "Accuracy of original model:  0.9735\n",
            "Starting with retraining\n",
            "[0.00028994755]\n",
            "Weight sparsities: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.08360541]\n",
            "Weight sparsities: [0.7055995, 0.70559996, 0.70566666, 0.70555556, 0.7066667]\n",
            "[0.21725371]\n",
            "Weight sparsities: [0.89279974, 0.8928, 0.89283335, 0.8927778, 0.8933334]\n",
            "[0.06509825]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.90000004, 0.90000004]\n",
            "[0.044349495]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.90000004, 0.90000004]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist0_pruned90.ckpt\n",
            "Accuracy after retraining \n",
            " 0.9611\n",
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=500,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.9,sparsity_function_begin_step=0,sparsity_function_end_step=500,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_1.ckpt\n",
            "Accuracy of original model:  0.9745\n",
            "Starting with retraining\n",
            "[0.00011641381]\n",
            "Weight sparsities: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.11274803]\n",
            "Weight sparsities: [0.7055995, 0.70559996, 0.7055714, 0.7057143, 0.705]\n",
            "[0.13977206]\n",
            "Weight sparsities: [0.89279974, 0.8928, 0.89285713, 0.89285713, 0.8925]\n",
            "[0.054561816]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.9, 0.9]\n",
            "[0.041656125]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.9, 0.9]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist1_pruned90.ckpt\n",
            "Accuracy after retraining \n",
            " 0.9688\n",
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=500,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.9,sparsity_function_begin_step=0,sparsity_function_end_step=500,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_2.ckpt\n",
            "Accuracy of original model:  0.9735\n",
            "Starting with retraining\n",
            "[2.2753464e-05]\n",
            "Weight sparsities: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.06438846]\n",
            "Weight sparsities: [0.7055995, 0.7056154, 0.7055769, 0.7055, 0.70600003]\n",
            "[0.05744257]\n",
            "Weight sparsities: [0.89279974, 0.89280766, 0.89278847, 0.89275, 0.892]\n",
            "[0.024284262]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.90000004, 0.90000004]\n",
            "[0.014715499]\n",
            "Weight sparsities: [0.9, 0.9, 0.9, 0.90000004, 0.90000004]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist2_pruned90.ckpt\n",
            "Accuracy after retraining \n",
            " 0.9647\n",
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=500,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.9,sparsity_function_begin_step=0,sparsity_function_end_step=500,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_3.ckpt\n",
            "Accuracy of original model:  0.9728\n",
            "Starting with retraining\n",
            "[0.006881542]\n",
            "Weight sparsities: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.052129686]\n",
            "Weight sparsities: [0.7055995, 0.7056, 0.7056296, 0.70555556, 0.70500004]\n",
            "[0.044768713]\n",
            "Weight sparsities: [0.89279974, 0.89280003, 0.8928148, 0.8927778, 0.8933334]\n",
            "[0.015629863]\n",
            "Weight sparsities: [0.9, 0.90000004, 0.9, 0.9, 0.90000004]\n",
            "[0.00828288]\n",
            "Weight sparsities: [0.9, 0.90000004, 0.9, 0.9, 0.90000004]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist3_pruned90.ckpt\n",
            "Accuracy after retraining \n",
            " 0.9647\n",
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=500,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.9,sparsity_function_begin_step=0,sparsity_function_end_step=500,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_4.ckpt\n",
            "Accuracy of original model:  0.9745\n",
            "Starting with retraining\n",
            "[0.00018984101]\n",
            "Weight sparsities: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.060449965]\n",
            "Weight sparsities: [0.705602, 0.7056, 0.7056, 0.70559996, 0.70600003]\n",
            "[0.040267143]\n",
            "Weight sparsities: [0.892801, 0.8928, 0.89280003, 0.8928, 0.892]\n",
            "[0.012541852]\n",
            "Weight sparsities: [0.9, 0.9, 0.90000004, 0.9, 0.90000004]\n",
            "[0.005637496]\n",
            "Weight sparsities: [0.9, 0.9, 0.90000004, 0.9, 0.90000004]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist4_pruned90.ckpt\n",
            "Accuracy after retraining \n",
            " 0.9697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoQlNhLEuiDD",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckCrHyRY_eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Variable to store accuracies for plotting curves\n",
        "acc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ8dneBguhGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "a00eeb9e-dc9b-4a37-9e08-65bac4cd1a36"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# all model names in list\n",
        "n_models = 5\n",
        "file_path = 'drive/My Drive/Colab Notebooks Old/ensemble_exp/'        \n",
        "# model_names = [('5L2_mnist'+str(i)+'_pruned98.ckpt') for i in range(n_models)]\n",
        "# meta_names = [('5L2_mnist'+str(i)+'_pruned98.ckpt.meta') for i in range(n_models)]\n",
        "model_names = [('5L2_mnist_'+str(i)+'.ckpt') for i in range(n_models)]\n",
        "meta_names = [('5L2_mnist_'+str(i)+'.ckpt.meta') for i in range(n_models)]\n",
        "\n",
        "# One hot encoding of model predictions to implement majority vote\n",
        "def one_hot_trans(arr,n_classes=10):\n",
        "        encoded = [[0 for i in range(n_classes)] for j in range(arr.shape[0])]\n",
        "        for i in range(arr.shape[0]):\n",
        "            encoded[i][arr[i]] = 1\n",
        "        return encoded\n",
        "\n",
        "pred = []       # list of output of individual models\n",
        "for i in range(len(model_names)):\n",
        "    reset_graph()\n",
        "    with tf.Session() as sess:\n",
        "        # Load graph and weights           \n",
        "        new_saver = tf.train.import_meta_graph(file_path+meta_names[i])\n",
        "        new_saver.restore(sess, file_path+model_names[i])\n",
        "\n",
        "        # Get required ops->tensors->python variables\n",
        "        graph = tf.get_default_graph()\n",
        "        tensors = graph.get_operations()\n",
        "        req_tensors = [v for v in tensors if (str(v.name) == 'Layer_5/model_output' or \n",
        "                                             str(v.name) == 'Y') or \n",
        "                                             str(v.name) == 'X'] \n",
        "        X = req_tensors[0].outputs[0]\n",
        "        model_pred = req_tensors[1].outputs[0]\n",
        "        Y = req_tensors[2].outputs[0]   \n",
        "\n",
        "        # # Make and save model predictions\n",
        "        # correct_prediction = tf.equal(tf.argmax(model_pred,1), tf.argmax(Y,1))\n",
        "        # accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "        # print(\"Model accuracy: \",sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "\n",
        "        # # Run quantization ops\n",
        "        # for i in range(16):\n",
        "        #     sess.run(quant_ops[i])\n",
        "        pred.append(sess.run(model_pred, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "\n",
        "# Consensus variable using sum of soft predictions\n",
        "def soft_cons(pred):\n",
        "    cons = pred[0]      \n",
        "    for k in range(len(pred)-1):\n",
        "        for i in range(len(pred[k+1])):\n",
        "            for j in range(len(pred[k][i])):\n",
        "                cons[i][j] = cons[i][j] + pred[k+1][i][j]\n",
        "    return cons\n",
        "\n",
        "# Consensus variable using majority vote\n",
        "def vote_cons(pred):\n",
        "    cons = one_hot_trans(np.argmax(pred[0],axis=1))\n",
        "    for k in range(len(pred)-1):\n",
        "        model_pred = one_hot_trans(np.argmax(pred[k+1],axis=1))\n",
        "        for i in range(len(pred[k+1])):\n",
        "            for j in range(len(pred[k][i])):\n",
        "                cons[i][j] = cons[i][j] + model_pred[i][j]\n",
        "    return cons\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    for i in range(len(pred)):\n",
        "        indiv_pred = tf.equal(tf.argmax(pred[i],1), tf.argmax(Y,1))\n",
        "        indiv_accuracy = tf.reduce_mean(tf.cast(indiv_pred, tf.float32))\n",
        "        print(\"Model accuracy: \",sess.run(indiv_accuracy, feed_dict={Y: mnist.test.labels}))\n",
        "    \n",
        "    acc.append([])      # Store accuracies for plotting curves\n",
        "    print('Models   |Consensus A    |Consensus B')\n",
        "    for i in range(len(pred)):\n",
        "        cons_1 = soft_cons(pred[:i+1])\n",
        "        cons_2 = vote_cons(pred[:i+1])\n",
        "        cons_pred1 = tf.equal(tf.argmax(cons_1, 1), tf.argmax(Y, 1)) \n",
        "        cons_pred2 = tf.equal(tf.argmax(cons_2, 1), tf.argmax(Y, 1)) \n",
        "        cons_accuracy1 = tf.reduce_mean(tf.cast(cons_pred1, tf.float32))\n",
        "        cons_accuracy2 = tf.reduce_mean(tf.cast(cons_pred2, tf.float32))\n",
        "        a1 = sess.run(cons_accuracy1, feed_dict={Y:mnist.test.labels})\n",
        "        a2 = sess.run(cons_accuracy2, feed_dict={Y:mnist.test.labels})\n",
        "        print(str(i+1)+'        '+str(a1)+'         '+str(a2))\n",
        "        acc[-1].append(a1)\n",
        "\n",
        "    conf_matr = tf.confusion_matrix(tf.argmax(Y,1),tf.argmax(soft_cons(pred),1))\n",
        "    print('Confusion matrix: \\n',sess.run(conf_matr, feed_dict={Y:mnist.test.labels}))\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_0.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_1.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_2.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_3.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/5L2_mnist_4.ckpt\n",
            "Model accuracy:  0.9735\n",
            "Model accuracy:  0.9745\n",
            "Model accuracy:  0.9735\n",
            "Model accuracy:  0.9728\n",
            "Model accuracy:  0.9745\n",
            "Models   |Consensus A    |Consensus B\n",
            "1        0.9735         0.9735\n",
            "2        0.9785         0.9761\n",
            "3        0.9803         0.9803\n",
            "4        0.98         0.9793\n",
            "5        0.9803         0.9804\n",
            "Confusion matrix: \n",
            " [[ 971    0    0    1    0    1    1    1    4    1]\n",
            " [   0 1125    3    1    0    1    2    1    2    0]\n",
            " [   4    2 1010    3    1    0    2    4    5    1]\n",
            " [   0    0    4  995    0    4    0    2    4    1]\n",
            " [   1    0    5    0  962    1    2    3    1    7]\n",
            " [   1    0    0    6    3  873    3    0    5    1]\n",
            " [   5    2    0    1    4    5  940    0    1    0]\n",
            " [   1    4    6    2    0    0    0 1006    3    6]\n",
            " [   2    0    2    8    3    5    3    2  943    6]\n",
            " [   3    3    0    6    7    1    0    9    0  980]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04HRyKrmlJZw",
        "colab_type": "text"
      },
      "source": [
        "#### Plot ensemble results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kol67Rnr8OjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "6b17f157-c743-4405-8a45-4205265cde3c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "# print(acc)\n",
        "\n",
        "acc1 = [[0.9611, 0.9732, 0.9774, 0.9787, 0.9801], [0.9402, 0.9661, 0.9715, 0.9736, 0.9752], [0.6695, 0.9479, 0.9555, 0.958, 0.9624], [0.4886, 0.7416, 0.9344, 0.9441, 0.949]]\n",
        "acc1.insert(0,acc[0])\n",
        "acc = acc1\n",
        "\n",
        "prnt_sparsities = [0.90,0.95,0.97,0.98]\n",
        "labels = [('Pruning sparsity: '+str(i)) for i in prnt_sparsities]\n",
        "labels.insert(0,'Original models')\n",
        "\n",
        "fig = plt.figure(1,figsize=(9,6))\n",
        "plt.plot([1,2,3,4,5],acc[0],'k',label=labels[0],marker=\"o\")\n",
        "plt.plot([1,2,3,4,5],acc[1],'r-',label=labels[1],marker=\"x\")\n",
        "plt.plot([1,2,3,4,5],acc[2],'g-',label=labels[2],marker=\"v\")\n",
        "plt.plot([1,2,3,4,5],acc[3],'b-',label=labels[3],marker=\"+\")\n",
        "plt.plot([1,2,3,4,5],acc[4],'m-',label=labels[4],marker=\"^\")\n",
        "\n",
        "plt.xticks([1,2,3,4,5])\n",
        "# plt.plot([0.7,0.75,0.8,0.85,0.9,0.95,0.96],[0.735,0.734,0.7269,0.6999,0.64,0.5001,0.4502], label='Regularized model',marker='x')\n",
        "plt.xlabel('Number of models in consensus')\n",
        "plt.ylabel('Test set accuracy')\n",
        "plt.legend()\n",
        "# plt.title('Inference accuracy vs number of models in consensus')\n",
        "fig.savefig('mnist_ensemble.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAF+CAYAAAB3fJvtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUxfrA8e/sphcgCIQAkkCoAZKogOVaQEWv7WevKKAoKKBYUFRUQEWvvaNgoSgqXJV77QVF7BdBCCUBKUlooScB0rM7vz9OElI2yUmyu2c3eT/Ps0/OmdPeTWDPuzNzZpTWGiGEEEIIf2WzOgAhhBBCiKaQZEYIIYQQfk2SGSGEEEL4NUlmhBBCCOHXJJkRQgghhF+TZEYIIYQQfk2SGSGEEEL4Na8mM0qp05VSnyqldiqltFJqlIljBiillimlCsqOe0QppbwQrhBCCCH8gLdrZiKAdcBEoKC+nZVSrYDvgD3AoLLj7gXu9mCMQgghhPAjyqoRgJVSR4AJWuu5dexzG/AUEK21Ligrewi4Deii6wi+Xbt2Oi4uzq0xCyGEEMI6K1eu3K+1bl+9PMCKYBrgZODn8kSmzDfAY0AckF7bgXFxcaxYscKz0QkhhBDCa5RSma7Kfb0DcEeMJqbK9lTaJoQQQogWzteTmQZRSo1RSq1QSq3Yt2+f1eEIIYQQwgt8PZnZDURXK4uutK0KrfVsrfVArfXA9u1rNKkJIYQQohny9WTmd+A0pVRIpbJhwC4gw5KIhBBCCOFTvD3OTIRSKlkplVx27a5l613Ltj+plPq+0iHvA/nAXKVUf6XUZcD9wPN1PckkhBBCiJbD2zUzA4FVZa9QYHrZ8qNl22OA+PKdtda5GDUxnYAVwGvAc8Dz3gtZCCGEEL7Mq49ma61/BGodvVdrPcpF2VrgdM9FJYQQQgh/5ut9ZoQQQggh6iTJjBBCCCH8miQzQgi/tWDBAuLi4rDZbMTFxbFgwQKrQxKixbLy/6MkM0IIv7RgwQLGjBlDZmYmWmsyMzMZM2aMJDT+5umnWTJlSpWb4JIpU+Dpp62OTDTAqmuv5b3Ro6v8f3xv9GhWXXutV67v63MzCeF2CxYsYMqUKWzbto2uXbsyY8YMhg8fbnVYfk9rjdPpxOl04nA4XP6sa5uZfSovbxk7lsH5+fxYKYbB+flsGTuWr485BqWMZw3Kf1ZebqllVl/fVdmf27dz2quv0g3IBLplZpL0xBN8MmECA7dtqziufDSOyqNySFkTyrRGO50ordEOB0pro6xsWTudqGrbtcNhPMHjdFZ5Ka1Z+MUXLCgq4m6MCRT7APOLirhj6VI+wPMsmzXb0wYOHKhlosmWTWtNaWkpRUVFFa9FixbxwAMPUFhYWLFfcHAwkydP5qyzzmrUTbWpN2V3H2/Vub39WTIEWARcBfzoYr0ls1V6qSauu+Mc9a0nApOAb4FzgReBDfXEVF+Msk/9+3jK/4DuGP8XlymF0+l027mVUiu11gNrlEsyI9yhetJQXFzcpHV3nKO4uNjrN9iGstvt2Gy2Gj9dlTVkn8Zu88jxShEIBGpNgNYEOJ0Vy4Fl6+XldoejYjnA6cTmdBLgcGB3OLCXbS9f/veCBcTk5XE5sBpIBr4AcsPCuOD8841vmuXfHsH4Blm+rvXR7ZV+qmo/K5arn6PyNlf7ly+XndtlWfVzNHa90vmUj/979wVOpcBmQyuFrr7sqqxsGaXQNiMF0DZbxXqVbZV/1lZeeXul4yuWbbaKfarsV+34ijKoekz181Tap/K26suuzq1c7FPjHGX7nbTvMQ50qJm0BB4IpPjlYrf9/WpLZqSZqQF8oXnC4XD4ZNLgzszbbrcTHBxMUFAQwcHBFa/q661bt65zu6uyLbfeyp9U/eY+BBgMnLNkiVcThspV76Y5nVBSAsXFxqvycvV1q5arrzsc7vhnUcN9gAPQwClAEXAOxmicQd9/X+MDuNHrlcsCAtx/Tk/E6UfXaD33JA61K63x9w3fH8CRiWmuY6gvptr2UarFdxTVWuPQDpzaWePlcNZSXsv+lY+Jf+8rDuYuR1fKKlQpnN7NO8PESTJjUnlnw/z8fAAyMzMZPXo0a9eu5R//+IfXkgaHG28MNpvNVNIQGRlJu3btGpQ0NGXdbre77T1Wd+3UqSzas8eo/sQYXnoBcH+7dpyVkOD6Jl1U1LCbtyeXPZQYAGC3Q2AgBAUdfVVer74cHl7/Po1dNrHfcXNPYvWelBpvI7ljL1aNXeW531MLV/lm6HA6cGhHjZ+1bSu/MR4tK2VAVHf+V/o3pZXuRgEO6B8Vy5f6b6N5s7RxN9va9m/MMXXe0N10Lm/E61HVMooQDe8l3ObZa7q+tKjNlClTKhKZckVFRTz11FOmjq9+83d1Qw8PD6dt27amE4CmJg0BAX7+59caDh+GnBzIzq76s5bl1wMDKQG+p2qb8Vv790OnTu6LzW5v2M27PDFo4g2+0cuBgUbMfuRkWyyppSkUV/pnHFQKJ9KFgpICUzfXht1469/m8ev4QNwaNzdlufhnV2qH/7GFC96/wL3XqoVCYVO2ipfdZq+yXlGuXJc35hi7zU6ALaDBx1SsU/+1TZ+rCftXHPOf/zArfAPf5f5FqbOUIHsQN8acR8eULUZHKE//DX29T0FjubvPjM1mc9n/QinF8uXL600aGtWk0BIUFtabgNSarOTkHO3LUJvWraFNG+MVFQVt2rDlwAFy//c/ji8u5rfgYIIvv5wTTjrJfbUHgYFH26mbMYfTQZGjiKLSIoocRRSWFrpcLiotW69nueI4k/sVHM4mmwKrfw1NVvmGYLfZa/ysbVv5DaYh2+q8Do04xk1xv/bna3y1+StKnaUE2gK5sOeF3Hfqfe692dZyjELJ57ObZB3OovvL3SksLSQ0IJStE7fSMaKjW68hfWaaqGvXrmRmZrosHziwxu+15XA4qiYX9SUg1ZeLiuo+f2holUSEjh2hb98aCUqV5fKfrVrVqG04btZxrN69Gs4qLykC3ic5KNUvmibKEwi3JQ71JBF1XavUWbOfQ2ME2AIItgcTHBBMSECIy+XWIa0rloPtR7f9su0X1u9bj0M7sCs7x8ccz8W9L7Y2KWjAdWyqkX2nmpnE6ES6v9ydUmcpAbYAZl440+03QeF5MZEx3Jh8I7NWzuLG5Bu9+jeUZMakGTNmVOkzAxAWFsaMGTMsjMoNtIYjRxqWgFRePny47vPb7TWTjmOPrT0Rqb4cHOzWt3uy6kpq6eoaTROnqNhajyl1lro/cSg/Rx3bXF3Lod3TZybAFlBr4lCeLJQnECEBITWSiCrr9SzXlaQE24Ox2xrfvFX+TdBR6iDIHsSn134qN0E/ZOVNULjXw6c/zPp963n4jIe9el1JZkwqf2rJ6qeZXCoqangyUrmsvk6lkZFVaz26dTOXjERFGX1BfOCbZ05hDlsObiFpnx1noB0qJQUlAYqlWb/T59U+LpMRdyUQgbbAem/8bULaVL3x2xueINSXpAQHBGNTzaMZTG6CzYdVN0HhXjGRMQzNWEbHCO9eV/rMmPX00zBoEAwderRs6VL480+4776mndvhgEOHGpaAVF4uqKffQEiIuWYZV8utWhmPo/o4rTVZR7LYcnALW7K3HP1Ztnyg4IDL4xSKLq26cFzMcUdv/I1MEOqrnWguCYSvyTqcxTUfX8PCKxZKMiOED1DKqPT3zLmlz0zTDBoEV10FixYZCc3SpUfXtYb8/MYnI7m5dV/bZquZbHTqVH8TTflySIh3fkceVuwoJjMn02WysjV7KwWlR5M6m7IR2zqW+LbxXJFwBfFR8cS3jSc+Kp6wwDAS30iksLSQkIAQlt+yXG6CfiwmMoZlo5ZZHYYQfkdrKC2tOspEQ17VR6gof1lBkhmzhg41EpeLL4b27WHbNoiOhquvNhKT0no6Q0ZEVE00YmMhKclcDUlkpE801XjD4aLDVZOVSknLttxtVcZJCA0IpXtUd3q07cG58edWJCvxbeOJbR1LoD2w1utI04QQvmfaNOPlzzyVIDTlVdc5PaX8ljV1qnf+ptLM1FAXXwyffgrx8UZtjZlOrG3a+EVTjTdordmTt6fW5qB9+fuq7H9M6DFHk5RKtSvxbeOJiYhp9JMg0jTRvDSHm6CovXmiKQmCJ5IDqxKE4OCqI0O4elUfPcIdr4aeMzDQ+81Mksw0RHnT0m23weuvH21yElWUOkvrbA7KK8mr2FehOLb1sS6TlfioeFqHtLbwnQh/4ck2em8qv2k7HMbL1bLZsqZutyKOtDTo2lUSBFcvu91/Kuilz4wvq9xHZuhQ41V5vYXJK85ja/ZWlwlLZm5mlTFIgu3BdI/qTnzbeM7sdmaVZCWuTRzBAe59/Fo0Lw6H0cc9L8/omlb+qrwOsGCB/9/wfTkhs9uNCma7veqy2bLKy8HBR8s2b4a//z56nW3bjJ+DBsFpp0mC4I+mTvX+NaVmxixPPs3kg7TW7M/f7zJZ2ZK9hd1HdlfZPyokqtbmoE6RneRJnmbK6ayaYFRPMqqv17Wttn3rG1exscrnjXTHzbkx2711jDvO6a0BrZtLDZvwHGlmEjU4nA62H9pea/+Vw8VVB8TrHNm51oSlbWhbi96FqI3TadRouDOxqL5eWNjwuAIDISzMGIIoLOzoq/J6Q7aFhUFiovHt3uzNu3wSZeFbJJnxf0VZRaRek0rCwgSCO7q/1l2amVqogpKCWpuDMnIyKHGWVOwbaAukW1Q34qPiOfXYU6skK93adCM0MNTCd+J+VnYa1bpqouGOxKL6en3DD7litxvJgqvkISqqYUmHq31DQ41kxhN69vTMeYX3WNE8Idwr47EMcn/JJfOxTHq91str15WamWbgYMFBl7Urmw9uZtfhXVX2bRXcqmqtSqXlLq26NGloeX9T15MThYWeazap3M+jIcoTjYYkDw3d5qlEw9PkaSYh3ENrjXZodJHGWeTEWeysuVzsxFlUc7l4bzFbJ29Fl2hsoTZO3Hqi22tnpGbGjzm1k52HdtbafyWnMKfK/jERMcS3jWdY92E1moOOCT1GJrbDeGoCjG5QrhKNhub4NlvtCUJ0tHuSkMBAaRqpjSQy/s/TzRO+Rjt1gxIFl8vFZceaWK5330qx4IY6Du3QXq2dkWTGRxSVFpGek+6yhiU9O50ix9FekAG2gIrRbQd3Hkx8VDw92vaoaA4KDwq38J34tmnTYPr0o+vllXeJiXDeeY2v3QgKkkRDiKbwRPOE1hpd4vmkoSFJRfn1dal7W0VUoEIFKWzBNmzBtqPLQTZU8NHlgKiAquVBZfvXtuzqnJWWy3+W5paScnYKush4X7pYs3vObmIfjvVKcirJjBeVT3boqoZlx6Ed6ErpcHhgOPFt4+nbri8X9rywSu1K19ZdCbDJn64xpk0zHoN9/HFjvZm2sgrhU7TWOAucOA47KD1ciuOww1g+ZCwX7Shi95u7wQlZs7NAgS3I5pakwa1s1Hozr7xsj7AT0DbAZTJRY9kdyUSQDWWz9tvUxnEba9ToeLN2Ru6IJh036zhW715dozy5YzKrxq4CjOagrMNZtTYHHSw4WOXYDuEdiI+K54y4M2r0X+kQ3kGagzxg+XJ48kkYNQrmzrU6GiF8l7PUWZF01JaEuNpWsX6o0vIRB5icfF6Xana9vgt7uL3eG3tgZGC9iUVdtRSmEovK57HLZ3JtDv1+CF1cNZvRxZrc3+qZe9BNJJkx6eQuJ5O6L5Vix9GhKO3KjlM7ufjDi9l8cDPp2em1TnZ4ZcKVVZKV7lHdiQyOtOKttFgFBTBypDFH54svGtNjCdFcaK1x5jtdJxaV1yslIrXue8iBs9BZ/0UxmjfskXbskXYCIgOwt7IT0CaAkGNDKsortpUvtzq67ChwsOacNVVqUWzBNgb/PbhF9J1pLgatGmTp9SWZMenh0x9mzuo5Vcoc2sHf+//G4XTQs21P/hn/zwZNdii866GHYMMG+O47aN1aOo0K61Wu/WhwbYeLfTGXf2CPsNdINIKPDSYsMqxKolE9CameiAREGk0pTWF184RoHiSZMSkmMoYbk2/krb/eosRZQqAtkOsGXMeci+dIc5AfWLYMXngBxo2Ds8+2OhrhTt58CqbW2o/6ajtqSUIaVftRlkwERAUQ0tVF7UerWpKQ8vUIu+X9KyqzunlCNA8yzkwDZB3OovvL3SksLSQ0IJStE7fKjMt+4PBhSEoyHp9evRoiIqyOSLjTxnEbyZqVRadbO7n8Ju8scdaeaJhscqlYPtK02g97pN1ohqkt0ahW8+Gu2g8hmgsZZ8YNymtnZq2cxY3JN0oi4yfuvRcyMuCnnySRaW7yUvOMp1+csOuNXRxecRhnUdWmG7NPtJTXflRpRnFV+1GtmcVlzUi4b9V+CNHcSTLTQA+f/jDr963n4TMetjoUYcI338CsWTBpEpx6qtXRCHcqySlh1Rmrjj4lo6FoRxGRAyPrbmappWZEaj+E8F/SzCSarexsGDAAWrWCv/6CkBCrIxLuUnqolFVDVpG3Kq9KuaeGUBdC+Ibampnkq4hotiZOhN27Yf58SWSak9LDpaw5bw15q/Nq1C2XPwUjhGhZJJkRzdLixfDuuzBlCgyskcMLf+XIc7D2grUc+t8hgmODobTqdnkKRoiWSfrMiGZn3z4YOxaOO85IZkTz4Mh3sPbCteT+mkvC+wl0uLqD1SEJIXyEJDOiWdEabr0VcnPhhx+MCSCF/3MUOFh38TpyluXQ992+ksgIIaqQZEY0Kx98AJ98Ak89Bf37Wx2NcAdHoYN1l64j+/ts+szpQ/TwaKtDEkL4GElmRLOxaxeMHw8nnwz33GN1NMIdnEVO1l+xnuxvsun9dm86jpSxnYQQNUkHYNEsaA033wxFRTBvHtjtVkckmspZ7GT91es5+MVBer3Ri5ibYqwOSQjho6RmRjQLb78NX30Fr7wCPXtaHY1oKmeJk9RrUznw3wP0fLUnncZ2sjokIYQPk5oZ4fcyMuCuu+DMM42JJIV/c5Y6Sbs+jf2f7KfHiz3oPL6z1SEJIXycJDPCrzmdcOONoBS8844xmaTwX9qh2TByA/sW7aP7M93pMrGL1SEJIfyANDMJv/bqq/Djj0YzU2ys1dGIptAOzYabNrD3/b10e7IbXSd1tTokIYSfkO+xwm9t3AiTJ8MFFxi1M8J/aadm45iN7Jm/h7hH44i9XzJTIYR5kswIv1RaCqNGQWgovPmm0cwk/JPWmr/H/c3ud3YT+3AscQ/HWR2SEMLPSDOT8EvPPgt//GEMkhcjT+z6La01m27fRNasLLo+0JW46XFWhySE8ENSMyP8ztq18MgjcOWVcPXVVkcjGktrzea7NrPrtV0cO+lYus3ohpIqNiFEI3g9mVFKjVNKpSulCpVSK5VSp9Wz/3ilVJpSqkAptVEpNcJbsQrfU1wMI0ZAVBTMnCnNS/5Ka83W+7ay86WddJ7Yme5Pd5dERgjRaF5tZlJKXQ28BIwDfin7+ZVSKkFrvc3F/rcBTwG3AP8DBgNvKqWytdafeS9y4SsefxxWr4b//hfatbM6GtEYWmvSH0xn+7Pb6TS+Ez1e6CGJjBCiSbxdM3M3MFdr/abWOk1rfTuQBdxWy/43AG9qrT/QWm/VWn8IzAYmeyle4UP+/BOeeAJGjoT/+z+roxGNlTE1g23/2kbM2Bh6vtJTEhkhRJN5LZlRSgUBJwDfVtv0LXBKLYcFA4XVygqAwUqpQPdGKHxZQYHRvBQTAy++aHU0orEyHssg87FMOo7uSK+ZvSSREUK4hTdrZtoBdmBPtfI9QG1T4X4D3KSUGqQMA4GbgcCy81WhlBqjlFqhlFqxb98+N4YurPbQQ7BhgzE4Xps2VkcjGiPzyUwyHskgekQ0vWf3RtkkkRFCuIevP830GPAF8BtQAvwXmFe2zVl9Z631bK31QK31wPbt23svSuFRP/0EL7wAt90G55xjdTSiMbY9u430B9PpcF0H+rzTRxIZIYRbeTOZ2Q84gOhq5dHAblcHaK0LtNY3AWFAHNAVyAAOA1L10gIcOWIMjtetGzz9tNXRiMbY/uJ2tt67lfZXt6fPvD4ouyQyQgj38loyo7UuBlYCw6ptGoZR81LXsSVa6x1aawdwDfC51rpGzYxofu6915gVe+5ciIiwOhrRUDtf28mWu7bQ7vJ29H23L7YAX68MFkL4I2+PAPw88K5SajnwK3Ar0Al4A0ApNR9Aaz2ibL0XcCLwBxCF8TRUf2Ckl+MWFvjmG3jjDbjnHjitztGIhC/aNWsXmyZs4piLjyHh/QRsgZLICCE8w6vJjNZ6oVLqGOAhIAZYB5yvtc4s26X6NLl2jASmN0afmaXAKVrrDO9ELKySkwOjR0PfvsbYMsK/ZL2dxd+3/k3bC9rSb2E/bEGSyAghPMfrczNprWcCM2vZNqTaehpwnBfCEj5m4kTYvRsWL4aQEKujEQ2xe95uNt6ykahzo+j3UT9swZLICCE8Sz5lhM/5z39g/nx48EEYNMjqaERD7Fmwhw03biDqrCj6L+6PPcRudUhCiBZAkhnhU/btg7Fj4bjjjLFlhP/Yu3AvaSPSaDOkDf3/2x97qCQyQgjv8HozkxC10doYSyYnB5YsgaAgqyMSZu37eB+pw1Np/Y/WDPhsAPYwSWSEEN4jyYzwGR9+CB9/DP/6FwwYYHU0wqz9/91P6jWptDqxFQO+GIA9XBIZIYR3STOT8Am7dsH48XDSSTBpktXRCLP2f76f9VeuJ+KECBK/SiQgUr4fCSG8T5IZYTmt4ZZboLAQ5s0Du3yx9wsHvj7A+svXE5EUQeLXiQS0kkRGCGEN+fQRlnvnHfjyS3j5ZejVy+pohBkHlxxk3SXrCO8XTuI3iQS2kUnshRDWkZoZYamMDLjzThg61GhmEr4ve2k26y5aR1jvMJK+SyKwrSQyQghrSTIjLON0wk03gVJG7YxN/jX6vJyfclh74VpC4kNIWpJE4DGSyAghrCfNTMIyr70GS5fCW29BXJzV0Yj65P6ay5rz1xDSNYTk75MJai/PzgshfIN8FxaW+PtvmDwZzj/fqJ0Rvi33j1zWnLeG4M7BJP2QRFC0JDJCCN8hyYzwOocDRo405lx6802jmUn4rkMrDrHm3DUEdggk+YdkgmOCrQ5JCCGqkGYm4XXPPgt//AHvvw+dOlkdjajL4b8Os2bYGgLbliUynSWREUL4HqmZEV61di088ghccQVcc43V0Yi6HEk5QsqwFOyt7CQtTSKkq0xfLoTwTZLMCK8pLjaal9q0gZkzpXnJlx1Zd4SUs1Owh9lJXppMaFyo1SEJIUStpJlJeM3jj8OqVbB4MbRvb3U0ojZ5aXmknJWCClQk/ZBEaHdJZIQQvk1qZoRX/PknPPEEjBgBl1xidTSiNvkb80k5MwUUJC9NJqxnmNUhCSFEvaRmRnhcQYHRvNSxI7z0ktXRiNrkb85n9Zmr0Q5N8o/JhPWWREYI4R8kmREe9/DDkJYG33xj9JcRvqcgvYCUM1NwFjlJ/jGZ8IRwq0MSQgjTJJkRHvXzz/D883DrrXDOOVZHI1wpzCxk9dDVOPIcJP+QTET/CKtDEkKIBpFkRnjMkSMwapQxVcEzz1gdjXClcHtZIpPrIOn7JCKSJJERQvgfSWaEx9x3H6Snw48/QoTcI31O0c4iUs5MoeRACUlLkog8PtLqkIQQolHkaSbhEd9+C6+/DnfdBaefbnU0orqirCJWn7ma4t3FJH6dSKtBrawOSQghGk2SGeF2OTkwejT06WOMLSN8S/GeYlLOSqFoZxEDvhpA65NbWx2SEEI0iTQzCbe7807IyoLffoNQGW/NpxTvLybl7BQKMwpJ/CqRNqfK42VCCP8nNTPCrf77X5g3Dx54AAYPtjoaUVnJgRJSzk6hYHMBAz4fQJszJJERQjQPkswIt9m/H8aMgeRkY2wZ4TtKsktIGZZC/oZ8+v+3P1FnRlkdkhBCuI00Mwm30Bpuuw2ys2HJEggKsjoiUa40t5Q1564hb30e/f/Tn7bntLU6JCGEcCtJZoRbLFwIH30ETz4JAwZYHY0oV3qolDX/XMOR1Ufo93E/jjnvGKtDEkIIt5NkRjRZVhaMGwcnnQSTJlkdjShXeqSUNeev4fCKwyQsSqDdRe2sDkkIITxC+syIJtEabrkFCguNjr8Bkh77BEeeg7UXrOXQH4fo+0Ff2l/a3uqQhBDCY+TWI5pkzhz44gtjNuxevayORgA48h2s/b+15P6SS98FfelwRQerQxJCCI+SZEY0WmamMabMkCEwYYLV0QgAR6GDdZesI2dpDn3m9yH6mmirQxJCCI+TZibRKE4n3HST0cw0Zw7Y5F+S5ZxFTtZfup7sJdn0fqc3Ha/vaHVIQgjhFaZuQUqp1UqpCUopGZxCADBzJvzwA7zwgjErtrCWs9jJ+ivWc/Drg/Sa3YuYUTFWhySEEF5j9vv0F8B9wC6l1AdKqbM8GJPwcZs2GTNin3eeMQeTsJazxEnq1akc+PwAPV/vSaebO1kdkhBCeJWpZEZrPQWIBS4D7MAXSql0pdQjSqmungxQ+BaHA0aOhJAQeOstUMrqiFo2Z6mTtOvS2P+f/fR4pQedb+1sdUhCCOF1pns6aMNXWuurgE7AbOBBYKtS6hul1D89FaTwHc89B7//Dq++Cp2kAsBSzlInG27YwL6P9hH/fDxdJnSxOiQhhLBEg7ttKqVOAv4F3A/sAqYDW4CPlFIvujc84UvWrjXmXLr8crj2Wqujadm0Q7Pxxo3s/XAv3Z/qzrF3HWt1SEIIYRlTj2YrpToAI4AbgXjgU+AKrfV3lfZ5F/gOuNMDcQqLFRcbzUutW8Prr0vzkpW0U7Px5o3seW8P3WZ0o+t90tIrhGjZzI4zswPYDLwNzNNa73exz3rgT3cFJnzLjBmwahUsXgztZTBZy2in5u+xf7N77m7ipsUR+2Cs1SEJIYTlzCYzZ2mtf65rB631IWBo00MSvmbFCiOZueEGuOQSq6NpubTWbBq/iay3sug6pSuxj0giI4QQYL7PzEGlVGL1QqVUolIqwc0xCR9SWAgjRkDHjsaUBcIaWqA03ewAACAASURBVGs237GZXW/s4tjJx9LtsW4oaesTQgjAfDIzG+jvojyhbJtoph5+GNLS4O23IUqGTLSE1pot92xh56s76XJ3F7o/2V0SGSGEqMRsMpMILHdR/icwwH3hCF/yyy/Go9hjx8K551odTcuktWbr5K3seGEHne/oTPyz8ZLICCFENWaTGQfQ2kV5FCCfrM3QkSPG00txcfDMM1ZH0zJprUl/KJ3tz2yn022d6PFiD0lkhBDCBbPJzDJgilLKXl6glAoApgA/eSIwYa3JkyE93ZhEMjLS6mhapozpGWx7Yhsxt8TQ89WeksgIIUQtzD7NdB/wC7BZKfVLWdmpQARwuicCE9b57jtjIsm77oIzzrA6mpYpc0YmmdMz6XhjR3q90Qtlk0RGCCFqY3Zupo0Y/WbeB9qWvRYASVrrNM+FJ7wtNxduugl69zYexxbet+2pbaQ/lE70DdH0frO3JDJCCFEPszUzaK2zMJqVmkQpNQ64F4jBGGjvzrrGsFFKXYdRM9QLOAQsASZprXc3NRZR0513wq5dxvxLoaFWR9PybH9+O1vv30qHazvQZ04flF0SGSGEqE+D5mZSSnVSSp2klDq98qsBx18NvAQ8ARwH/AZ8VdvM20qpfwDvAvOAfsAlGI+DL2hI3MKcTz+FuXPhgQdg8GCro2l5dry8gy33bKH9le3pM18SGSGEMEtprevfSalOGE1MpwMa4wmmigO11vZaDq1+nv8Ba7TWt1Qq2wR8pLV+wMX+k4DbtdaxlcpuBF7RWkfUda2BAwfqFStWmAlLAPv3Q//+xuB4y5dDUJDVEbUsO2fuZNP4TbS7tB0JCxOwBTZ4DlghhGj2lFIrtdYDq5eb/cR8EePx7AQgHzgNuBJIA/5pMoAg4ATg22qbvgVOqeWwX4EYpdRFytAOuAb40mTcwqTx4+HgQZg/XxIZb9s1exebxm/imIuOIeFDSWSEEKKhzH5qngFM1lpvwKiR2ae1/gSYDDxm8hztADuwp1r5HqCjqwO01r9jJC8LgGJgH0at0EhX+yulxiilViilVuzbt89kWGLhQli0CKZPh8Qak1YIT8qak8XfY/+m7flt6ffvftiCJJERQoiGMvvJGQqUz5R9EOhQtpyK8ZSTR5TN+/QKRsJ0AkYtUEdglqv9tdaztdYDtdYD28vUzqZkZcG4cXDiiXDvvVZH07Lsfnc3G0dvJOqcKPp93A9bsCQyQgjRGGafZtoA9AEygNXArUqp7cB4YKfJc+zHaKqKrlYeDdT2ZNIDwHKtdfkYtGuUUnnAz0qpB7XWO0xeW7igNYwZA/n5MG8eBJh+tk001Z7397Bh1AbaDG1D///0xx5iqtuZEEIIF8x+FXyJo01BjwLnAFuBccCDZk6gtS4GVgLDqm0ahvFUkythGAlQZeXr8jW2iebOhc8/h3/9yxhXRnjH3n/vJe2GNFqf1poBnw3AHiqJjBBCNIWp7+Ja6wWVlv9SSsVh1NRs01rvr+04F54H3lVKLcfo3Hsr0Al4A0ApNb/sGiPK9v8MeFMpdRvwDcbYNC8Cf2mttzXguqKazEyYONEY4ff2262OpuXY98k+Uq9NpfUprRnw+QDsYZLICCFEU9WbzCilAoHtwFla6/UAWut84K+GXkxrvVApdQzwEEZisg44X2udWbZL12r7z1VKRQITgOeAXOAHjI7HopGcTmOUX62NuZdsUsflFfs/3U/q1am0GtyKAV8OICBC2vWEEMId6v001VqXKKVKqDSuTFNorWcCM2vZNsRF2SsYnYCFm7z+OvzwA8yeDd26WR1Ny3DgywOsv2I9EcdHkPhVIgGRksgIIYS7mP1O/grwQNlM2cKPbdoE990H//wn3Hyz1dG0DAe/Oci6y9YRPiCcxG8SCWgt/42EEMKdzH6qnoYx1sxOpdQ6IK/yRq31/7k7MOF+DgeMGmUMivfWW6BktHyPy/4+m3WXrCO8bzhJ3yUR2CbQ6pCEEKLZMZvM7Ac+9mQgwvOeew5++w3eew86d7Y6muYv+8ds1l60ltCeoSR+l0hgW0lkhBDCE8w+zXSjpwMRnrVuHTz8MFx2GVx3ndXRNH85v+Sw9sK1hHQLIWlJEkHtZI4IIYTwFHmOpQUoKYERI6B1a6PzrzQveVbu77msPW8twV2CSfo+iaAOksgIIYQnmaqZUUqtpY6nmbTWMqOPD5sxA1atgo8/hg4d6t9fNN6h5YdYc+4agmKCSP4hmeCOwVaHJIQQzZ7ZPjMfVVsPBJKBfwCvuTUi4VYrV8Ljj8P11xtNTMJzDq88TMo5KQS2DyTphySCO0kiI4QQ3mC2z8x0V+VKqXuBWLdGJNymsNBoXoqOhpdftjqa5u3w6sOkDEshoE0AyT8kE9IlxOqQhBCixWhqn5lPgOHuCES43yOPQGoqvP02REVZHU3zdWTtEVLOTsEeYSd5aTIhsZLICCGENzU1mTkdyHdHIMK9fv0Vnn3WmBX7n/+0OprmKy81j5SzUrCF2Ehemkxot1CrQxJCiBbHbAfgT6sXYcytdBzgsglKWCcvD0aOhNhYI6ERnpG3IY/VZ65GBSiSf0gmNF4SGSGEsILZDsAHqq07gfXAg1rrb90bkmiqyZNhyxb48UeIjLQ6muYpf1M+KWemAJD0QxJhvcIsjkgIIVouGTSvmVmyBF57De68E844w+pomqeCLQWsHroaXapJXppMeJ9wq0MSQogWzVSfGaVUP6VUjbFklFKJSqkE94clGiM3F266CXr3hieesDqa5qkg3UhknAVOkpYkEd5PEhkhhLCa2Q7As4H+LsoTyrYJH3DXXbBzJ8ybB6HSfcPtCrcVknJmCo4jDpKWJBGRGGF1SEIIITCfzCQCy12U/wkMcF84orE++wzmzIH774cTT7Q6muancEchq4eupiS7hKTvkog8TjojCSGErzDbAdgBtHZRHoXxZJOw0IEDcMstkJhojC0j3KtoVxEpZ6ZQsq8skTlBEhkhhPAlZmtmlgFTlFL28gKlVAAwBfjJE4EJ88aPh4MHYf58CJYR9N2qaHcRq89cTXFWMYlfJ9LqxFZWhySEEKIaszUz9wG/AJuVUr+UlZ0KRGAMnCcssnCh8ZoxA5KSrI6meSneW0zKWSkUbS8i8etEWp/iqnJSCCGE1UzVzGitN2L0m3kfaFv2WgAkaa3TPBeeqMvu3TBuHAweDPfdZ3U0zUvx/mJSzk6hML2QAV8MoM1pbawOSQghRC3M1sygtc7CaFYSPkBro59Mfr7x9FKA6b+kqE/JwRLWDFtDwaYCBnw+gKghMrGVEEL4MrPjzExQSl3vovx6pdQ494cl6jNvHnz+OTz5JPTpY3U0zUdJTgkp56SQl5pH///0J+osSWSEEMLXme0AfCew3UV5BnCX26IRpmzbBhMnGiP83nGH1dE0H6W5paw5dw15a/Lov7g/bc9ta3VIQgghTDDbONEFyHRRvqNsm/ASpxNGjwaHwxhXxtbUec8FAKWHS1lz3hqO/HWEfh/345jzj7E6JCGEECaZvRXuBpJdlB8P7HdfOKI+r79uzL/0/PPQrZvV0TQPpUdKWXv+Wg4tP0TCwgTa/V87q0MSQgjRAGaTmfeBl5VSw5RSgWWvc4AXMZ5qEl6waZPx1NK55xqdf0XjFWUVseqMVRRsLWDdRevI/S2XhPcTaH9Ze6tDE0II0UBmm5mmAt2AbzBGAwYjEfo38LAH4hLVOBwwahQEBcHbb4OScZebJOOxDHJ/yWXV6asoziqm77t96XBVB6vDEkII0QimkhmtdQlwrVLqEY42N63WWm/yWGSiiuefh99+g3ffhc6drY7GvxVlFbFnzh5wQvHOYnq81IPo66KtDksIIUQjNWh0krLkRRIYL1u/Hh56CC69FIYPtzoa/5fxWAbOYqexYof8jfnWBiSEEKJJTCczSqlewBVAVyCo8jat9U1ujkuUKSmBESOgVSt44w1pXmqqoqwidr+1G8pyGRywe85uYh+OJbijTGwlhBD+yOygeRcAa4CLgJuA3sD5wKWAPPrhQU88AX/9BbNmQQfp0tFkW+7Zgi7RVcq0Q5P5mKuRB4QQQvgDs08zPQpM11qfDBQBNwBxwBLgR49EJli5Eh5/3Ghauuwyq6Pxf45CB/sW76tRros1ub/lWhCREEIIdzDbzNQbWFi2XAKEaa0LlVKPAl8Az3siuJassBBGjjRqY155xepomoctd29BF2oGfD6AYy6QQfGEEKK5MJvMHAZCypazgB7AurLjZfIaD5g61ej4++WXECW/4Sbbu2gvu17fxbH3HiuJjBBCNDNmk5n/AacCqRg1Mc8ppZIw+sz87qHYWqzffoNnnjEGxjvvPKuj8X/5m/PZePNGWp3cim4zZNhkIYRobswmM3cDEWXL04BI4HLg77Jtwk3y8ozmpdhYeO45q6Pxf45CB6lXpaICFAkfJmALlMmshBCiuTE7aN7WSsv5wG0ei6iFu/9+2LwZli6FyEiro/F/WyZt4ciqI/T/tD8hXUPqP0AIIYTfka+pPuT77+HVV2HiRBgyxOpo/N/ej/ay67VddLmnC+0ukhEEhBCiuZJkxkfk5sJNN0GvXsbYMqJpCrYUsHH0RiJPjKT7k92tDkcIIYQHNWg6A+E5d98NO3bAr79CWJjV0fg3Z5GT9VetR9kU/Rb2k34yQgjRzEky4wM+/xzeeQceeABOOsnqaPzflnu3cOSvI/T/T39CYqWfjBBCNHdmpzMYoZSqMXGNUipIKTXC/WG1HAcOGI9gJyYaY8uIptn38T52vrKTLnd1od3F0k9GCCFaArP173OA1i7KI8u2iUaaMMFIaObPh2CZ57BJCrYWsGH0BiIHR9L9X9JPRgghWgqzzUwK0C7KuwIyqU0jLVoEH35ozL+UlGR1NP7NWeQk9epUlCobTyZI+skIIURLUWcyo5Rai5HEaGCZUqq00mY7EAt86bnwmq/du2HcOBg0CCZPtjoa/7dl8hYOrzhMv8X9CO0WanU4QgghvKi+mpmPyn72x5jG4EilbcVABvCx+8Nq3rSGsWON0X7nz4cA6YbdJPsW72PnSzvpPLEz7S9pb3U4QgghvKzO26jWejqAUioDWKi1LvRGUM3d/Pnw6afw/PPQp4/V0fi3gvQCNt60kciBkcQ/HW91OEIIISxgqmOB1noegFLqCqXUZKVUm7L1eKVUW08G2Nxs2wZ33AGnn26M9Csaz1ls9JPRWpOwUPrJCCFES2WqgUMp1QNYgjHZZBvg30AOxhxNbYCbPRVgc+J0wujR4HDAnDlgk3tvk2y9fyuH/zxMv4/7Edpd+skIIURLZfZ2+iLwLRANFFQq/xQY2pALKqXGKaXSlVKFSqmVSqnT6th3rlJKu3jlNeSavuKNN2DJEmM27O7y5HCT7P/vfna8sIPOt3em/WXST0YIIVoys8nMKcCzWmtHtfJtQCezF1NKXQ28BDwBHAf8BnyllOpayyETgZhqr63AIrPX9BWbN8O998I558CYMVZH498KMgrYMGoDESdEEP+M9JMRQoiWriENHYEuyho6zszdwFyt9Zta6zSt9e1AFkZzVQ1a61yt9e7yFxAPdAfebMA1LedwwKhREBgIb78NSlkdkf9yFjtJvSYV7dTGvEvB0lYnhBAtndk7wbcYiUg5rZRqBUzHeGS7XkqpIOCEsnNVP/cpJuO4BVivtf7N5P4+4YUXjAkkX3kFunSxOhr/tvXBrRz+32F6v92b0HjpJyOEEMJ8MnM3cKpSaiMQAizEGGOmI3C/yXO0wxhob0+18j1l56mTUqo1cBV11MoopcYopVYopVbs27fPZFietX49TJkCl1wC119vdTT+bf+n+9nx3A46je9Ehys6WB2OEEIIH2HqaSat9S6lVDJwLXA8RhI0G1igtS6o82D3ub7suu/WtoPWenZZXAwcONDV9AteVVICI0dCq1ZG519pXmq8wsxCo5/McRHEPyv9ZIQQQhxleuzZsqTlnbJXY+wHHBhPRFUWDew2cfwtwMda64ONvL7XPfkkrFwJ//43RFd/18I0Z0lZP5lSTcKiBOwhdqtDEkII4UNMNTMppa5SSp1Taf0RpdQOpdQ3SqkYM+fQWhcDK4Fh1TYNw3iqqa7rDwaS8KOOv3/9BY89BtddB1dcYXU0/i39wXQO/XGI3m/1JqxHmNXhCCGE8DFm+8xMK19QSh0PPAi8jPGE03MNuN7zwCil1M1Kqb5KqZcwHu1+o+zc85VS810cNwbYpLX+sQHXskxREYwYAe3bG51+RePt/3w/25/dTqfbOtHhKuknI4QQoiazzUyxwMay5UuB/2itn1ZKfQt8Y/ZiWuuFSqljgIcwxoxZB5yvtc4s26XGeDNKqUjgGuBRs9ex2tSpRsffL76AtjLZQ6MVbi9kw8gNRCRHEP+89JMRQgjhmtlkphCILFs+i6P9ZnIrlZuitZ4JzKxl2xAXZYcxplHwC7/9Bs88AzffDOefb3U0/quin0yx9JMRQghRN7PJzM/Ac0qpX4CBQHkvkF7Adk8E5o/y8oynl4491piyQDRe+kPpHPrtEH0/6EtYT+knI4QQonZm+8xMAIoxkphbtda7ysrPowHNTM3dAw8Y0xbMmWM8ji0a58CXB9j+9HZixsYQfY08BiaEEKJuZseZ2QFc5KL8TrdH5Kd++MHo7HvHHTC0QVNvisoKdxSSNiKN8KRwerzQw+pwhBBC+AGZ2MYNDh2CG2+Enj2NsWVE4zhLy/rJFGn6LeqHPVT6yQghhKif6UHzRO3uvht27IBffoEw6d7RaBkPZ3Do10P0fb8vYb3kFymEEMIcqZlpoi++MGbCvu8+OPlkq6PxXwe+PsC2f20j5pYYoq+VfjJCCCHMk2SmCQ4cMB7B7t8fpk2zOhr/VbSziA03bCB8QDg9XpJ+MkIIIRrG7HQGI5RSwS7Kg5RSI9wfln+4/XbYvx/mz4fgGr8dYYaz1Enqtak4Chz0+7f0kxFCCNFwZmtm5gCtXZRHlm1rcf79b/jgA2O03+OOszoa/5UxNYPcn3PpPas3Yb2ln4wQQoiGM9sBWAHaRXlXjFGAW5RJk2DuXBg0CO6/3+po/NfBbw6y7cltdBzdkejh0k9GCCFE49SZzCil1mIkMRpYppQqrbTZjjFn05eeC8/3aG2M7hscDPPmQYA8D9YoRbuKSLshjfB+4fR8uafV4QghhPBj9d2KPyr72R/4AjhSaVsxkAF87P6wfNf8sjm9n3gC+va1NhZ/5Sx1knpdKo48hzHvUpj0kxFCCNF4dSYzWuvpAEqpDOBDrXWRN4LyRdOmwfTpR9fvucd4TZ0qTzI1VOb0THKX5dJnXh/C+4ZbHY4QQgg/p7R21RWm2k5KtQfQWu8rWx8AXA2s11p/4NEIG2ngwIF6xYoVHjm3UkZzk2i4g98dZM25a+g4qiN93uljdThCCCH8iFJqpdZ6YPVys08zLaJsbialVDvgJ+BS4A2l1D1ui1I0a0VZRaQNTyMsIYyer0o/GSGEEO5hNplJBP4oW74C2Ky17geMAMZ6IjBfNnWq1RH4H+3QpF2XhiPPYcy7JP1khBBCuInZZ3FCOdr592zg07Llv4Bj3R2Ur5M+Mg2X8WgGOT/m0GduH8ITpJ+MEEII9zFbM7MJuEwpdSxwDvBtWXk0kOOJwETzkf19NpmPZRI9MpqOIztaHY4QQohmxmwyMx14CuNR7D+01v8rKz8XWOWBuEQzUbS7iNThqYT1CaPXa72sDkcIIUQzZKqZSWv9iVKqK9AJSKm0aQktbJwZYV5FP5lDDpK/T8YeLv1khBBCuJ/p8Wu11nuAPUqpaKXUPq21s1INjRA1ZD6eSc7SHHq/05vwftJPRrRcTqeT/fv3k5OTg8PhsDocIXyS3W6nTZs2tGvXDpvNbMORwVQyo5QKBGYAt2F0Bu4FbFVKPQVkaq1nNjBm0cxl/5BNxvQMom+IpuMo6ScjWrYdO3aglCIuLo7AwECUUlaHJIRP0VpTUlLCnj172LFjB127dm3Q8WZTn6kY48xcD1QeBXg5MKpBVxTNXtHuIlKvSyWsdxg9Z/aUD27R4uXl5dG5c2eCgoLk/4MQLiilCAoKonPnzuTl5TX4eLPNTNcCN2mtlymlnJXK12HU0ggBlPWTuT4NR66DpO+SCIiQmTiFABpcbS5ES9TY/ydm7zSdgMxajpe7laiQ+UQmOd/n0Put3kQMiLA6HCGEEC2A2RRoPXC6i/KrgJXuC0f4s+wfs8mYlkGH4R3oeJP0kxFCQFxcHM8++2yDjlFK8dFHH7k1jmnTptG/f3+3nrMpIiIimDt3run9586dS0SEfEGsTZ21Kkqpd4CJGOPMvFc2aJ4duFIp1Qe4DrjA41EKn1e8p5i0a9MI7RlKrzd6Sb8AIZqJnTt3Mn36dL788kv27t1L+/btOf/885k6dSpdunSp9/g///yT8PCGPc2YlZVFVFRUY0MWLVB9NTMjgVCt9WcYtTDnAE6MDsE9gYu01ks8G6LwddqpSbshjdKcUvot6if9ZIRoJtLT0xk4cCDr1q1j3rx5bN68mffee4/169czaNAgMjIyaj22uLgYgPbt2xMWFtag63bs2JHg4OCmhC5amPqSmYqv11rrb7TWZ2itI7TWYVrrU7XW39Z1sGgZtj25jezvsunxcg8iEqUaVAhPWbBgAXFxcdhsNuLi4liwYIFHrzd+/HhsNhtLlizhrLPOomvXrgwdOpQlS5Zgs9kYP358xb5DhgzhtttuY9KkSbRv355//OMfQM1mpr///pszzjiDkJAQevfuzZdfflmjyaVyM1NGRgZKKT7++GOGDRtGWFgYCQkJfPfddxX7OxwORo8eTbdu3QgNDaVnz548/fTTOJ2Vn1epW/l1PvzwQ8444wxCQ0M57rjjWLNmDevWreOUU04hPDycU089lfT09CrHzpo1ix49ehAUFESPHj148803q2zfvHkzQ4YMqXjPn3/+eY3r79y5k2uuuYaoqCiioqK44IIL2LRpU63xbt++nYsvvpi2bdsSFhZGnz59+PDDD02/3+bGTJ8Z7fEohN/KWZZD+iPpdLi2AzE3x1gdjhDN1oIFCxgzZgyZmZlorcnMzGTMmDEeS2gOHjzI119/zfjx42vUrISFhTFu3Di++uorsrOzK8rfe+89tNb8/PPPzJ8/v8Y5nU4nl156KQEBAfzxxx/MnTuX6dOnU1RUVGPf6qZMmcIdd9xBSkoKgwYN4pprruHIkSMV5+3cuTOLFi0iLS2NGTNm8MQTTzBnzpwGv++pU6cyefJkVq1aRZs2bbj22mu5/fbbmTFjBsuXL6ewsJA77rijYv/FixczYcIE7rzzTtatW8fEiRMZN24cn332WZX37HQ6+f3333nnnXeYNm1alfecn5/P0KFDCQkJYdmyZfz+++/ExMRw9tlnk5+f7zLOcePGkZ+fz9KlS1m/fj0vvvgibdq0afD7bS7MtAfsrq//g9ZaxqlvgYr3FpN6XSqh8aH0miX9ZIRoiDvvvJPVq1eb3v+PP/6ocdPPz89n9OjRNWoCapOcnMyLL75oat9NmzahtaZv374utyckJKC1ZtOmTQwePBiAbt268dxzz9V6zu+++46NGzfy7bff0rlzZwBeeOGFilqcutx1111cdNFFADzxxBPMnz+f1atXc+qppxIYGMijjz5asW9cXBx//fUXH3zwAaNHjzb1fsvdfffdnH/++QDcc889XHTRRTz22GMMHToUgAkTJjBhwoSK/Z999lluuOGGirJevXqxcuVKnnrqKS666CKWLFlCamoq6enpFQPBvfjii5x22mkV5/jwww/RWjNnzpyKz9FZs2bRoUMHPv/8c6666qoacWZmZnL55ZeTlJQEGL/7lsxMMjMGmRlbVFPeT6bkQAmJXyYSECn9ZITwpNpqL8zUanjLCSecUOf2DRs20KlTp4pEBmDQoEGmxhZJTEysWO7UqRMAe/furSh74403eOutt8jMzKSgoICSkhJiY2Mb+haqXCc6OhqAAQMGVCnLy8sjPz+fsLAw0tLSuOmmm6qc49RTT+XTTz8FIC0tjc6dO1cZ0fbEE0+s8p5XrlxJeno6kZGRVc6Tn5/Pli1bXMY5ceJEbr31Vr7++mvOOussLr300np//82ZmTvQZ1rrvfXvJlqSbU9tI/vbbHq90YuIJOknI0RDma0hKRcXF0dmZs3hvmJjY/nxxx/dFNVRPXr0QClFamoql156aY3tqampKKXo0aNHRVlDn1pqiMDAwIrl8tqL8j4xCxcu5M477+TZZ5/llFNOoVWrVrz22mssXrzYLdep69q1aUhNtdPpJDk52WWfl7Zt27o8ZvTo0Zx77rl8+eWXLFmyhFNOOYUHHniAadOmmb5uc1JfOiz9ZUQNOT/nkP5QOh2u6UDMGOknI4Q3zJgxw2XflRkzZnjkescccwznnnsuM2fOrNFvIz8/n9dee43zzjuv1putK3369GHXrl3s2rWromzFihUN6qjryi+//MKJJ57IhAkTOP744+nRo0etNRru1rdvX3799dca8SQkJFRs37lzJ9u3b6/Yvnz58irv+fjjj2fz5s20a9eOHj16VHnV9fvt0qULY8aMYdGiRTz66KPMnj3bze/Of5h+mkkIgOJ9xaRem0pod+knI4Q3DR8+nNmzZxMbG4tSitjYWGbPns3w4cM9ds1XX32V0tJSzj77bH744Qe2b9/Ojz/+yLBhw9Ba8+qrrzbofMOGDaN3796MHDmSlJQU/vjjD+6++24CAgKa9FnSq1cv/vrrL7766is2bdrEY489xrJlyxp9voa49957effdd3nttdfYtGkTr7zyCgsWLOC+++4D4Oyzz6ZPnz6MGDGC1atX8/vvv3PXXXcREHC0YWT48OFER0dz8cUXs2zZMtLT0/npp5+45557an2iaeLEiXz99ddsx/vuiQAAIABJREFU3bqV1atX8/XXX1ckUC1RncmM1tomTUyinHZqNozYQMn+EhIWJRDQSvrJCOFNw4cPJyMjA6fTSUZGhkcTGYD4+HhWrFhBv379uOGGG+jevTvXXXcdffv25c8//2xwp1ObzcbixYspKipi8ODBjBw5kilTpqCUIiQkpNFxjh07lquuuorrrruuYvybe+65p9Hna4hLLrmEV155hRdeeIGEhAReeuklZs6cWdFZufw9O51OTjzxREaMGMFDDz1UZRydsLAwfvrpJ7p3786VV15Jnz59GDlyJNnZ2bUOHuh0Orn99ttJSEhg2LBhREdHM2/ePK+8Z1+ktG6eLUkDBw7UK1assDqMZmXbU9vYev9Wes7sSefbOtd/gBACMDqB1vZUUEuXkpJCcnIyK1asaNEdWMVRdf1/UUqt1FoPrF4uX62FKTm/5LB1ylbaX9WeTrd2sjocIYSfWrx4MeHh4fTs2ZOMjAzuvvtukpKSOP74460OTfgxSWZEvYr3G/MuhcSF0PvN3tJPRgjRaIcPH2by5Mls376dqKgohgwZwgsvvCCfK6JJJJkRddJOzYaRGyjeW8zxvx8v/WSEEE0yYsQIRowYYXUYopmRO5Oo0/bntnPwy4P0fLUnkcdH1n+AEEII4WVm5mYSLVTub7lsfWAr7a9oT6dx0k9GCCGEb5JkRrhUcqCE1GtSCYkNofdb0k9GCCGE75JmJlGDdmrSRqZRvKeY4387noDW8s9ECCGE75K7lKhh+/PbOfjFQXq83IPIE6SfjBBCCN8mzUyiitzfc0l/IJ12l7Wj8wQZGE8IIYTvk2RGVCg5aPSTCT42mN5vSz8ZIYS1hgwZwoQJE6wOwzLTpk2jf//+VofhFySZEQBordkwagPFWcUkLEwgsE1g/QcJIZq1UaNGoZRCKUVgYCDdu3dn0qRJ5OXleeX6n3zyCU8++aRXruWLJk2aVGXCzFGjRnHhhRd65Foff/wxCQkJBAcHk5CQwOLFi+s9ZtGiRSQnJxMWFkZsbCzPPPOMR2IzQ5IZAcCOF3Zw4LMDxD8TT6tBrawORwjhI84++2yysrLYunUrjz/+ODNnzvz/9u49rqoqb/z4ZyEXkUOmwIjACKKIYiIiauiEiCg2aanzeGW8jILZqOkg5aOTI1qGlub1MSd9wMzw9lN6CsfSB9HCG5GJI+rxkrfiQNLTGKIiwvr9cY5nONwh4Aiu9+u1X7LXXmvv796bw16u/d1nEx0dXW7dhw8fUpfv+2vdujX29k0zb+/BgwdV1tFoNDg4ONR7LMePH2fMmDGEh4dz+vRpwsPDGTVqFCdPnqywzf79+xk/fjzTpk3j7NmzbNiwgVWrVtX4Tep1RkrZoBPwZ+AqcB/4BniuivrWwBJDmwLgBvBqVdvp2bOnVKrn9onb8rDlYfnP4f+UxcXF5g5HUZqcc+fO/fqVLF8u5aFDpmWHDunL68mkSZPkCy+8YFIWEREhnZ2dpZRSLlq0SHbt2lXGx8dLT09PaWFhIfPy8mT//v3ljBkzKl1X//795SuvvCLnz58vHRwcpJOTk5w7d64sKioyqVNyPe7u7vLNN9+U06ZNk/b29tLV1VW+8847JtvRarUyKChI2tjYyE6dOsl9+/ZJOzs7GR8fX+F+njlzRoaEhEh7e3tpZ2cnfX195SHDsU5JSZGA/Oyzz2T37t2ljY2N9Pf3l+np6cb2ubm5cuzYsdLV1VU2b95c+vj4yLi4OJNt9O/fX06fPl3OnTtXOjo6yoCAACmllBs3bpReXl7SxsZGOjg4yMGDB8vCwkKT4/voZ8BkSklJkQMGDChzrG/fvi1tbW3lnj17KtznkkaPHi1DQ0NNygYOHCjHjh1bYZtx48bJ4cOHm5StXbtWurm5/errSGWfFyBdlnPNb9CRGSHEGGAN8DbQAzgG7BdCtKuk2Q5gCDAN8AZGAWfqOdQnRuHPhWSOycTGzQbvOJUnoyiPrV69YPRoSEnRz6ek6Od79WrQMGxtbSksLDTOX716lYSEBHbv3k1GRgbNmzev9ro+/vhjLC0tOXbsGOvXr2f16tXs3Lmz0jarVq2iW7dunDp1innz5vH6669z/PhxAIqLixkxYgSWlpacOHGCLVu2sHjxYgoKCipd5/jx42nbti1paWmcPn2amJiYMvsRHR3N8uXLSU9Px9PTk6FDh3L37l0A7t+/j7+/P0lJSWRmZjJ79mxefvllkpOTTdaxbds2pJR89dVXbN26lfT0dGbMmMGiRYvQarUkJyczZMiQcmOMjo5m9OjRxpEynU5H3759iYyMJCEhwWQft2/fjkajYdiwYcTExFT5d/348eMMHjzYpCwsLIxjx45V2KagoKDMMbK1teX777/n+vXrlW6vPjT0o9lRwBYp5SbD/CwhxBDgFWB+6cpCiMHAQKCDlDLXUHytIQJ9EkgpufCnCzzIekCP1B5YtVJ5MorSYObMgdOna9bGxQXCwqBtW9DpoEsXWLxYP1WHnx+sXl3zWA3S0tJISEhg4MCBxrIHDx7w0Ucf0aZNmxqvz8fHhyVLlgDQqVMnNm3aRHJyMuPGjauwzeDBg41JwbNmzWLt2rUkJycTGBjIwYMH0Wq1HDhwAFdX/dOYq1atol+/fpXGcf36daKjo+ncuTMAHTt2LFNn4cKFhIWFARAfH4+bmxsJCQlERETg6urKa6+9Zqw7bdo0Dh06xPbt202OVfv27Vm5cqVxfu/evdjZ2fHiiy9ib2+Pu7s73bt3LzdGjUaDra0tNjY2ODs7G8tHjhzJrFmzSExMZOzYsQDExcUxceJErKyscHR0xNvbu9L9z87OLnP+2rRpQ3Z2doVtwsLCmDNnDgcOHCA0NJTLly8b902n0+Hh4VHpNutag43MCCGsgZ7AgVKLDgB9K2g2HPgaiBJCfC+EuCSEWCuE0NRjqE+M79d8z0//8xOeyz15qrfKk1GUx16rVvqOzI0b+n9btar3TX7++edoNBqaN29OYGAgQUFBrFu3zrjczc2tVh0ZAF9fX5N5FxcXfvzxx1q3uXDhAi4uLsaODECvXr2wsKj8UhcVFUVERAQhISEsXbqUCxculKkTGBho/Fmj0dCtWzfOnTsHQFFREUuXLsXX1xcHBwc0Gg179+7lxo0bJuvo2bOnyfygQYNwd3enffv2hIeH8+GHH5KXl1dprKXZ2NgwYcIE4uLiAMjMzCQtLY2pU6cCMHPmzHL359eKjIxk1qxZvPTSS1hbW/Pss88aO1NVHe/60JAjM45AMyCnVHkOEFpBG0/gd+hzZf4APA2sA1yA/6ifMJ8Mv6T9wnevf4fDiw64zXEzdziK8uSpzQjJo1tLCxfC++/DokUwYEDdx1ZCUFAQH3zwAVZWVri4uGBlZTqCa2dnV6aNhYVFmUTgkremHim9LiEExcXFlcZTmzZViYmJITw8nP379/PFF1+wePFiNm7cyJQpU6rVfsWKFaxcuZI1a9bQrVs3NBoNCxYsKNMxK32s7O3tOXXqFF9++SUHDx4kNjaWBQsW8PXXX+PiUv334UVERODr68uNGzeIi4sjMDCQLl26VLu9s7MzOTmml+acnByTEaDShBAsX76ct99+m+zsbJycnIy31Tw9Pau97bryuD/NZIE+0Wm8lPKklPILYCbwByFEmf8KCCGmCSHShRDpt27dauhYG43CfxVybsw5rNta0zm+s8qTUZTG4FFHZtcuWLJE/2/JHJp60qJFCzp27Ii7u3uZjkRFnJyc0Ol0JmUZGRn1EZ6Jzp07k5WVRVZWlrEsPT29Wp0dLy8vXn31Vfbt28fUqVPZvHmzyfITJ04Yf87Pz+fs2bPGDkNqairDhg1jwoQJ+Pn50aFDBy5evFitmC0tLQkJCSE2NpYzZ86Qn59PUlJSuXWtra0pKioqU961a1f69OnDpk2b2LZtW7U7YY88ukVX0sGDB+nbt6KbJv/WrFkzXF1dsba2Zvv27QQGBuLk5FSj7deFhuzM5AJFQOlOSBugohtzOuAHKeXtEmXnDf+WSRqWUn4gpQyQUgaY42A2BlJKtFO0FHxfoP8+mdYqT0ZRGoWvv9Z3YB6NxAwYoJ//+mvzxlWOkJAQ9u/fz6effopWqyUqKoqbN2/W+3YHDRqEt7c3kyZNIiMjgxMnThAVFYWlpWWF/2m7d+8eM2bM4PDhw1y7do2TJ0+SmpqKj4+PSb233nqLgwcPkpmZyZQpU7C2tmb8+PGAPt8nOTmZ1NRULly4wMyZM7l69WqV8SYlJbFmzRq+/fZbrl+/TkJCAnl5eRWOqnh4eHD27Fm0Wi25ubkmo12RkZG888475OfnM2bMGGP5+vXrjblAFZk9ezaHDh1i2bJlXLhwgdjYWFJSUpgzZ46xzvz5803yf3Jzc3n//fc5f/48p0+fZvbs2ezevZvVvyIn69dosM6MlPIB+kexB5VaNAj9U03lOQq4lMqR6WT4t+HTpZuAH9b9QG5iLp7LPGn5bEtzh6MoSnW9/nrZW0oDBujLHzNTpkwxTv369cPe3p4RI0bU+3YtLCxITEykoKCA3r17M2nSJP76178ihKjwKatmzZrx888/M3nyZLy9vRkxYgSBgYG89957JvWWLVvG3Llz8ff359KlSyQlJRlvG73xxhv07t2b559/nqCgIOzs7AgPD68y3qeffppPPvmE0NBQOnfuzIoVK9i8eTPPPfdcufUjIyPp0qULAQEBODk5cfToUeOyMWPGYG1tzejRo02+myc3NxetVltpHH379mXHjh1s2bIFX19ftm7dys6dO+nTp4+xjk6n48qVKybttm7dSq9evejXrx+ZmZkcPnyY3r17V7nf9UGUvq9ZrxvTP5r9EfrvmjkKTAemAl2llNeFEFsBpJQTDfU16EdiTgAx6HNm/g6cl1KOqmxbAQEBMj09vZ72pHH6Jf0Xvu37La2HtOaZ/3lG3V5SlAZy/vz5GuUwKHUnIyMDPz8/0tPTyyTgVsfhw4cZMGAAt27dwtHRsR4irBtZWVm0a9eOI0eOVPn01uOuss+LEOIbKWVA6fIGfTRbSrlTCOEAvAG0Bc4Cv5dSPhplaVeq/h0hRCj6pN+vgZ+BT4D/bLiom4bCfxVybvQ5rJ2t6bxF5ckoitI0JSYmYmdnh5eXF9euXSMqKoru3bvj7+9v7tDqRWFhIT/99BMLFiygR48ejb4jU1sN/T0zSCk3ABsqWBZcTpkWGFy2tlJdUkq0EVoKbhbg96WfypNRFKXJysvLY968edy8eZNWrVoRHBzMqlWrmux/4I4ePcqAAQPw8vJi165d5g7HbBq8M6M0vB/+6wdy9+Ti+Y4nLQNVnoyiKE3XxIkTmThxYp2tLzg4uE7fN1XXHvf4Gsrj/mi28ivlfZPHlblXaP1Ca34797fmDkdRFEVR6pzqzDRhD28/JHN0Jta/sabLh10QFk1zmFVRFEV5sqnbTE2UlBJtpJb71+/T48seWDmoPBlFURSlaVKdmSYq6/0sbu2+hedyT1r2VXkyiqIoStOlbjM1QXnf5nH5L5dp/Xxrfhut8mQURVGUpk11ZpqYh788JHNUJlZOVnTe2lnlySiKoihNnurMNCFSSrTTtNy/dh+fHT5YO1qbOyRFUZRaCw4OZubMmeYOw2xiYmJ45plnzB1Go6A6M01I1t+zuLXzFu3fas/Tv3va3OEoitLITZ48GSEEQgisrKzw9PQkOjqa/Pz8Btn+3r17iY2NbZBtPY6io6M5cuSIcX7y5MkMHTq0Xra1Z88efHx8sLGxwcfHh8TExCrb7Nq1Cz8/P1q0aIG7uzvvvvuuyfLDhw8bf39KThcuXKjz+FUCcBORdzqPy3Mu03pIa9q9XuaF4oqiKLUSGhrKRx99RGFhIV999RURERHk5+fz/vvvl6n78OFDmjVrVmffttu6des6Wc/j6MGDB1hbVz56rtFo0Gg0ldapC8ePH2fMmDEsXryYkSNHsnfvXkaNGsXRo0dNXjZZ0v79+xk/fjxr165lyJAhnD9/nsjISGxtbcuMpmVmZpqcSycnp7rfCSllk5x69uwpnxSFtwvlCa8T8qjLUVnwY4G5w1EUpZRz58796nX4bfSTxFBm8tvoVwcRlm/SpEnyhRdeMCmLiIiQzs7OUkopFy1aJLt27Srj4+Olp6entLCwkHl5ebJ///5yxowZla6rf//+8pVXXpHz58+XDg4O0snJSc6dO1cWFRWZ1Cm5Hnd3d/nmm2/KadOmSXt7e+nq6irfeecdk+1otVoZFBQkbWxsZKdOneS+ffuknZ2djI+Pr3A/z5w5I0NCQqS9vb20s7OTvr6+8tChQ1JKKVNSUiQgP/vsM9m9e3dpY2Mj/f39ZXp6urF9bm6uHDt2rHR1dZXNmzeXPj4+Mi4uzmQb/fv3l9OnT5dz586Vjo6OMiAgQEop5caNG6WXl5e0sbGRDg4OcvDgwbKwsNDk+D76GTCZUlJS5IABA8oc69u3b0tbW1u5Z8+eCve5pNGjR8vQ0FCTsoEDB8qxY8dW2GbcuHFy+PDhJmVr166Vbm5usri42OTY3bp1q1pxPFLZ5wVIl+Vc89VtpkZOSsnFly9y78o9fLb7YO2k8mQUpSkKdAvEupnp59u6mTV93fo2aBy2trYUFhYa569evUpCQgK7d+8mIyOD5s2bV3tdH3/8MZaWlhw7doz169ezevVqdu7cWWmbVatW0a1bN06dOsW8efN4/fXXOX78OADFxcWMGDECS0tLTpw4wZYtW1i8eDEFBQWVrnP8+PG0bduWtLQ0Tp8+TUxMTJn9iI6OZvny5aSnp+Pp6cnQoUO5e/cuAPfv38ff35+kpCQyMzOZPXs2L7/8MsnJySbr2LZtG1JKvvrqK7Zu3Up6ejozZsxg0aJFaLVakpOTGTJkSLkxRkdHM3r0aEJDQ9HpdOh0Ovr27UtkZCQJCQkm+7h9+3Y0Gg3Dhg0jJiamypGy48ePM3iw6SsQw8LCOHbsWIVtCgoKyhwjW1tbvv/+e65fv25SHhAQQNu2bRk4cCApKSmVxlJb6jZTI6fbpOPHHT/Sfml7ng5SeTKK0ljM+XwOp7NPV7t+wcMCHhY/NCl7WPyQb7O/JXhLcLXW4efsx+ohq2sSpom0tDQSEhIYOHCgsezBgwd89NFHtGnTpsbr8/HxYcmSJQB06tSJTZs2kZyczLhx4ypsM3jwYONtjFmzZrF27VqSk5MJDAzk4MGDaLVaDhw4gKurK6Dv/FT1Junr168THR1N586dAejYsWOZOgsXLiQsLAyA+Ph43NzcSEhIICIiAldXV1577TVj3WnTpnHo0CG2b99ucqzat2/PypUrjfN79+7Fzs6OF198EXt7e9zd3enevXu5MWo0GmxtbbGxscHZ2dlYPnLkSGbNmkViYiJjx44FIC4ujokTJ2JlZYWjoyPe3t6V7n92dnaZ89emTRuys7MrbBMWFsacOXM4cOAAoaGhXL582bhvOp0ODw8P2rZty/vvv0+vXr2MvycDBw7kyJEjPPfcc5XGVFNqZKYRu5Nxh0uvXqLV4Fa0+0+VJ6MoTZmNpQ1t7Nog0P8vWyBwtnMuM1pT1z7//HM0Gg3NmzcnMDCQoKAg1q1bZ1zu5uZWq44MgK+vr8m8i4sLP/74Y63bXLhwARcXF2NHBqBXr15YWFR+qYuKiiIiIoKQkBCWLl1aboJqYGCg8WeNRkO3bt04d+4cAEVFRSxduhRfX18cHBzQaDTs3buXGzdumKyjZ8+eJvODBg3C3d2d9u3bEx4ezocffkheXl6lsZZmY2PDhAkTiIuLA/T5KWlpaUydOhWAmTNn1kvCbWRkJLNmzeKll17C2tqaZ5991tiZenS8vb29mT59Oj179iQwMJANGzYwZMiQMonCdUGNzDRSD/P0712yam1Fl4/Ue5cUpbGpzQiJLk+H51pP7j+8T3PL5nzz8jc4a5yrbvgrBAUF8cEHH2BlZYWLiwtWVqavRrGzsyvTxsLCosybnEvemnqk9LqEEBQXF1caT23aVCUmJobw8HD279/PF198weLFi9m4cSNTpkypVvsVK1awcuVK1qxZQ7du3dBoNCxYsKBMx6z0sbK3t+fUqVN8+eWXHDx4kNjYWBYsWMDXX3+Ni4tLteOPiIjA19eXGzduEBcXR2BgIF26dKl2e2dnZ3JyckzKcnJyTEaAShNCsHz5ct5++22ys7NxcnIy3lbz9PSssF2fPn3YsWNHtWOrLjUy0whJKbk4/SL3LhvyZH6j8mQU5UnQ1r4tf/L7ExbCgj/5/aneOzIALVq0oGPHjri7u5fpSFTEyckJnU5nUpaRkVEf4Zno3LkzWVlZZGVlGcvS09Or1dnx8vLi1VdfZd++fUydOpXNmzebLD9x4oTx5/z8fM6ePWvsMKSmpjJs2DAmTJiAn58fHTp04OLFi9WK2dLSkpCQEGJjYzlz5gz5+fkkJSWVW9fa2pqioqIy5V27dqVPnz5s2rSJbdu2VbsT9sijW3QlHTx4kL59q87HatasGa6urlhbW7N9+3YCAwMrfVrp9OnTtG3btkbxVYcamWmEdP+t48eEH/F404On+6s8GUV5kiwMWkjmrUwW9l9o7lAqFBISwpw5c/j000/x9vbm73//Ozdv3sTDw6Netzto0CC8vb2ZNGkSK1as4N69e0RFRWFpaVlhEuy9e/eIjo5m1KhReHh4kJOTQ2pqaplHkt966y2cnJxwcXFhyZIlWFtbM378eECf77Nz505SU1NxdHRk3bp1XL16lR49elQab1JSEleuXCEoKIjWrVuTkpJCXl5ehaMqHh4e7N+/H61Wi4ODAy1btjR2MCMjI5k+fTpWVlaMGTPG2Gb9+vWsX7++0ltNs2fPJigoiGXLljF8+HASExNJSUkhNTXVWGf+/PmkpaUZR19yc3PZvXs3wcHBFBQUEB8fz+7du02+F2f16tV4eHjQtWtXHjx4wLZt2/jkk0/Ys2dPpcelNtTITCNz58wdLs+6TKvQVrjPdzd3OIqiNLC29m05MvlIg4zK1NaUKVOMU79+/bC3t2fEiBH1vl0LCwsSExMpKCigd+/eTJo0ib/+9a8IISp8yqpZs2b8/PPPTJ48GW9vb0aMGEFgYCDvvfeeSb1ly5Yxd+5c/P39uXTpEklJScbbRm+88Qa9e/fm+eefJygoCDs7O8LDw6uM9+mnn+aTTz4hNDSUzp07s2LFCjZv3lxhcmxkZCRdunQhICAAJycnjh49alw2ZswYrK2tGT16NPb29sby3NxctFptpXH07duXHTt2sGXLFnx9fdm6dSs7d+406dDpdDquXLli0m7r1q306tWLfv36kZmZyeHDh+ndu7dx+YMHD3jttdfw9fXlueeeIzU1lX379jFy5Mgqj01NidL3NZuKgIAAmZ6ebu4w6tTDOw/5JuAbim4XEXA6AOs26vaSojQG58+fr1EOg1J3MjIy8PPzIz09vUwCbnUcPnyYAQMGcOvWLRwdHeshwrqRlZVFu3btOHLkSJVPbz3uKvu8CCG+kVIGlC5Xt5kaCSkll165xL1L9+j+v91VR0ZRFKUciYmJ2NnZ4eXlxbVr14iKiqJ79+74+/ubO7R6UVhYyE8//cSCBQvo0aNHo+/I1JbqzDQS2fHZ5GzLwWOxB60GtDJ3OIqiKI+lvLw85s2bx82bN2nVqhXBwcGsWrWqzl6x8Lg5evQoAwYMwMvLi127dpk7HLNRt5kagTtn73Cq9ymeCnyK7ge6I5o1zQ+lojRV6jaTolRfbW4zqQTgx9zDOw85N+oczZ5qRpePu6iOjKIoiqKUom4zPeYuzbjEXe1duh/sjo2zjbnDURRFUZTHjhqZeYzptujI2ZqD+9/caTVQ5ckoiqIoSnlUZ+YxlZ+Zz6U/X+LpAU/jsdDD3OEoiqIoymNLdWYeQ0X5RWSOzqSZvcqTURRFUZSqqJyZx9ClmZe4e/4uvgd8sWmr8mQURVEUpTJqZOYxk/1hNtlbsnF/w53Woa3NHY6iKIrZBAcHM3PmTHOHYTYxMTE888wz5g6jUVCdmcdI/rl8Lv75Ii37t8RjkYe5w1EU5Qk3efJkhBAIIbCyssLT05Po6Gjy8/MbZPt79+4lNja2Qbb1OIqOjjZ5cePkyZMZOnRovWxrz549+Pj4YGNjg4+PD4mJiVW22bVrF35+frRo0QJ3d3feffddk+Ulf39KTo/eaVWXVGfmMVF015AnY9cMnwQflSejKMpjITQ0FJ1Ox3fffcdbb73Fhg0biI6OLrfuw4cPqcsvYm3durXJSxObkgcPHlRZR6PR4ODgUO+xHD9+nDFjxhAeHs7p06cJDw9n1KhRnDx5ssI2+/fvZ/z48UybNo2zZ8+yYcMGVq1axfr164111qxZg06nM5k8PT0ZPXp03e+ElLJJTj179pSNyfkp52WKSJE/ffGTuUNRFKWOnTt3rk7Xt2hRna6uQpMmTZIvvPCCSVlERIR0dnY2xLFIdu3aVcbHx0tPT09pYWEh8/LyZP/+/eWMGTMqXVf//v3lK6+8IufPny8dHBykk5OTnDt3riwqKjKpU3I97u7u8s0335TTpk2T9vb20tXVVb7zzjsm29FqtTIoKEja2NjITp06yX379kk7OzsZHx9f4X6eOXNGhoSESHt7e2lnZyd9fX3loUOHpJRSpqSkSEB+9tlnsnv37tLGxkb6+/vL9PR0Y/vc3Fw5duxY6erqKps3by59fHxkXFycyTb69+8vp0+fLufOnSsdHR1lQECAlFLKjRs3Si8vL2ljYyMdHBzk4MGDZWFhocnxffQzYDKlpKTIAQMGlDnWt2/flra2tnLPnj0V7nNJo0ePlqGhoSZlAwcOlGPHjq2wzbhx4+Tw4cNNytauXSvd3NxkcXFxuW1SU1MlII8ePVppPJV9XoB0Wc41X43MPAayP8omOy6bdgva0XqwypNRFKWsGY1gAAAgAElEQVRyixebb9u2trYUFhYa569evUpCQgK7d+8mIyOD5s2bV3tdH3/8MZaWlhw7doz169ezevVqdu7cWWmbVatW0a1bN06dOsW8efN4/fXXOX78OADFxcWMGDECS0tLTpw4wZYtW1i8eDEFBQWVrnP8+PG0bduWtLQ0Tp8+TUxMTJn9iI6OZvny5aSnp+Pp6cnQoUO5e/cuAPfv38ff35+kpCQyMzOZPXs2L7/8MsnJySbr2LZtG1JKvvrqK7Zu3Up6ejozZsxg0aJFaLVakpOTGTJkSLkxRkdHM3r0aONImU6no2/fvkRGRpKQkGCyj9u3b0ej0TBs2DBiYmKqfC/V8ePHGTx4sElZWFgYx44dq7BNQUFBmWNka2vL999/z/Xr18tts2nTJrp27Urfvn0rjac21NNMZpZ/Pp+L0y/SMqglHjEe5g5HUZQGMmcOnD5d+/bBwTVv4+cHq1fXfptpaWkkJCQwcOBAY9mDBw/46KOPaNOmTY3X5+Pjw5IlSwDo1KkTmzZtIjk5mXHjxlXYZvDgwcak4FmzZrF27VqSk5MJDAzk4MGDaLVaDhw4gKurK6Dv/FT1Junr168THR1N586dAejYsWOZOgsXLiQsLAyA+Ph43NzcSEhIICIiAldXV1577TVj3WnTpnHo0CG2b99ucqzat2/PypUrjfN79+7Fzs6OF198EXt7e9zd3enevXu5MWo0GmxtbbGxscHZ2dlYPnLkSGbNmkViYiJjx44FIC4ujokTJ2JlZYWjoyPe3t6V7n92dnaZ89emTRuys7MrbBMWFsacOXM4cOAAoaGhXL582bhvOp0ODw8Pk/q3b99m165d9ZYDpUZmzKjobhHnRp+jWQt9noyFpTodiqKU79o1OHJEP8G/f752rX63+/nnn6PRaGjevDmBgYEEBQWxbt0643I3N7dadWQAfH19TeZdXFz48ccfa93mwoULuLi4GDsyAL169cLCovK/rVFRUURERBASEsLSpUu5cOFCmTqBgYHGnzUaDd26dePcuXMAFBUVsXTpUnx9fXFwcECj0bB3715u3Lhhso6ePXuazA8aNAh3d3fat29PeHg4H374IXl5eZXGWpqNjQ0TJkwgLi4OgMzMTNLS0pg6dSoAM2fOLHd/fq3IyEhmzZrFSy+9hLW1Nc8++6yxM1Xe8d62bRvFxcVMmDChzmMBNTJjVpdnXyb/bD6+n/ti46q+T0ZRniS/ZoRECKjDPNtKBQUF8cEHH2BlZYWLiwtWVlYmy8t7MsXCwqJMInDJW1OPlF6XEILi4uJK46lNm6rExMQQHh7O/v37+eKLL1i8eDEbN25kypQp1Wq/YsUKVq5cyZo1a+jWrRsajYYFCxaU6ZiVPlb29vacOnWKL7/8koMHDxIbG8uCBQv4+uuvcXFxqXb8ERER+Pr6cuPGDeLi4ggMDKzRW9qdnZ3JyckxKcvJyTEZASpNCMHy5ct5++23yc7OxsnJyXhbzdPTs0z9TZs28Yc//IHWresnlUINBZhJzsc56DbraDe/Ha3DVJ6MoiiPpxYtWtCxY0fc3d3LdCQq4uTkhE6nMynLyMioj/BMdO7cmaysLLKysoxl6enp1erseHl58eqrr7Jv3z6mTp3K5s2bTZafOHHC+HN+fj5nz541dhhSU1MZNmwYEyZMwM/Pjw4dOnDx4sVqxWxpaUlISAixsbGcOXOG/Px8kpKSyq1rbW1NUVFRmfKuXbvSp08fNm3axLZt26rdCXvk0S26kg4ePFit3JZmzZrh6uqKtbU127dvJzAwECcnJ5M6aWlpZGRkEBkZWaO4akJ1ZszgrvYu2pe1tPxdSzyWeJg7HEVRGplFi8wdQeVCQkLYv38/n376KVqtlqioKG7evFnv2x00aBDe3t5MmjSJjIwMTpw4QVRUFJaWlhUmwd67d48ZM2Zw+PBhrl27xsmTJ0lNTcXHx8ek3ltvvcXBgwfJzMxkypQpWFtbM378eECf75OcnExqaioXLlxg5syZXL16tcp4k5KSWLNmDd9++y3Xr18nISGBvLy8CkdVPDw8OHv2LFqtltzcXJPRrsjISN555x3y8/MZM2aMsXz9+vXGXKCKzJ49m0OHDrFs2TIuXLhAbGwsKSkpzJkzx1hn/vz5Jvk/ubm5vP/++5w/f57Tp08ze/Zsdu/ezepyhhw/+OADvLy8CK5Nolc1qc5MAyu6V0TmqEwsmlvQZXsXlSejKEqNxcSYO4LKTZkyxTj169cPe3t7RowYUe/btbCwIDExkYKCAnr37s2kSZP461//ihCiwqesmjVrxs8//8zkyZPx9vZmxIgRBAYG8t5775nUW7ZsGXPnzsXf359Lly6RlJRkvG30xhtv0Lt3b55//nmCgoKws7MjPDy8yniffvppPvnkE0JDQ+ncuTMrVqxg8+bNPPfcc+XWj4yMpEuXLgQEBODk5MTRo0eNy8aMGYO1tTWjR482+W6e3NxctFptpXH07duXHTt2sGXLFnx9fdm6dSs7d+6kT58+xjo6nY4rV66YtNu6dSu9evWiX79+ZGZmcvjwYXr37m1SJy8vjx07dhAREVHl8fg1ROn7mk1FQECATE9PN3cYZWhf1qL7QEe3f3TD4fn6/zIkRVHM7/z58zXKYVDqTkZGBn5+fqSnp5dJwK2Ow4cPM2DAAG7duoWjo2M9RFg3srKyaNeuHUeOHKny6a3HXWWfFyHEN1LKgNLlKgG4AeVsz0H3gY7fzvut6sgoiqLUg8TEROzs7PDy8uLatWtERUXRvXt3/P39zR1avSgsLOSnn35iwYIF9OjRo9F3ZGpLdWYayN2Ld7k47SJP9XuK9m+2N3c4iqIoTVJeXh7z5s3j5s2btGrViuDgYFatWlXlF8c1VkePHmXAgAF4eXmxa9cuc4djNuo2UwMoul/EqWdPUXCzgIDTATT/bfW/IVNRlMZP3WZSlOpTt5keU1f+coX8jHy6JXVTHRlFURRFqWPqUZp69uPOH8namMVvX/stDi+oPBlFURRFqWuqM1OP7l66izZSy1OBT9F+qcqTURRFUZT6oDoz9aTovv69S8JS4LPDBwsrdagVRVEUpT6onJl6cmXuFe6cvsMznz5D83YqT0ZRFEVR6osaLqgHP+76kawNWbjNdcNx2OP7JUuKoiiK0hSozkwdu3v5LtoILU89+xSesWXfHKooiqJUT3BwMDNnzjR3GGYTExPDM888Y+4wGoUG78wIIf4shLgqhLgvhPhGCFH+Syj0dYOFELKcqfK3ZplJcUEx58aoPBlFUZqGyZMnI4RACIGVlRWenp5ER0eTn5/fINvfu3cvsbGxDbKtx1F0dDRHjhwxzk+ePJmhQ4fWy7b27NmDj48PNjY2+Pj4kJiYWGWbXbt24efnR4sWLXB3d+fdd98tUychIcFYx9nZmT/+8Y9kZ2fXefwNerUVQowB1gBvAz2AY8B+IUS7Kpp2BdqWmC7VZ5y1dSX6CndO3aHzls40d1d5MoqiNH6hoaHodDq+++473nrrLTZs2EB0dHS5dR8+fEhdfhFr69atTV6a2JQ8ePCgyjoajQYHh/r/So/jx48zZswYwsPDOX36NOHh4YwaNYqTJ09W2Gb//v2MHz+eadOmcfbsWTZs2MCqVatYv369sc7Ro0eZMGECkyZNIjMzk08++YRz585V6yWcNSalbLAJOAlsKlV2CYitoH4wIAHHmm6rZ8+esiHl7M6RKaTIS3+51KDbVRTl8Xfu3Lk6W9f9rPvyVNApeV93v87WWZFJkybJF154waQsIiJCOjs7SymlXLRokezatauMj4+Xnp6e0sLCQubl5cn+/fvLGTNmVLqu/v37y1deeUXOnz9fOjg4SCcnJzl37lxZVFRkUqfketzd3eWbb74pp02bJu3t7aWrq6t85513TLaj1WplUFCQtLGxkZ06dZL79u2TdnZ2Mj4+vsL9PHPmjAwJCZH29vbSzs5O+vr6ykOHDkkppUxJSZGA/Oyzz2T37t2ljY2N9Pf3l+np6cb2ubm5cuzYsdLV1VU2b95c+vj4yLi4OJNt9O/fX06fPl3OnTtXOjo6yoCAACmllBs3bpReXl7SxsZGOjg4yMGDB8vCwkKT4/voZ8P10DilpKTIAQMGlDnWt2/flra2tnLPnj0V7nNJo0ePlqGhoSZlAwcOlGPHjq2wzbhx4+Tw4cNNytauXSvd3NxkcXGxlFLKd999V7Zr186kTlxcnLSzs6s0nso+L0C6LOea32AjM0IIa6AncKDUogNA3yqapwshdEKIZCHEgHoJ8Fe49909tFO12Pe2x3OZypNRFKX+XHvzGrdTb3P9zetm2b6trS2FhYXG+atXr5KQkMDu3bvJyMigefPqj0p//PHHWFpacuzYMdavX8/q1avZuXNnpW1WrVpFt27dOHXqFPPmzeP111/n+PHjABQXFzNixAgsLS05ceIEW7ZsYfHixRQUFFS6zvHjx9O2bVvS0tI4ffo0MTExZfYjOjqa5cuXk56ejqenJ0OHDuXu3bsA3L9/H39/f5KSksjMzGT27Nm8/PLLJCcnm6xj27ZtSCn56quv2Lp1K+np6cyYMYNFixah1WpJTk5myJAh5cYYHR3N6NGjjSNlOp2Ovn37EhkZSUJCgsk+bt++HY1Gw7Bhw4iJianyvVTHjx9n8ODBJmVhYWEcO3aswjYFBQVljpGtrS3ff/8916/rfzf79euHTqfjs88+Q0pJbm4uO3bs4Pe//32l8dRGQz6a7Qg0A3JKlecAoRW00QGvAF8D1sAEIFkI0V9K+VXpykKIacA0gHbtqrpzVTeKC4rJHJ2JsBD47PTBwlrlySiKUrVLcy5x5/SdGrUpLigmLy0PiiFrYxZ53+bV6G+Oxk+D12qvmoZqlJaWRkJCAgMHDjSWPXjwgI8++og2bdrUeH0+Pj4sWbIEgE6dOrFp0yaSk5MZN25chW0GDx5sTAqeNWsWa9euJTk5mcDAQA4ePIhWq+XAgQO4uroC+s5PVW+Svn79OtHR0XTurE/H7NixY5k6CxcuJCwsDID4+Hjc3NxISEggIiICV1dXXnvtNWPdadOmcejQIbZv325yrNq3b8/KlSuN83v37sXOzo4XX3wRe3t73N3d6d69e7kxajQabG1tsbGxwdnZ2Vg+cuRIZs2aRWJiImPHjgUgLi6OiRMnYmVlhaOjI97e3pXuf3Z2dpnz16ZNm0pzW8LCwpgzZw4HDhwgNDSUy5cvG/dNp9Ph4eFBYGAgO3bsIDw8nHv37vHw4UMGDRrEhx9+WGk8tfFYX3mllFop5UYp5TdSyuNSyj8DnwOvVVD/AyllgJQywMnJqUFivPL6Fe58cwfveG9sPWwbZJuKojyZCq4X6G8wAEjDfD37/PPP0Wg0NG/enMDAQIKCgli3bp1xuZubW606MgC+vr4m8y4uLvz444+1bnPhwgVcXFyMHRmAXr16YWFR+aUuKiqKiIgIQkJCWLp0KRcuXChTJzAw0PizRqOhW7dunDt3DoCioiKWLl2Kr68vDg4OaDQa9u7dy40bN0zW0bNnT5P5QYMG4e7uTvv27QkPD+fDDz8kLy+v0lhLs7GxYcKECcTFxQGQmZlJWloaU6dOBWDmzJnl7s+vFRkZyaxZs3jppZewtrbm2WefNXamHh3vc+fOMWvWLBYuXMg333zD559/TnZ2Ni+//HKdx9OQIzO5QBFQ+re+DVCT1OaTwNi6CurXuLX3Fj+s/QHX2a44DW+YzpOiKE1DTUdICnQFnPQ8adKZefjzQ3x2+GDjbFP3ARoEBQXxwQcfYGVlhYuLC1ZWVibL7ezsyrSxsLAokwhc8tbUI6XXJYSguLi40nhq06YqMTExhIeHs3//fr744gsWL17Mxo0bmTJlSrXar1ixgpUrV7JmzRq6deuGRqNhwYIFZTpmpY+Vvb09p06d4ssvv+TgwYPExsayYMECvv76a1xcXKodf0REBL6+vty4cYO4uDgCAwNr9JZ2Z2dncnJMb5rk5OSYjACVJoRg+fLlvP3222RnZ+Pk5GS8rebpqU+3iI2NpXfv3sZRK19fX+zs7Hjuued4++23cXNzq3aMVWmwkRkp5QPgG2BQqUWD0D/VVF1+6G8/mdW9q/e4MOUC9r3s6fBOB3OHoyhKE3ftzWvIYtMOgiyS9Z4706JFCzp27Ii7u3uZjkRFnJyc0OlM/0xnZGTUR3gmOnfuTFZWFllZWcay9PT0anV2vLy8ePXVV9m3bx9Tp05l8+bNJstPnDhh/Dk/P5+zZ88aOwypqakMGzaMCRMm4OfnR4cOHbh48WK1Yra0tCQkJITY2FjOnDlDfn4+SUlJ5da1tramqKioTHnXrl3p06cPmzZtYtu2bdXuhD3y6BZdSQcPHqRv36rSWaFZs2a4urpibW3N9u3bCQwM5NGdkbt379KsWbMy9YFf3QEtraFfZ/Ae8JEQIg04CkwHXICNAEKIrQBSyomG+TnANSATfc7MH4HhwB8aOG6jAl0B50af4+GdhwAqT0ZRlAbxy/FfkA9KdWYeSG4fu22miCoWEhLCnDlz+PTTT/H29ubvf/87N2/exMPDo163O2jQILy9vZk0aRIrVqzg3r17REVFYWlpWWES7L1794iOjmbUqFF4eHiQk5NDamoqffr0Man31ltv4eTkhIuLC0uWLMHa2prx48cD+nyfnTt3kpqaiqOjI+vWrePq1av06NGj0niTkpK4cuUKQUFBtG7dmpSUFPLy8iocVfHw8GD//v1otVocHBxo2bKlsYMZGRnJ9OnTsbKyYsyYMcY269evZ/369ZXeapo9ezZBQUEsW7aM4cOHk5iYSEpKCqmpqcY68+fPJy0tzTj6kpuby+7duwkODqagoID4+Hh2795t8r04w4YNIzIykvfff5+wsDB0Oh1z5szB39+/zvNaG7QzI6XcKYRwAN5A/30xZ4HfSykf/dei9N5ZA+8CbsA99J2aF6SU/2igkMt49CQBQNc9XbFtr/JkFEWpf72+7WXuEKptypQpnDlzxjhCMGPGDEaMGEFubm69btfCwoLExEQiIiLo3bs3Hh4erFy5kpEjR1b4lFWzZs34+eefmTx5MjqdDgcHB4YOHcqKFStM6i1btoy5c+ei1Wrp2rUrSUlJxttGb7zxBlevXuX555/H1taWyZMnEx4ebsypqcjTTz/NJ598wpIlS7h79y4dOnRg8+bNPPdc+d8lGxkZyeHDhwkICODOnTukpKQQHBwMwJgxY3j11VcZNWqUyXfz5ObmotVqK42jb9++7NixgzfeeIO//e1vdOjQgZ07d5p06HQ6HVeuXDFpt3XrVl577TWklAQGBnL48GF69+5tXD558mTy8vJYv349c+fOpWXLloSEhLB8+fJK46kNUfq+ZlMREBAg09PT63SdBboCTnic0P/vqBkEfh9Yr/eqFUVpGs6fP1+jHAal7mRkZODn50d6enqZBNzqOHz4MAMGDODWrVs4Oj6+79rLysqiXbt2HDlypMqntx53lX1ehBDfSCkDSpert2bXQMl71qKZ4Pqb1+n0X53MHJWiKIrySGJiInZ2dnh5eXHt2jWioqLo3r07/v7+5g6tXhQWFvLTTz+xYMECevTo0eg7MrWlkj2qqUBXQE58DuhTZZAPJNnx2RRk1/+jkYqiKEr15OXlMXPmTHx8fAgPD6dLly588cUXVX5xXGN19OhR2rZty7Fjx9i0aZO5wzEbNTJTTZU9SaBGZxRFUR4PEydOZOLEiXW2vuDg4Dp931Rde9zjayhqZKaaGtOTBIqiKIryJFEjM9XUmJ4kUBRFUZQniRqZURRFaQDqVoCiVK22nxPVmVEURalnVlZW3Lt3z9xhKMpj7969e9X+pumSVGdGURSlnv3mN7/hhx9+4O7du2qERlHKIaXk7t27/PDDD/zmN7+pcXuVM6MoilLPnnrqKUD/xWblvXBRURT9CGabNm2Mn5eaUJ0ZRVGUBvDUU0/V6o+0oihVU7eZFEVRFEVp1FRnRlEURVGURk11ZhRFURRFadRUZ0ZRFEVRlEZNdWYURVEURWnURFP9zgMhxC3gej2t3hHIrad1Kw1HncemQ53LpkGdx6ahPs+ju5TSqXRhk+3M1CchRLqUMsDccSi/jjqPTYc6l02DOo9NgznOo7rNpCiKoihKo6Y6M4qiKIqiNGqqM1M7H5g7AKVOqPPYdKhz2TSo89g0NPh5VDkziqIoiqI0ampkRlEURVGURk11ZhRFURRFadRUZ6aahBBBQohPhRA/CCGkEGKyuWNSak4IMV8I8bUQ4hchxC0hxGdCiGfMHZdSM0KIGUKIM4bz+IsQ4rgQ4gVzx6X8OobPpxRCrDd3LEr1CSFiDOet5JTdkDGozkz1aYCzwGzgnpljUWovGNgA9AVCgIfA/wohWpszKKXGvgfmAf5AAHAI+EQI4WvWqJRaE0I8C0wDzpg7FqVWtEDbElO3hty4ZUNurDGTUv4D+AeAEGKLeaNRaktKGVZyXggxAbgN9AM+M0tQSo1JKf+nVNFfhRCvAIGoi2GjI4RoCXwMTAEWmTkcpXYeSikbdDSmJDUyozzp7NF/Dn42dyBK7QghmgkhxqIfPT1m7niUWvkA+H9SyhRzB6LUmqcQIksIcVUIsUMI4dmQG1cjM8qTbg1wGjhu7kCUmhFCdEN/3poDd4ARUsp/mjcqpaaEEJFAR+CP5o5FqbWTwGTgAvAb4A3gmBCiq5Typ4YIQHVmlCeWEOI94HfA76SUReaOR6kxLeAHtAT+A/hQCBEspTxr3rCU6hJCeANvo/8MFpo7HqV2pJT7S84LIU4A3wGTgPcaIgbVmVGeSEKIVcBYYICU8jtzx6PUnJTyAXDZMPuNEKIX8BdgqvmiUmooEP0bljOFEI/KmgFBQojpgJ2UssBcwSm1I6W8I4TIBLwaapuqM6M8cYQQa4Ax6DsyF8wdj1JnLAAbcweh1MgnQHqpsnjgEvoRmwcNHpHyqwkhmgOdgQbLgVKdmWoSQmjQ39cF/R/NdkIIP+D/pJQ3zBeZUhNCiP8CJgDDgZ+FEM6GRXeklHfMF5lSE0KIZcA+4Cb6JO7x6B+7V98104hIKf8F/KtkmRAiH/3fVXW7sJEQQqxA/zToDfQ5MwsBO+DDhopBPc1UfQHAt4bJFlhs+HmJOYNSauzP6C9+yYCuxBRtzqCUGnMGtqHPm0kGegHPl753ryhKg3ADtqP/PO4FCoBnpZTXGyoA9aJJRVEURVEaNTUyoyiKoihKo6Y6M4qiKIqiNGqqM6MoiqIoSqOmOjOKoiiKojRqqjOjKIqiKEqjpjoziqIoiqI0aqozoyiPCSHEFiFEkrnjKEkI8ZIQ4pIQ4qEQYstjEE9STeIQQngIIaQQIqCW2ws2tHesTXtFURqG6swoCsaOhBRCLCxV/qRfzP4b2AO4A7PNHIs5HAPaAg3y5l9FUWpHdWYU5d/uA68JIZzMHUhdEkJY1bLd04AD8IWU8gcp5e26jezxJ6V8IKXMlurbRRXlsaY6M4rybynANfTvFSlXeSM1pW9llKjzvBDiGyHEPSHEV0IINyFEfyFEhhDijuGWiUM523hDCJFjqBMvhLAtsUwIIV4XQlwxrPefQog/lhPLOCHEISHEPeDlCvallRDiQyHEz4Z1/a8QouujfQB+NlQ9ZFhncAXruSaE+JthdCtPCHFTCDFGCPG0EGKHYT8uCSEGl2oXJIQ4KYS4b9jfVUII6xLLWxjWecewfEE527YWQiwXQnwvhLgrhPhaCBFWXpyG+lZCiLVCiCwhRIEh1mWV1Dc530KIyYZ4Bgohzgoh8oUQKUKI9hWtw9CupRDifSGEzrC/54UQY0osH2k4l49i+qsQ/36NtOEYvyGE+LsQ4hfD/r5WahsvCyEuGtafK4T4QghhWWL5n4QQ5wzLLwoh/iKEsCixXAohpgkhdhv267uSv1uGOn8TQlw3xJkthNhaYtlhIcT6UvVNbp0azvkJwzG8LYRIE0I8U9mxU5RqkVKqSU1P/ARsAZKA36N/U28HQ3kwIAHH8uYNZR6GsoBSddKA5wBf4CxwFP17hPqgf9fXVWBdqRjygN3AM0AY8AOwtkSdpejffzIEaI/+BYv5wAulYrkG/IehjlsF+/w/wAUgCOgGfIr+xY22gDXgY1jXSPTvQrKuYD3XgP9D/94rL2Al+lGufwAT0b+g9b+BH4Hmhjauhrg3Al2AoUA2sLLEejcY9j/McDx2A78AW0rU+Rg4YdgHT2Cm4fx1r+DczDXsYxDQDugL/KmS34vS538yUAj8L9DbcG6/RT96VdE6hOHcnzOcN0/geWCEYXlPoAj9+946AeHAHWBWqWP8k2H/OgKzDHEFGpYHAA8Nbd2B7sBfAEvD8kj07yB79DsxzHC8Z5bYhgS+B/5o2Eas4Vi2Myz/g+H4v2A4dgGl2h8G1pf3uTL8bIm+g7wC6ID+rcrjgS7m/vyrqfFPZg9ATWp6HKZSf3RTgB2Gn0tfzEzmDWWlL5iP6oSVqDPTUOZfoiwGOFsqhn8BmhJlf0T/0jY7w3QPeK5U7KuBf5SKZW4V++tlqBdUoqwlcBuIMMw7GuoEV7Gua8D2EvMaQ7uSnbDSx2gpcAmwKFFnsmFfWxjWUQCEl1rvvzB0ZgwXxOJHF9sS9T4BNlSw3bXoO5Simr8Xpc//ZMO8d4k64YZYy10nMMgQZ7kXbfQdskOlymKA7ys6xoayS8Abhp9HGs6dfQXbuAFMKFU2BzhXYl4CsSXmLYG7wB8N81HoO9JWFWzjMJV3ZlobttG/vj/PanryJnWbSVHKmgeMEkL0/JXrOVPi5xzDv/8sVfab0m2klHdKzB9HP0rSAf1ISXPgc8Mw/R0hxB3gFcPyktKriK0L+gvs8UcFUp8T80/DdmrKuK+G+O9Sdl/h3/vbBTghpSwuUScV/b52RL8/1qXiu+88lBcAAASvSURBVFNqnf7oRz3OlToeL1D2eDyyBfADLgoh/ksI8ULJWy3VVCCl1JaYzzLE2qqC+j0AnZTyfAXLu6AfuSkpFXAVQjxVouxMqTpZ/Pt4HgSuA1eFEB8LISYJIewBhD4H7LfA30sdp2WUPU4lz+ND4FaJbexG//t3VQjx30KIUUIImwr2qQwp5f+hP/5fCCH2CSGihBDtqtteUSqjOjOKUoqUMg39EzzvlLP40cVXlCirKMG2sORqDesuXVaTz+CjusPQX5AfTV2BwaXq5tdgvaXVJtm1sNS8pJz9p3r7W93tWxjq9sL0eHQBppS7YilPoR+tmW9o/yFwsIYdmocVxFsff09LHovyjrEFgJQyD33nbjT6UZj5wAUhhEuJuKZjepyeQf+7U1Jl27gJeKPPwfoF/e3Eb4QQdoa6xZh+LqDUZ0NK+Sf0t1m/BF4EtJXlOClKdanOjKKUbwH6fJchpcpvGf5tW6LMrw63263ExQHgWfR5C1fQ51wUAO5Sysulpus13M559J//wEcFhlGAbobt1LfzwLOlOhG/49/7egX9hfXZEvHZob8AP/It+ouncznH44eKNiylzJNS/j8p5SvoR3FC0I8G1ZdvgbZCiC4VLD8P9CtV9jv0t5nyqrsRKeVDKeUhKeV89Lk8dsBQKWUO+lGcDuUcp8s12REp5X0p5T4p5V/QdyK7loj9FqafC9Dn7pReR4aUcrmUMhj9ralJNYlBUcpjWXUVRXnySCkvCyE+oOx3q1xGn0AaI4T4T/T/y3+jDjdtCcQJIZYALuhvBWySUuYDCCFWACsMT7p8iT6P5FmgWEr5QXU3IqW8JIT4H/S3Hqahz0VZiv5/3Al1uD8V2YA+Z2ODEGIN+qTYZehzLu4CCCH+G1guhLiF/mL8N6BZiX24KIT4GNgihJgLnEKflxEMfCel3Ft6o0KIKPSJsKfRd5bGo9/n7+tpP0Gfo3MS2COE+AtwEX3nyU5K+Qn6EY6vhRAx6I99L/SJymWe3qqIEGIo+ltGX6JPxh4A2KPvKAEsAtYJIf6FPjHbCv1IjquUMraa25iM/vfzJPoE5THoj+ElQ5VDwGohxIvoc2teRn9765qhfXtD2afoE7s90Xe63q/ufipKRVRnRlEqtoRS/2uUUhYKIcaivxhnoL8oLkD/JFRdOAJkok9CboH+dtfrJZYvRJ9/Eo3+IvCLIYbybolV5U/ok4c/RZ8LcRQYIqW8V9vgq0tK+YMQ4nngXfTx/wv9hbzkBTwa/ehCIvocnHWG+ZL+BPwV/f67ob+Qp6E/fuXJA17j3wnQ3wLPP+pA1QcpZXGJfd2GvpPxHfokX6SUp4QQo9A/zbQA/fldBqwvd4Xl+xcwHH2HrwX6ka0IKeVXhm1sFkLko9/3WPSJ5Jm12MY89E8jWaEfwRsppbxqWB6HvnMSZ5j/L/Tn7tHXGNxF/7TWbkNZDvrk5+U1iEFRyiWkVN8FpSiKoihK46VyZhRFURRFadRUZ0ZRFEVRlEZNdWYURVEURWnUVGdGURRFUZRGTXVmFEVRFEVp1FRnRlEURVGURk11ZhRFURRFadRUZ0ZRFEVRlEZNdWYURVEURWnU/j+L1MoAEoocqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiTyf1cL8Oj2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 10. Implement AlexNet\n",
        " **AlexNet** [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
        "\n",
        "```\n",
        "#--------------------\n",
        "# fc8\n",
        "# (4096, 1000) # weights\n",
        "# (1000,) # bias\n",
        "#--------------------\n",
        "# fc7\n",
        "# (4096, 4096) # weights\n",
        "# (4096,) # bias\n",
        "#--------------------\n",
        "# fc6\n",
        "# (9216, 4096) # weights\n",
        "# (4096,) # bias\n",
        "#--------------------\n",
        "# conv5\n",
        "# (3, 3, 192, 256) # weights\n",
        "# (256,) # bias\n",
        "#--------------------\n",
        "# conv4\n",
        "# (3, 3, 192, 384) # weights\n",
        "# (384,) # bias\n",
        "#--------------------\n",
        "# conv3\n",
        "# (3, 3, 256, 384) # weights\n",
        "# (384,) # bias\n",
        "#--------------------\n",
        "# conv2\n",
        "# (5, 5, 48, 256) # weights\n",
        "# (256,) # bias\n",
        "#--------------------\n",
        "# conv1\n",
        "# (11, 11, 3, 96) # weights\n",
        "# (96,) # bias\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWP2N4dSWziG",
        "colab_type": "text"
      },
      "source": [
        "### Load CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWVgZGhlXwku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! tar -xvf drive/My\\ Drive/Colab\\ Notebooks/cifar-10-python.tar\n",
        "# ! mkdir drive/My\\ Drive/Colab\\ Notebooks/cifar-10-batches-py\n",
        "# ! mv  -v cifar-10-batches-py/* drive/My\\ Drive/Colab\\ Notebooks/cifar-10-batches-py/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Hi0J1DWy3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decide image size. (32 or 70)\n",
        "img_size = 70\n",
        "\n",
        "# Unpickle particular batch file into a dictionary\n",
        "def __extract_file__(fname):\n",
        "    with open(fname, 'rb') as fo:\n",
        "        d = pickle.load(fo, encoding='bytes')\n",
        "    return d\n",
        "\n",
        "def __unflatten_image__(img_flat):\n",
        "    img_R = img_flat[0:1024].reshape((32, 32))\n",
        "    img_G = img_flat[1024:2048].reshape((32, 32))\n",
        "    img_B = img_flat[2048:3072].reshape((32, 32))\n",
        "    img = np.dstack((img_R, img_G, img_B))\n",
        "    ##********##\n",
        "    img = scipy.misc.imresize(img,size=(img_size,img_size),interp='bicubic')\n",
        "    ##********##\n",
        "    return img\n",
        "\n",
        "# Extract only data and labels and then reshape for use  \n",
        "def __extract_reshape_file__(fname):\n",
        "    res = []\n",
        "    d = __extract_file__(fname)\n",
        "    images = d[b\"data\"]\n",
        "    labels = d[b\"labels\"]\n",
        "    for image, label in zip(images, labels):\n",
        "        res.append((__unflatten_image__(image), label))\n",
        "    return res\n",
        "  \n",
        "# Load data from all batches into a single variable \n",
        "def get_images_from(dir):\n",
        "    files = [f for f in os.listdir(dir) if f.startswith(\"data_batch\")]\n",
        "    res = []\n",
        "    for f in files:\n",
        "        res = res + __extract_reshape_file__(os.path.join(dir, f))\n",
        "    return res\n",
        "    \n",
        "\n",
        "class Cifar(object):\n",
        "\n",
        "    def __init__(self, dir=\"data/cifar-10-batches-py/\", batch_size=1):\n",
        "        self.__res__ = get_images_from(dir)\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = []\n",
        "        self.__batch_num__ = 0\n",
        "        # Divide the data into batches\n",
        "        for i in range(math.ceil(len(self.__res__)/batch_size)):\n",
        "            self.batches.append(self.__res__[i*batch_size:(i+1)*batch_size])\n",
        "        self.test_set = __extract_reshape_file__(os.path.join(dir, \"test_batch\"))\n",
        "        \n",
        "    def batch(self, num):\n",
        "        return self.batches[num]\n",
        "\n",
        "    def next_batch(self):\n",
        "        if self.__batch_num__ <= len(self.batches):\n",
        "            res = self.batches[self.__batch_num__]\n",
        "            self.__batch_num__ = self.__batch_num__ + 1\n",
        "        else:\n",
        "            res = []\n",
        "\n",
        "        return res\n",
        "\n",
        "    def reset_batch(self):\n",
        "        self.__batch_num__ = 0\n",
        "\n",
        "# Processing the batches to form input and output matrix        \n",
        "def one_hot(num, dim=1000):\n",
        "    vec = np.zeros(dim)\n",
        "    vec[num] = 1\n",
        "    return vec\n",
        "\n",
        "\n",
        "def transform_to_input_output(input_output, dim=1000):\n",
        "    input_vals = []\n",
        "    output_vals = []\n",
        "    for input_val, output_val in input_output:\n",
        "        input_vals.append(input_val)\n",
        "        output_vals.append(output_val)\n",
        "\n",
        "    return np.array(input_vals), np.array([one_hot(out, dim=dim)\n",
        "         for out in output_vals], dtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFQhBnaWMW86",
        "colab_type": "text"
      },
      "source": [
        "### Define original model\n",
        "\n",
        "Removed LRN from model as double derivative of LRN not available in tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9sy1VZs8Oj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" build the AlexNet model\n",
        "* Use Alexnet(), not Alexnet_small\n",
        "* Function returns output of all important layers to help construct two networks \n",
        "with the same architecture later\n",
        "* Removed LRN in final implementation as its double derivative is not natively \n",
        "supported by tensorflow. \n",
        "\n",
        "100_noLRN3,256,128,p=0.9,b=128 (74.5%) 120 epochs last_2layer_dropout\n",
        "100_noLRN4,256,192,p=0.6,b=128 (72.5%) 60 epochs     l6_l7_dropout \n",
        "100_noLRN5,256,256,p=0.7,b=128 (60.5%) 100 epochs last_2layer_dropout  \n",
        "100_noLRN6,256,256,p=0.6,b=128 (71.3%) 50 epochs   l6_l7_dropout  \n",
        "100_noLRN7,384,256,256,p=0.5,b=128 (71.3) 60 epochs l6_l7_dropout  \n",
        "100_noLRN8,384,384,256,p=0.5,b=128 (73%) 60 epochs l6_l7_dropout  \n",
        "\"\"\"\n",
        "from tensorflow import layers\n",
        "\n",
        "# Used for convolving split layers with split kernel, with 2 gpu in parallel\n",
        "def conv2d_split(X, filters, kernel_size, strides, name, activation):\n",
        "    input_channels = int(X.get_shape()[-1])\n",
        "    with tf.variable_scope(name):\n",
        "        # Fetch kernel variable in name scope with given shape\n",
        "        weights = tf.get_variable('kernel', initializer = random_values([kernel_size, kernel_size, int(input_channels/2), filters]))\n",
        "        # Fetch bias variable in name scope with given shape\n",
        "        biases = tf.get_variable('bias', initializer =tf.ones(shape=[filters], dtype=tf.float32))\n",
        "    \n",
        "    conv = lambda x, w: tf.nn.conv2d(x, w, strides = [1, strides, strides, 1], padding=\"SAME\")\n",
        "    \n",
        "    input_groups = tf.split(axis = 3, num_or_size_splits=2, value=X)\n",
        "    weight_groups = tf.split(axis = 3, num_or_size_splits=2, value=pruning.apply_mask(weights,name))\n",
        "    output_groups = [conv(x, w) for x,w in zip(input_groups, weight_groups)]\n",
        "\n",
        "    output = tf.concat(axis = 3, values = output_groups) + biases\n",
        "    \n",
        "    return activation(output)\n",
        "    \n",
        "random_mean = 0\n",
        "random_stddev = 0.01\n",
        "def random_values(shape):\n",
        "    return tf.random_normal(shape=shape, mean=random_mean, stddev=random_stddev, dtype=tf.float32)\n",
        "\n",
        "def AlexNet(X,pkeep = 0.5):\n",
        "    print(np.shape(X))\n",
        "    with tf.variable_scope('conv1'):\n",
        "        w = tf.get_variable('kernel', initializer = random_values([11,11,3,96]))\n",
        "        b = tf.get_variable('bias',initializer =tf.ones(shape = [96], dtype=tf.float32))\n",
        "    # Choose stride from 1 or 4 depending on CIFAR or Imagenet    \n",
        "    c1 = tf.nn.conv2d(X, pruning.apply_mask(w,'conv1'), strides = [1, 4, 4, 1], padding=\"SAME\")\n",
        "    c1 = c1 + b\n",
        "    c1 = tf.nn.relu(c1)\n",
        "    print(np.shape(c1))\n",
        "    # c1 = layers.conv2d(X, filters=96, kernel_size=11, strides=4, padding=\"SAME\", activation='relu', name='conv1')\n",
        "    # lrn1 = tf.nn.lrn(c1, depth_radius=2, alpha=1e-05, beta=0.75, bias=1.0)\n",
        "    m1 = layers.max_pooling2d(c1, pool_size=3, strides=2, padding=\"VALID\")\n",
        "        \n",
        "    c2 = conv2d_split(m1, filters=256, kernel_size=5, strides=1, name=\"conv2\", activation=tf.nn.relu)\n",
        "    print(np.shape(c2))\n",
        "    # lrn2 = tf.nn.lrn(c2, depth_radius=2, alpha=1e-05, beta=0.75, bias=1.0)\n",
        "    m2 = layers.max_pooling2d(c2, pool_size=3, strides=2, padding=\"VALID\")\n",
        "    \n",
        "    with tf.variable_scope('conv3'):\n",
        "        w =  tf.get_variable('kernel', initializer = random_values([3,3,256,384]))\n",
        "        b = tf.get_variable('bias',initializer =tf.ones(shape = [384]), dtype=tf.float32)\n",
        "    c3 = tf.nn.conv2d(m2, pruning.apply_mask(w,'conv3'), strides = [1, 1, 1, 1], padding=\"SAME\")\n",
        "    c3 = c3 + b\n",
        "    c3 = tf.nn.relu(c3)\n",
        "    # c3 = layers.conv2d(m2, filters=384, kernel_size=3, strides=1, padding=\"SAME\", activation='relu', name='conv3')\n",
        "    print(np.shape(c3))\n",
        "    c4 = conv2d_split(c3, filters=384, kernel_size=3, strides=1, name=\"conv4\", activation=tf.nn.relu)\n",
        "    print(np.shape(c4))\n",
        "    \n",
        "    # c5 = conv2d_split(c4, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, name='conv5')\n",
        "    c5 = conv2d_split(c4, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, name='conv5')\n",
        "    print(np.shape(c5))\n",
        "    m5 = layers.max_pooling2d(c5, pool_size=3, strides=2, padding=\"VALID\")\n",
        "    m5 = layers.flatten(m5)\n",
        "    \n",
        "    with tf.variable_scope('fc6'):\n",
        "        # w =  tf.get_variable('kernel', initializer = random_values([256,256]))\n",
        "        w =  tf.get_variable('kernel', initializer = random_values([256,256]))\n",
        "        b = tf.get_variable('bias',initializer =tf.ones(shape = [256]), dtype=tf.float32)\n",
        "    f6 = tf.nn.relu(tf.matmul(m5, pruning.apply_mask(w,'fc6')) + b)\n",
        "    print(np.shape(f6))\n",
        "    # f6 = tf.nn.dropout(f6, keep_prob=pkeep, name='f6_dropout')\n",
        "    # f6 = layers.dense(m5, 4096, activation='relu', name=\"fc6\")\n",
        "\n",
        "    with tf.variable_scope('fc7'):\n",
        "        # w =  tf.get_variable('kernel', initializer = random_values([256,128]))\n",
        "        # b = tf.get_variable('bias',initializer =tf.ones(shape = [128]), dtype=tf.float32)\n",
        "        w =  tf.get_variable('kernel', initializer = random_values([256,128]))\n",
        "        b = tf.get_variable('bias',initializer =tf.ones(shape = [128]), dtype=tf.float32)\n",
        "    f7 = tf.nn.relu(tf.matmul(f6, pruning.apply_mask(w,'fc7')) + b)\n",
        "    print(np.shape(f7))\n",
        "    # f7 = layers.dense(f6, 4096, activation='relu', name=\"fc7\")\n",
        "    f7 = tf.nn.dropout(f7, keep_prob=pkeep, name='f7_dropout')\n",
        "    # Set the number of output classes\n",
        "    with tf.variable_scope('fc8'):\n",
        "        # w = tf.get_variable('kernel', initializer = random_values([128,10]))\n",
        "        w = tf.get_variable('kernel', initializer = random_values([128,10]))\n",
        "        b = tf.get_variable('bias',initializer =tf.ones(shape = [10]), dtype=tf.float32)\n",
        "    f8 = (tf.matmul(f7, pruning.apply_mask(w,'fc8')) + b)\n",
        "    print(np.shape(f8))\n",
        "    #  f8 = tf.nn.softmax(tf.matmul(f7, pruning.apply_mask(w,'fc8')) + b)\n",
        "    #  f8 = layers.dense(f7, 1000, activation='softmax', name=\"fc8\")\n",
        "    f8 = tf.nn.dropout(f8, keep_prob=pkeep, name='f8_dropout')\n",
        "    \n",
        "    return [c1,c2,c3,c4,c5,f6,f7,f8]\n",
        "\n",
        "\n",
        "def AlexNet_small(X):\n",
        "    with tf.variable_scope('conv1'):\n",
        "        w = tf.get_variable('kernel', [3,3,3,64])\n",
        "        b = tf.get_variable('bias',shape = [64])\n",
        "    # Choose stride from 1 or 4 depending on CIFAR or Imagenet    \n",
        "    c1 = tf.nn.conv2d(X, pruning.apply_mask(w,'conv1'), strides = [1, 1, 1, 1], padding=\"SAME\")\n",
        "    c1 = c1 + b\n",
        "    c1 = tf.nn.relu(c1)\n",
        "    print(np.shape(c1))\n",
        "    # c1 = layers.conv2d(X, filters=96, kernel_size=11, strides=4, padding=\"SAME\", activation='relu', name='conv1')\n",
        "    lrn1 = tf.nn.lrn(c1, depth_radius=2, alpha=1e-05, beta=0.75, bias=1.0)\n",
        "    m1 = layers.max_pooling2d(lrn1, pool_size=2, strides=1, padding=\"VALID\")\n",
        "        \n",
        "    c2 = conv2d_split(m1, filters=192, kernel_size=3, strides=2, name=\"conv2\", activation=tf.nn.relu)\n",
        "    print(np.shape(c2))\n",
        "    lrn2 = tf.nn.lrn(c2, depth_radius=2, alpha=1e-05, beta=0.75, bias=1.0)\n",
        "    m2 = layers.max_pooling2d(lrn2, pool_size=2, strides=1, padding=\"VALID\")\n",
        "    \n",
        "    with tf.variable_scope('conv3'):\n",
        "        w = tf.get_variable('kernel', [3,3,192,384])\n",
        "        b = tf.get_variable('bias',shape = [384])\n",
        "    c3 = tf.nn.conv2d(m2, pruning.apply_mask(w,'conv3'), strides = [1, 2, 2, 1], padding=\"SAME\")\n",
        "    c3 = c3 + b\n",
        "    c3 = tf.nn.relu(c3)\n",
        "    # c3 = layers.conv2d(m2, filters=384, kernel_size=3, strides=1, padding=\"SAME\", activation='relu', name='conv3')\n",
        "    print(np.shape(c3))\n",
        "    c4 = conv2d_split(c3, filters=256, kernel_size=3, strides=1, name=\"conv4\", activation=tf.nn.relu)\n",
        "    print(np.shape(c4))\n",
        "    \n",
        "    c5 = conv2d_split(c4, filters=256, kernel_size=3, strides=1, activation=tf.nn.relu, name='conv5')\n",
        "    print(np.shape(c5))\n",
        "    m5 = layers.max_pooling2d(c5, pool_size=3, strides=2, padding=\"VALID\")\n",
        "    m5 = layers.flatten(m5)\n",
        "    print(np.shape(m5))\n",
        "    # Choose dim from [2304,512] or [9216,4096] depending on CIFAR or Imagenet  \n",
        "    with tf.variable_scope('fc6'):\n",
        "        w = tf.get_variable('kernel',[2304,1024])\n",
        "        b = tf.get_variable('bias',shape=[1024])\n",
        "    f6 = tf.nn.relu(tf.matmul(m5, pruning.apply_mask(w,'fc6')) + b)\n",
        "    # f6 = layers.dense(m5, 4096, activation='relu', name=\"fc6\")\n",
        "\n",
        "    # Choose dim from [512,512] or [4096,4096] depending on CIFAR or Imagenet \n",
        "    with tf.variable_scope('fc7'):\n",
        "        w = tf.get_variable('kernel',[1024,256])\n",
        "        b = tf.get_variable('bias',shape=[256])\n",
        "    f7 = tf.nn.relu(tf.matmul(f6, pruning.apply_mask(w,'fc7')) + b)\n",
        "    # f7 = layers.dense(f6, 4096, activation='relu', name=\"fc7\")\n",
        "\n",
        "    # Set the number of output classes\n",
        "    with tf.variable_scope('fc8'):\n",
        "        w = tf.get_variable('kernel',[256,10])\n",
        "        b = tf.get_variable('bias',shape=[10])\n",
        "    f8 = (tf.matmul(f7, pruning.apply_mask(w,'fc8')) + b)\n",
        "    # f8 = tf.nn.softmax(tf.matmul(f7, pruning.apply_mask(w,'fc8')) + b)\n",
        "    # f8 = layers.dense(f7, 1000, activation='softmax', name=\"fc8\")\n",
        "\n",
        "    return f8\n",
        "\n",
        "# load inital weights and biases to the model\n",
        "def load_initial_weights(session):\n",
        "    # load the weights into memory\n",
        "    weights_dict = np.load('drive/My Drive/Colab Notebooks/AlexNet_trained/bvlc_alexnet.npy', encoding='bytes').item()\n",
        "    # Create a dictionary with all global variables available\n",
        "    var_dict = dict((v.name, v) for v in tf.global_variables())\n",
        "    #print(v for v in var_dict.keys())\n",
        "    # loop over all layer names stored in the weights dict\n",
        "    for layer in weights_dict:\n",
        "        with tf.variable_scope(layer, reuse=True):\n",
        "            # loop over list of weights/biases and assign them to their corresponding tf variable\n",
        "            for wb in weights_dict[layer]:\n",
        "                # biases\n",
        "                if len(wb.shape) == 1:\n",
        "                    bias = var_dict[layer+'/bias:0']\n",
        "                    session.run(bias.assign(wb))\n",
        "                # weights\n",
        "                else:\n",
        "                    weight =  var_dict[layer+'/kernel:0']\n",
        "                    session.run(weight.assign(wb))\n",
        "                    \n",
        "# load the ImageNet ILSVRC dataset for retraining\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr9LoklZ5cJa",
        "colab_type": "text"
      },
      "source": [
        "#### Train AlexNet on Cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S9dB2XKt-Bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "56301980-8b1a-41af-c906-dfa7395639f4"
      },
      "source": [
        "file_path = 'drive/My Drive/Colab Notebooks Old/'\n",
        "n_out = 10 # number of output classes\n",
        "batch_size = 128\n",
        "\n",
        "#### Load Data A\n",
        "# data = Cifar(file_path+'cifar-10-batches-py/',batch_size)\n",
        "# print('Size of dataset:',len(data.__res__))\n",
        "# x_test, y_test = transform_to_input_output(data.test_set, dim=n_out)\n",
        "# ### Do this if using augmented data ###\n",
        "# x_train = np.array([row[0] for row in data.__res__])\n",
        "# y_train = np.array(np.reshape([row[1] for row in data.__res__],(-1,1)))\n",
        "# # Augment the dataset\n",
        "# print(np.shape(x_train),np.shape(y_train))\n",
        "# datagen = ImageDataGenerator(rotation_range=90, width_shift_range=0.1, \n",
        "#                              height_shift_range=0.1, horizontal_flip=True)\n",
        "# datagen.fit(x_train)\n",
        "# gen = datagen.flow(x_train,y_train,batch_size=batch_size)\n",
        "\n",
        "#### Load Data B\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train_, x_test_, y_train_, y_test_= [],[],[],[]\n",
        "for i in range(len(x_train)):\n",
        "    # x_train_.append(scipy.misc.imresize(x_train[i],size=(img_size,img_size),interp='bicubic'))\n",
        "    x_train_.append(np.array(Image.fromarray(x_train[i]).resize((img_size,img_size))))\n",
        "for i in range(len(x_test)):\n",
        "    # x_test_.append(scipy.misc.imresize(x_test[i],size=(img_size,img_size),interp='bicubic')) \n",
        "    x_test_.append(np.array(Image.fromarray(x_test[i]).resize((img_size,img_size))))\n",
        "x_train = np.array(x_train_)\n",
        "x_test = np.array(x_test_)\n",
        "x_test, y_test = transform_to_input_output(zip(x_test,y_test), dim=n_out)\n",
        "datagen = ImageDataGenerator(rotation_range=90, width_shift_range=0.1, \n",
        "                             height_shift_range=0.1, horizontal_flip=True)\n",
        "datagen.fit(x_train)\n",
        "gen = datagen.flow(x_train,y_train,batch_size=batch_size)\n",
        "\n",
        "n_epochs = 60\n",
        "\n",
        "# Reset graph and define model\n",
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(shape=[None, img_size, img_size, 3], dtype=tf.float32, name='X')\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "model = AlexNet(X,0.9)\n",
        "alex = model[7]\n",
        "# Define tensor name for model output so it can be restored\n",
        "model_output =  tf.identity(alex, name=\"model_output\")\n",
        "\n",
        "learning_rate = 5e-3    \n",
        "momentum = 0.9\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=alex, labels=y))\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(?, 70, 70, 3)\n",
            "(?, 18, 18, 96)\n",
            "WARNING:tensorflow:From <ipython-input-4-b0d665815e61>:53: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/pooling.py:311: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "(?, 8, 8, 256)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 256)\n",
            "WARNING:tensorflow:From <ipython-input-4-b0d665815e61>:75: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "(?, 256)\n",
            "(?, 128)\n",
            "WARNING:tensorflow:From <ipython-input-4-b0d665815e61>:94: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "(?, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDFAQfNp5wSC",
        "colab_type": "text"
      },
      "source": [
        "##### Execute training( Skip if trained )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTp_xQB5htD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "4eec2001-4d93-4573-c6bc-868b7e3cd9f4"
      },
      "source": [
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \n",
        "                                       momentum=momentum).minimize(cost)\n",
        "# load_path = file_path + \"AlexNet_Cifar_trained100_noLRN_5.ckpt\"\n",
        "save_name = \"AlexNet_Cifar_trained100_noLRN_4.ckpt\"\n",
        "saver = tf.train.Saver() \n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    correct_pred = tf.equal(tf.argmax(alex, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    # saver.restore(sess,load_path)\n",
        "    for epoch in range(n_epochs):\n",
        "        batches = 0\n",
        "        for ip, op in gen:\n",
        "            batch_x, batch_y = transform_to_input_output(zip(ip,op), dim=n_out)\n",
        "            sess.run([optimizer], feed_dict={X: batch_x, y: batch_y})\n",
        "            batches+=1\n",
        "            if batches >= len(x_train)/batch_size:\n",
        "                break\n",
        "            \n",
        "        acc = sess.run(accuracy, feed_dict={X: batch_x, y: batch_y})\n",
        "        loss = sess.run(cost, feed_dict={X: batch_x, y: batch_y})                       \n",
        "        print(\"epoch {} Acc: {} Loss: {}\".format(epoch, acc, loss))\n",
        "    \n",
        "        test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test})    \n",
        "        print(\"Test set accuracy: {}\".format(test_acc))\n",
        "\n",
        "    save_path = saver.save(sess, file_path+save_name)\n",
        "    print(\"Model saved in path: %s\" % save_path)\n",
        "    \n",
        "#####\n",
        "# 100_1:original alexnet, p=0.7, b=128 (64%)\n",
        "# 100_2:128,128, p=0.8, b=128 (64%)\n",
        "# 100_3:256,128, p=0.8, b=128 (65%)\n",
        "# 100_4:4096, 4096, p=0.8, b=128 (68%) augmented data\n",
        "# 100_x:4096, 1024, p=0.6, b=128 (53%)\n",
        "# 100_5:256,128, p=0.7, b=256 (56%)\n",
        "# 100_6:256,128, p=0.75, b=64 (62.3%)\n",
        "# 100_7:256,128, p=0.9, b=64 (70.4%)\n",
        "# 100_8:256,128, p=0.9, b=128 (71.5%) augmented data, can train more\n",
        "# 100_9:256,128, p=0.9, b=128 (73%) augmented data, can train more\n",
        "# 100_noLRN1,128,p=0.9, b=128 (71.5%) augmented data, no LRN layers\n",
        "# 100_noLRN3,128,p=0.9, b=128 (74.5%) augmented data, no LRN layers, 120 epochs\n",
        "\n",
        "# 100_noLRN6,256,256,p=0.7, (60.5%) 100 epochs\n",
        "# 100_noLRN7,"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e37782fdcd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load_path = file_path + \"AlexNet_Cifar_trained100_noLRN_5.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"AlexNet_Cifar_trained100_noLRN_4.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    826\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    827\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           build_restore=build_restore)\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     saveables = saveable_object_util.validate_and_slice_inputs(\n\u001b[0;32m--> 482\u001b[0;31m         names_to_saveables)\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mvalidate_and_slice_inputs\u001b[0;34m(names_to_saveables)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \"\"\"\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_list_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mop_list_to_dict\u001b[0;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m           raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 293\u001b[0;31m                            name)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: conv1/bias"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw7zSYWNrQM0",
        "colab_type": "text"
      },
      "source": [
        "#### Prune original model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07SKfF5WnRmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To load and resave old checkpoints with added name of model output op\n",
        "# so model can be restored using the meta file.\n",
        "\n",
        "# # reset_graph()\n",
        "# model_path = file_path+\"ensemble_exp/AlexNet_noLRN3_pruned95.ckpt\"\n",
        "# # save_path = file_path+\"ensemble_exp/AlexNet_noLRN8_pruned95.ckpt\"\n",
        "# # meta_name = file_path+\"ensemble_exp/AlexNet_noLRN5_pruned95.ckpt.meta\"\n",
        "\n",
        "# saver = tf.train.Saver()\n",
        "# # new_saver = tf.train.import_meta_graph(meta_name)\n",
        "\n",
        "# with tf.Session() as sess:\n",
        "#     saver.restore(sess, model_path)\n",
        "#     saver.save(sess, model_path)\n",
        "#     # new_saver.restore(sess, save_path)\n",
        "#     for op in tf.get_default_graph().get_operations():\n",
        "#         print(str(op.name))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqfrku2TrQ_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "a1391e68-2809-423e-b76a-b84552b69c54"
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "\n",
        "model_path = file_path+\"AlexNet_Cifar_trained100_noLRN_3.ckpt\"\n",
        "save_name = \"ensemble_exp/AlexNet_noLRN3_pruned97.ckpt\"\n",
        "target_sparsity = 0.97\n",
        "# ensemble_seed = 1\n",
        "# save_name = \"AlexNet_noLRN3_pruned_x.ckpt\"\n",
        "\n",
        "rand_prune = 0.3 # Fraction of l7 and l8 weights to be deleted randomly b4 pruning\n",
        "n_epochs = 100\n",
        "\n",
        "# Define reduced dataset\n",
        "fraction = 10       # Training is done only on 1/fraction of the dataset \n",
        "print_freq = 10     # How often to print losses during training\n",
        "dataset_size = int(50000/fraction)\n",
        "batch_size = 1250\n",
        "\n",
        "idx = random.sample(range(50000), dataset_size)\n",
        "x_train_ = []\n",
        "y_train_ = []\n",
        "for i in idx:\n",
        "    x_train_.append(x_train[i])\n",
        "    y_train_.append(y_train[i])\n",
        "x_train_ = np.array(x_train_)\n",
        "y_train_ = np.array(y_train_)\n",
        "datagen.fit(x_train_)\n",
        "gen = datagen.flow(x_train_,y_train_,batch_size=batch_size)\n",
        "\n",
        "# Get variables for random pruning of layer 7 and 8\n",
        "# np.random.seed(ensemble_seed)\n",
        "# with tf.variable_scope('fc7'):\n",
        "#     tf.get_variable_scope().reuse_variables() \n",
        "#     w7 =  tf.get_variable('kernel', initializer = random_values([256,128]))\n",
        "#     mask1 = tf.cast(np.random.choice(a=[False, True], size=np.shape(w7), \n",
        "#                                      p=[rand_prune, 1-rand_prune]),w7.dtype)      \n",
        "#     b7 = tf.get_variable('bias',initializer =tf.ones(shape = [128]), dtype=tf.float32)\n",
        "#     mask2 = tf.cast(np.random.choice(a=[False, True], size=np.shape(b7), \n",
        "#                                      p=[rand_prune, 1-rand_prune]),b7.dtype)    \n",
        "    \n",
        "# with tf.variable_scope('fc8'):\n",
        "#     tf.get_variable_scope().reuse_variables() \n",
        "#     w8 = tf.get_variable('kernel', initializer = random_values([128,10]))\n",
        "#     mask3 = tf.cast(np.random.choice(a=[False, True], size=np.shape(w8), \n",
        "#                                      p=[rand_prune, 1-rand_prune]),w8.dtype)       \n",
        "#     b8 = tf.get_variable('bias',initializer =tf.ones(shape = [10]), dtype=tf.float32)\n",
        "#     mask4 = tf.cast(np.random.choice(a=[False, True], size=np.shape(b8), \n",
        "#                                      p=[rand_prune, 1-rand_prune]),b8.dtype)  \n",
        "\n",
        "# Pruning code begins\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "reset_global_step_op = tf.assign(global_step, 0)\n",
        "\n",
        "pruning_hparams = pruning.get_pruning_hparams()\n",
        "# Change hyperparameters to meet our needs\n",
        "pruning_hparams.begin_pruning_step = 0\n",
        "pruning_hparams.end_pruning_step = 100  # dataset_size/batch_size #steps/epoch\n",
        "pruning_hparams.pruning_frequency = 1\n",
        "pruning_hparams.sparsity_function_end_step = 100\n",
        "pruning_hparams.target_sparsity = target_sparsity\n",
        "\n",
        "print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
        "\n",
        "# Create a pruning object using the pruning specification, sparsity seems to have priority over the hparam\n",
        "p = pruning.Pruning(pruning_hparams, global_step=global_step)\n",
        "prune_op = p.conditional_mask_update_op()\n",
        "\n",
        "learning_rate = 5e-3    \n",
        "momentum = 0.9\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=alex, labels=y))\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \n",
        "                                       momentum=momentum).minimize(cost, global_step =global_step)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "#     X = tf.placeholder(shape=[None, 70, 70, 3], dtype=tf.float32, name='X')\n",
        "#     alex = AlexNet(X)\n",
        "    init = tf.global_variables_initializer() # needs to be defined after model is generated\n",
        "    sess.run(init)\n",
        "    # Restore original trained weights\n",
        "    saver.restore(sess, model_path)\n",
        "    \n",
        "    correct_pred = tf.equal(tf.argmax(alex, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print(\"Accuracy of original model: \",sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "\n",
        "    # Randomly delete 10% weights in layer 7 and layer 8\n",
        "    # sess.run(tf.assign(w7, w7*mask1)) \n",
        "    # sess.run(tf.assign(w8, w8*mask3))\n",
        "\n",
        "    print(\"Accuracy after random pruning: \",sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    \n",
        "    sess.run(reset_global_step_op)\n",
        "    print(\"Sparsity before pruning\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
        "    print(\"Starting with retraining\")\n",
        "    \n",
        "\n",
        "#     gen = datagen.flow(x_train,y_train,batch_size=batch_size)\n",
        "    for epoch in range(n_epochs):\n",
        "        batches = 0\n",
        "        for ip, op in gen:\n",
        "            batch_x, batch_y = transform_to_input_output(zip(ip,op), dim=n_out)\n",
        "            sess.run(prune_op)\n",
        "            sess.run([optimizer], feed_dict={X: batch_x, y: batch_y})\n",
        "            \n",
        "            batches+=1\n",
        "            if batches >= len(x_train)/batch_size/fraction:\n",
        "                break\n",
        "        if epoch%print_freq == 0:\n",
        "                print(sess.run([cost],{X:batch_x, y:batch_y}))\n",
        "                print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
        "\n",
        "    #Save trained model\n",
        "    save_path = saver.save(sess, file_path+save_name)\n",
        "    print(\"Model saved in path: %s\" % save_path)\n",
        "\n",
        "    print(\"Accuracy after gradual pruning and retraining\",sess.run(accuracy, feed_dict={X: x_test, y: y_test}))\n",
        "    \n",
        "    \"\"\" Results:\n",
        "    Filenames: \"AlexNet_pruned_<75>.ckpt\" orig acc: 73 \n",
        "    sparsity: 0.75 pruning_period: 100 epochs: 130 accuracy: 73\n",
        "    sparsity: 0.8 pruning_period: 100 epochs: 150 accuracy: 71.84\n",
        "    sparsity: 0.85 pruning_period: 100 epochs: 130 accuracy: 69.72\n",
        "    sparsity: 0.9 pruning_period: 100 epochs: 130 accuracy: 63.69\n",
        "    sparsity: 0.95 pruning_period: 100 epochs: 130 accuracy: 48.78\n",
        "\n",
        "    Filenames: \"AlexNet_noLRN_pruned_<75>.ckpt\" orig acc: 71.4\n",
        "    sparsity: 0.75 pruning_period: 100 epochs: 130 accuracy:70.88 \n",
        "    sparsity: 0.75_ pruning_period: 50 epochs: 100 accuracy:69.42\n",
        "    sparsity: 0.75__ pruning_period: 100, pruning_freq:5 epochs: 130 accuracy: 70.85\n",
        "    sparsity: 0.80 pruning_period:100 epochs: 130 accuracy: 69.58\n",
        "    sparsity: 0.85 pruning_period:100 epochs: 130 accuracy: 67.49\n",
        "    sparsity: 0.90 pruning_period:100 epochs: 130 accuracy: 61.87\n",
        "    \"\"\"\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=100,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.97,sparsity_function_begin_step=0,sparsity_function_end_step=100,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/AlexNet_Cifar_trained100_noLRN_3.ckpt\n",
            "Accuracy of original model:  0.7459\n",
            "Accuracy after random pruning:  0.7453\n",
            "Sparsity before pruning [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Starting with retraining\n",
            "[0.47438908]\n",
            "Weight sparsities: [0.08471074, 0.08470704, 0.08470663, 0.08470775, 0.08470775, 0.08470154, 0.0847168, 0.084375]\n",
            "[1.1512614]\n",
            "Weight sparsities: [0.79037535, 0.79036134, 0.79036236, 0.7903631, 0.79036236, 0.7903595, 0.79037476, 0.79062504]\n",
            "[2.0854561]\n",
            "Weight sparsities: [0.9652204, 0.9652344, 0.9652348, 0.9652341, 0.9652348, 0.9652405, 0.9652405, 0.965625]\n",
            "[1.8862427]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.8404355]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.7663654]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.7833838]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.7175725]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.6713779]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "[1.6492531]\n",
            "Weight sparsities: [0.9700126, 0.97, 0.9700001, 0.9699994, 0.9700001, 0.9700012, 0.9700012, 0.97031254]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN3_pruned97.ckpt\n",
            "Accuracy after gradual pruning and retraining 0.419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqdx05_vzaLv",
        "colab_type": "text"
      },
      "source": [
        "#### Quantize original model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTJvddgYzfX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "2081cfdc-0970-45f6-e7c7-f933cae3d4e5"
      },
      "source": [
        "# model_path = file_path+\"AlexNet_noLRN_pruned_75.ckpt\"\n",
        "model_path = file_path+ \"AlexNet_Cifar_trained100_noLRN_1.ckpt\"\n",
        "saver = tf.train.Saver()\n",
        "init = tf.global_variables_initializer()\n",
        "# newSaver = tf.train.Saver({\"W1\":W1,\"B1\":B1,\"W2\":W2,\"B2\":B2,\"W3\":W3,\"B3\":B3,\"W4\":W4,\"B4\":B4,\"W5\":W5,\"B5\":B5,\n",
        "#                            \"W1_\":W1_,\"B1_\":B1_,\"W2_\":W2_,\"B2_\":B2_,\"W3_\":W3_,\"B3_\":B3_,\"W4_\":W4_,\"B4_\":B4_,\"W5_\":W5_,\"B5_\":B5_})\n",
        "\n",
        "# First get old variable and then initialize new variables with old variables\n",
        "with tf.variable_scope('conv1'):\n",
        "    tf.get_variable_scope().reuse_variables()        \n",
        "    w1_ = tf.get_variable('kernel', [11, 11, 3, 96])\n",
        "    b1_ = tf.get_variable('bias',shape = [96])\n",
        "with tf.variable_scope('conv2'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w2_ = tf.get_variable('kernel', [5, 5, 48, 256])\n",
        "    b2_ = tf.get_variable('bias',shape = [256])\n",
        "with tf.variable_scope('conv3'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w3_ = tf.get_variable('kernel', [3, 3, 256, 384])\n",
        "    b3_ = tf.get_variable('bias',shape = [384])\n",
        "with tf.variable_scope('conv4'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w4_ = tf.get_variable('kernel', [3, 3, 192, 384])\n",
        "    b4_ = tf.get_variable('bias',shape = [384])\n",
        "with tf.variable_scope('conv5'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w5_ = tf.get_variable('kernel', [3, 3, 192, 256])\n",
        "    b5_ = tf.get_variable('bias',shape = [256])\n",
        "with tf.variable_scope('fc6'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w6_ = tf.get_variable('kernel', [256, 256])\n",
        "    b6_ = tf.get_variable('bias',shape = [256])\n",
        "with tf.variable_scope('fc7'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w7_ = tf.get_variable('kernel', [256, 128])\n",
        "    b7_ = tf.get_variable('bias',shape = [128])\n",
        "with tf.variable_scope('fc8'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w8_ = tf.get_variable('kernel', [128, 10])\n",
        "    b8_ = tf.get_variable('bias',shape = [10])\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    sess.run(init)\n",
        "    # Restore original trained weights\n",
        "    saver.restore(sess, model_path)\n",
        "\n",
        "    # Print max and min weight values\n",
        "    maxW = sess.run(tf.math.reduce_max(w1_))\n",
        "    minW = sess.run(tf.math.reduce_min(w1_))\n",
        "    meanW = sess.run(tf.math.reduce_mean(w1_))\n",
        "    print(\"{min,max,mean}: {\",minW,maxW,meanW,\"}\")\n",
        "    \n",
        "    # Evaluate performance\n",
        "    correct_pred = tf.equal(tf.argmax(alex, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print(\"Test accuracy before quant: \",sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    \n",
        "#     check = sess.run(tf.equal(parameters[:img_size,:h1],W1))\n",
        "#     print(check)\n",
        "    \n",
        "    multiplier = 1024  #(clip_max-clip_min)/2^(new_precision), 128 for 8bit\n",
        "    clip_min = -0.5\n",
        "    clip_max = 0.5\n",
        "    \n",
        "    quant_op1 = w1_.assign(tf.math.round(tf.clip_by_value(w1_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op2 = w2_.assign(tf.math.round(tf.clip_by_value(w2_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op3 = w3_.assign(tf.math.round(tf.clip_by_value(w3_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op4 = w4_.assign(tf.math.round(tf.clip_by_value(w4_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op5 = w5_.assign(tf.math.round(tf.clip_by_value(w5_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op6 = w6_.assign(tf.math.round(tf.clip_by_value(w6_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op7 = w7_.assign(tf.math.round(tf.clip_by_value(w7_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op8 = w8_.assign(tf.math.round(tf.clip_by_value(w8_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "\n",
        "    quant_op9 = b1_.assign(tf.math.round(tf.clip_by_value(b1_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op10 = b2_.assign(tf.math.round(tf.clip_by_value(b2_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op11 = b3_.assign(tf.math.round(tf.clip_by_value(b3_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op12 = b4_.assign(tf.math.round(tf.clip_by_value(b4_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op13 = b5_.assign(tf.math.round(tf.clip_by_value(b5_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op14 = b6_.assign(tf.math.round(tf.clip_by_value(b6_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op15 = b7_.assign(tf.math.round(tf.clip_by_value(b7_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    quant_op16 = b8_.assign(tf.math.round(tf.clip_by_value(b8_,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    \n",
        "    sess.run(quant_op1)\n",
        "    sess.run(quant_op2)\n",
        "    sess.run(quant_op3)\n",
        "    sess.run(quant_op4)\n",
        "    sess.run(quant_op5)\n",
        "    sess.run(quant_op6)\n",
        "    sess.run(quant_op7)\n",
        "    sess.run(quant_op8)\n",
        "    sess.run(quant_op9)\n",
        "    sess.run(quant_op10)\n",
        "    sess.run(quant_op11)\n",
        "    sess.run(quant_op12)\n",
        "    sess.run(quant_op13)\n",
        "    sess.run(quant_op14)\n",
        "    sess.run(quant_op15)\n",
        "    sess.run(quant_op16)\n",
        "    \n",
        "    # Evaluate performance\n",
        "    correct_pred = tf.equal(tf.argmax(alex, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print(\"Test accuracy after quant: \",sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5d5780372f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model_path = file_path+\"AlexNet_noLRN_pruned_75.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"AlexNet_Cifar_trained100_noLRN_1.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# newSaver = tf.train.Saver({\"W1\":W1,\"B1\":B1,\"W2\":W2,\"B2\":B2,\"W3\":W3,\"B3\":B3,\"W4\":W4,\"B4\":B4,\"W5\":W5,\"B5\":B5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m    826\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m    827\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m    863\u001b[0m           \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No variables to save\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No variables to save"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et0byZ2i1lqX",
        "colab_type": "text"
      },
      "source": [
        "### Define modified model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cr319NW11Y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "327356a7-5538-4a6e-d286-845ff2a3da15"
      },
      "source": [
        "file_path = 'drive/My Drive/Colab Notebooks Old/'\n",
        "model_path = file_path+ \"AlexNet_Cifar_trained100_noLRN_3.ckpt\"\n",
        "\n",
        "# sx_labmix : mixed labels in dataset\n",
        "# sx_lab1: only samples with one label in dataset\n",
        "# Alex_seed5 has wrong results saved\n",
        "save_name = \"ensemble_exp/Alex_s10_labmix.ckpt\"  \n",
        "ensemble_seed = 10       #Seed for ensemble experiments\n",
        "\n",
        "reset_graph(seed=ensemble_seed)\n",
        "learning_rate = tf.placeholder(tf.float32)   \n",
        "momentum = 0.98\n",
        "\n",
        "X = tf.placeholder(shape=[None, img_size, img_size, 3], dtype=tf.float32, name='X')\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "model = AlexNet(X,0.9)\n",
        "alex = model[7]\n",
        "\n",
        "# Defined additional weights and new model\n",
        "with tf.variable_scope('Alex_new') as scope:\n",
        "    # Thesis result using 0.9 pkeep for dropout.\n",
        "    model_new = AlexNet(X,1)\n",
        "    alex_new = model_new[7]  #Final output of the new model\n",
        "\n",
        "# Regularization coefficient\n",
        "beta = tf.placeholder(tf.float32,name='Regu_coeff') # Variable beta for each layer\n",
        "\n",
        "# Map graph variables to python variables for defining regu loss, eigenvalue ops\n",
        "\n",
        "# First get old variable and then initialize new variables with old variables\n",
        "#\n",
        "# Initializer and var._read_value() doesn't work for our purpose here\n",
        "# https://github.com/tensorflow/tensorflow/issues/4920\n",
        "# Changed to simpler init, and tf.assign() used instead during graph execution\n",
        "#\n",
        "w_ = []\n",
        "b_ = []\n",
        "w = []\n",
        "b = []\n",
        "regularizer = []\n",
        "init_norm = []\n",
        "\n",
        "with tf.variable_scope('conv1'):\n",
        "    tf.get_variable_scope().reuse_variables()        \n",
        "    w_.append(tf.get_variable('kernel', [11, 11, 3, 96]))\n",
        "    b_.append(tf.get_variable('bias',shape = [96]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('conv1'):\n",
        "        tf.get_variable_scope().reuse_variables()        \n",
        "        w.append(tf.get_variable('kernel', [11, 11, 3, 96]))\n",
        "        b.append(tf.get_variable('bias', [96]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('conv2'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [5, 5, 48, 256]))\n",
        "    b_.append(tf.get_variable('bias',shape = [256]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('conv2'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [5, 5, 48, 256]))\n",
        "        b.append(tf.get_variable('bias', [256]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('conv3'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [3, 3, 256, 384]))\n",
        "    b_.append(tf.get_variable('bias',shape = [384]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('conv3'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [3, 3, 256, 384]))\n",
        "        b.append(tf.get_variable('bias', [384]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('conv4'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [3, 3, 192, 384]))\n",
        "    b_.append(tf.get_variable('bias',shape = [384]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('conv4'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [3, 3, 192, 384]))\n",
        "        b.append(tf.get_variable('bias', [384]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('conv5'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [3, 3, 192, 256]))\n",
        "    b_.append(tf.get_variable('bias',shape = [256]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('conv5'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [3, 3, 192, 256]))\n",
        "        b.append(tf.get_variable('bias', [256]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('fc6'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [256, 256]))\n",
        "    b_.append(tf.get_variable('bias',shape = [256]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('fc6'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [256, 256]))\n",
        "        b.append(tf.get_variable('bias', [256]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('fc7'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [256, 128]))\n",
        "    b_.append(tf.get_variable('bias',shape = [128]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('fc7'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel',  [256, 128]))\n",
        "        b.append(tf.get_variable('bias', [128]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "with tf.variable_scope('fc8'):\n",
        "    tf.get_variable_scope().reuse_variables()\n",
        "    w_.append(tf.get_variable('kernel', [128, 10]))\n",
        "    b_.append(tf.get_variable('bias',shape = [10]))\n",
        "with tf.variable_scope('Alex_new'):\n",
        "    with tf.variable_scope('fc8'):\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        w.append(tf.get_variable('kernel', [128, 10]))\n",
        "        b.append(tf.get_variable('bias', [10]))\n",
        "regularizer.append(tf.norm(w[-1],ord=1) + tf.norm(b[-1],ord=1))\n",
        "init_norm.append(tf.norm(w_[-1],ord=1) + tf.norm(b_[-1],ord=1))\n",
        "\n",
        "# # Thesis implementation used  Reduction.MEAN, mean is over weights parameter of function, which equals 1 by default.\n",
        "# loss_ = []\n",
        "# for i in range(8):\n",
        "#     loss_.append(tf.losses.mean_squared_error(model[i], model_new[i], reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE)) \n",
        "# new_loss = []\n",
        "# for i in range(8):\n",
        "#     new_loss.append(tf.reduce_mean(loss_[i] + beta * regularizer[i]))\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=alex_new, labels=y))\n",
        "new_loss = []\n",
        "for i in range(8):\n",
        "    new_loss.append(tf.reduce_mean(loss + beta * regularizer[i]))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum)\n",
        "\n",
        "train_step = []\n",
        "for i in range(8):\n",
        "    train_step.append(optimizer.minimize(new_loss[i],var_list=[w[i],b[i]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 70, 70, 3)\n",
            "(?, 18, 18, 96)\n",
            "(?, 8, 8, 256)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 256)\n",
            "(?, 256)\n",
            "(?, 128)\n",
            "(?, 10)\n",
            "(?, 70, 70, 3)\n",
            "(?, 18, 18, 96)\n",
            "(?, 8, 8, 256)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 384)\n",
            "(?, 3, 3, 256)\n",
            "(?, 256)\n",
            "(?, 128)\n",
            "(?, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16CySLbZSyXC",
        "colab_type": "text"
      },
      "source": [
        "#### Train modified model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm9IBUo3SEcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate largest eigenvalue using power iteration\n",
        "def HessVecProd(ys,xs,v,grads):\n",
        "    \"\"\"Multiply the Hessian of `ys` wrt `xs` by `v`. \n",
        "    grads is passed additionally to avoid construction of gradient \n",
        "    ops each time this function is called\"\"\"\n",
        "    if v.shape != xs.shape:\n",
        "        raise ValueError(\"xs and v must have the same length.\")\n",
        "    # grads = tf.gradients(ys,xs)\n",
        "    gTv = tf.multiply(grads,v)\n",
        "    gTv = tf.reshape(gTv,[-1])  # Conver to 1-D list as gradient is computed over sum of list\n",
        "    Hv = tf.gradients(gTv,xs)[0] # Compute gradients\n",
        "    Hv = tf.stack(Hv)  # Merge list of tensors into a single tensor\n",
        "    return(Hv)\n",
        "\n",
        "def compute_eig(sess,data,loss,w,Beta=0,n_steps=5):\n",
        "    v = tf.Variable(tf.random_uniform(shape=tf.shape(w), minval=-0.2, maxval=0.2, dtype=tf.float32))\n",
        "    sess.run(v.initializer)\n",
        "    gradient = tf.gradients(loss,w)\n",
        "    HvW_op = HessVecProd(loss,w,v,gradient) # Define hessian vecotor computation op\n",
        "    sess.run(tf.assign(v,v/tf.norm(v)))  # normalize v\n",
        "    for i in range(n_steps):       \n",
        "        HvW = sess.run(HvW_op,{X: data[0], y: data[1], beta: Beta})\n",
        "        eig_op = tf.norm(HvW)\n",
        "        eig = sess.run(eig_op)\n",
        "        # print('eigenvalue estimate: ',eig)\n",
        "        sess.run(tf.assign(v,HvW/eig))\n",
        "    # print(eig)\n",
        "    return eig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4FUwnjokt1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "# file_path = 'drive/My Drive/Colab Notebooks Old/'\n",
        "\n",
        "# variables_to_restore = tf.train.list_variables(model_path)\n",
        "variables = tf.global_variables()\n",
        "# Extra conditions added below to use saved checkpoint with momentum optimizer when new optimizer is Adam\n",
        "variables_to_restore = [v for v in variables if (v.name.split('/')[0]!='Alex_new' and v.name.split('_')[0]!='beta1' and v.name.split('_')[0]!='beta2')] \n",
        "saver = tf.train.Saver(variables_to_restore)\n",
        "\n",
        "variables_to_save = [v for v in variables if v.name.split('/')[0]=='Alex_new'] \n",
        "newSaver = tf.train.Saver(variables_to_save)\n",
        "\n",
        "# n_epochs = 50\n",
        "n_min = 50      # #epochs to train each layer\n",
        "n_search = 2   # #epochs to search for solution with best eigenvalue\n",
        "n_epochs = n_min + n_search # total number of epochs\n",
        "search_freq = 1 # how frequently to check eigenvalue\n",
        "eig_steps = 6\n",
        "\n",
        "fraction = 10   # Training is done only on 1/fraction of the dataset \n",
        "print_freq = 10   # How often to print losses and compute eigenvalues during training\n",
        "batch_size = 1250 # Selected to be large enough so <10 steps in each epoch for shorter training time\n",
        "\n",
        "# To find indices of samples corresponding to each label\n",
        "label_idx = []\n",
        "for i in range(10):\n",
        "    label_idx.append([ j for j in range(len(y_train)) if y_train[j] == i ])\n",
        "\n",
        "# # Define reduced dataset having samples from only one label selected based on seed\n",
        "# if ensemble_seed <10 and ensemble_seed >=0:\n",
        "#     label = ensemble_seed            # label: selected label of samples to have in dataset\n",
        "# else:\n",
        "#     label = 9\n",
        "# dataset_size = int(50000/fraction)\n",
        "# idx = random.sample(range(5000), dataset_size)\n",
        "# x_train_ = []\n",
        "# y_train_ = []\n",
        "# for i in idx:\n",
        "#     x_train_.append(x_train[label_idx[label][i]])\n",
        "#     y_train_.append(y_train[label_idx[label][i]])\n",
        "# x_train_ = np.array(x_train_)\n",
        "# y_train_ = np.array(y_train_)\n",
        "# datagen.fit(x_train_)\n",
        "# gen = datagen.flow(x_train_,y_train_,batch_size=batch_size)\n",
        "\n",
        "# Define reduced dataset having mutually exclusive samples for different seed\n",
        "dataset_size = int(50000/fraction)\n",
        "random.seed(1)\n",
        "data_idx = [i for i in range(50000)]\n",
        "idx = random.sample(data_idx, dataset_size)\n",
        "# To select exclusive subset of values for each seed, starting from seed 1\n",
        "if ensemble_seed >1:                        \n",
        "    for i in range(ensemble_seed-1):\n",
        "        for j in range(len(idx)):\n",
        "            data_idx.remove(idx[j])\n",
        "        idx = random.sample(data_idx,dataset_size)\n",
        "x_train_ = []\n",
        "y_train_ = []\n",
        "for i in idx:\n",
        "    x_train_.append(x_train[i])\n",
        "    y_train_.append(y_train[i])\n",
        "x_train_ = np.array(x_train_)\n",
        "y_train_ = np.array(y_train_)\n",
        "datagen.fit(x_train_)\n",
        "gen = datagen.flow(x_train_,y_train_,batch_size=batch_size)\n",
        "\n",
        "# To selectively initialize uninitialized variables\n",
        "def initialize_uninitialized(sess):\n",
        "    global_vars          = tf.global_variables()\n",
        "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
        "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
        "\n",
        "#     print([str(i.name) for i in not_initialized_vars]) # only for testing\n",
        "    if len(not_initialized_vars):\n",
        "        sess.run(tf.variables_initializer(not_initialized_vars))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxNjEHFfSy9b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "094eebe3-ce00-4098-83a6-8564da9a4c21"
      },
      "source": [
        "\"\"\" \n",
        "AlexNet_noLRN_same: initialized to same value as original model\n",
        "same3: training layer 1 first followed by layer 2...\n",
        "same4: training layer 8 first followed by layer 7...\n",
        "\"\"\"\n",
        "\n",
        "eig = []\n",
        "\n",
        "lr_coeff = 1e-4\n",
        "beta_coeff = 1e-3\n",
        "print('lr_coeff:',lr_coeff)\n",
        "print('beta_coeff:',beta_coeff)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver.restore(sess, model_path)\n",
        "    \n",
        "    # Define accuracy ops\n",
        "    correct_prediction = tf.equal(tf.argmax(alex_new,1), tf.argmax(y,1))\n",
        "    correct_prediction_orig = tf.equal(tf.argmax(alex,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    accuracy_orig = tf.reduce_mean(tf.cast(correct_prediction_orig, tf.float32))\n",
        "\n",
        "    # Initialize new model with trained values  \n",
        "    for i in range(8):\n",
        "        sess.run(w[i].assign(w_[i]))  \n",
        "    \n",
        "    # Initialize remaining variables\n",
        "    initialize_uninitialized(sess)\n",
        "\n",
        "    # Reference dataset for eigenvalue computation\n",
        "    for ip, op in datagen.flow(x_train_,y_train_,batch_size=dataset_size):\n",
        "        x_ref, y_ref = transform_to_input_output(zip(ip,op), dim=n_out)\n",
        "        break\n",
        "\n",
        "    init_norm_val = sess.run(init_norm)\n",
        "    print(init_norm_val)\n",
        "    # beta_val = np.float32([alpha/i for i in init_norm])\n",
        "    beta_val = []\n",
        "\n",
        "    # Print eigenvalues before training\n",
        "    for i in range(8):\n",
        "        print(compute_eig(sess,[x_ref,y_ref],loss,w[i],n_steps=eig_steps))\n",
        "\n",
        "    # Train layers from last to first \n",
        "    for i in range(8):\n",
        "        print(\"Training layer \"+str(8-i)+\". {[Total loss, MSE loss], eigenvalue}:\")\n",
        "        \n",
        "        if i == 5:          # layer 3, don't init to random value, custom beta,lr\n",
        "            lr = 1e-5\n",
        "            beta_val.append(1e-4*l_size/eig_local)\n",
        "            print('learning rate(lr_coeff/eig_local): ',lr) \n",
        "            print('Regu coeff: ',beta_val[-1]) \n",
        "        elif i>5:           # layer 1,2, don't init to random value\n",
        "            eig_local = compute_eig(sess,[x_ref,y_ref],loss,w[7-i],n_steps=eig_steps)\n",
        "            lr = lr_coeff\n",
        "            beta_val.append(beta_coeff*l_size/eig_local)\n",
        "            print('learning rate(lr_coeff/eig_local): ',lr) \n",
        "            print('Regu coeff: ',beta_val[-1]) \n",
        "        else:\n",
        "            sess.run(tf.variables_initializer([w[7-i],b[7-i]]))\n",
        "\n",
        "            # Determine learning rate and regularization coefficient\n",
        "            l_shape = np.shape(model_new[7-i])    # next layer shape\n",
        "            # for k in range(len(l_shape)-1):\n",
        "            #     l_size = l_size*l_shape[k+1]\n",
        "            # l_size = int(l_size)\n",
        "            l_size = 1                          # No. of output neurons\n",
        "            eig_local = compute_eig(sess,[x_ref,y_ref],loss,w[7-i],n_steps=eig_steps)            \n",
        "            # lr = lr_coeff/eig_local\n",
        "            lr = lr_coeff\n",
        "            beta_val.append(beta_coeff*l_size/eig_local)\n",
        "            print('learning rate(lr_coeff/eig_local): ',lr) \n",
        "            print('Regu coeff: ',beta_val[-1]) \n",
        "\n",
        "        eig.append([])\n",
        "        local_saver = tf.train.Saver({('w'+str(7-i)): w[7-i], ('b'+str(7-i)): b[7-i]})\n",
        "        eig_min = 999999\n",
        "        for epoch in range(n_epochs):\n",
        "            batches = 0\n",
        "            for ip, op in gen:\n",
        "                batch_x, batch_y = transform_to_input_output(zip(ip,op), dim=n_out)                    \n",
        "                sess.run(train_step[7-i], {X:batch_x, y:batch_y, beta:beta_val[-1], learning_rate:lr})\n",
        "                batches+=1\n",
        "                if batches >= len(x_train)/batch_size/fraction:\n",
        "                    break\n",
        "            if epoch%print_freq == 0:\n",
        "                print(sess.run([new_loss[7-i],loss],{X:batch_x, y:batch_y, beta:beta_val[-1]}))\n",
        "            if epoch>n_min:\n",
        "                if epoch%search_freq == 0:\n",
        "                    eig[i].append(compute_eig(sess,[x_ref,y_ref],loss,w[7-i],n_steps=eig_steps))\n",
        "                    print(sess.run([new_loss[7-i],loss],{X:batch_x, y:batch_y, beta:beta_val[-1]}), eig[i][-1]) \n",
        "                    if eig[i][-1] <= eig_min:\n",
        "                        eig_min = eig[i][-1]\n",
        "                        temp_save_path = local_saver.save(sess,file_path+'temp_save.ckpt')\n",
        "        # Restore to the model with minimum eigenvalue\n",
        "        local_saver.restore(sess,temp_save_path)\n",
        "        # Print performance of selcted solution\n",
        "        print('Selected model performance: ',\n",
        "              sess.run([new_loss[7-i],loss],{X:batch_x, y:batch_y, beta:beta_val[-1]}),\n",
        "              compute_eig(sess,[x_ref,y_ref],loss,w[7-i],n_steps=eig_steps))\n",
        "        print('New model accuracy:',sess.run(accuracy, feed_dict={X:x_test, y:y_test})) \n",
        "\n",
        "\n",
        "    # Print final eigenvalues\n",
        "    for i in range(8):\n",
        "         print(compute_eig(sess,[x_ref,y_ref],loss,w[i],n_steps=eig_steps))\n",
        "    \n",
        "    #Save trained model\n",
        "    save_path = newSaver.save(sess, file_path+save_name)\n",
        "    print(\"New model with trained L8 saved in path: %s\" % save_path)\n",
        "    i+=1\n",
        "\n",
        "    ######### Evaluate Performance ###########\n",
        "    print('New model accuracy:',sess.run(accuracy, feed_dict={X:x_test, y:y_test}))\n",
        "    print('Original model accuracy:',sess.run(accuracy_orig, feed_dict={X:x_test, y:y_test})) \n",
        "    \n",
        "    \"\"\"\n",
        "    1) regu_frac=0.01 epochs=5 accuracy: 73.06\n",
        "    2) regu_frac=0.05 epochs=5 accuracy: 73.06\n",
        "    3) regu_frac=0.05 epochs=10 accuracy: 72.9\n",
        "    4) (adaptive beta in l1,l2) regu_frac=10 epochs=10 accuracy: 72.95\n",
        "    5) (adaptive beta in all L) regu_frac=10 epochs=10 accuracy: 72.8\n",
        "    6) fixed beta epochs=50 accuracy: 73.01(overwritten with bad results)\n",
        "    7) NewTest trained to 72.3 accuracy, lambda 10^-6 for all. corrected \n",
        "    (label,prediction) order supplied to MSE function \n",
        "    8) NewTest trained to 76.28 accuracy, reduction changed to sum_over_batch_size, \n",
        "    1/20th dataset used. Adam optimizer, 9e-5 learning rate. \n",
        "    Explaination: earlier version probably required tuning different learning rates for each layer. \n",
        "    These trainings also seem very sensitive to learning rate.\n",
        "\n",
        "    Training on 1/20th of complete dataset for model without LRN. \n",
        "    save name = AlexNet_noLRN_same.ckpt\n",
        "    same: epochs=50  learning rate:9e-5   accuracy:73.99\n",
        "    same1: epochs=50  learning rate:5e-4   accuracy:73.99  \n",
        "    same2: epochs=100  learning rate:3.5e-5   accuracy:74.77  beta=1e-3\n",
        "\n",
        "    --------------------------------------------------\n",
        "    Training in reverse order from last layer to first\n",
        "\n",
        "    \"\"\"\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr_coeff: 0.0001\n",
            "beta_coeff: 0.001\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/AlexNet_Cifar_trained100_noLRN_3.ckpt\n",
            "[1992.4414, 7976.155, 18286.32, 13005.328, 7342.893, 1484.8911, 798.2844, 90.08429]\n",
            "Training layer 8. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  2.609945019152148e-05\n",
            "[2.3355432, 2.3350084]\n",
            "[1.7154232, 1.7148691]\n",
            "[1.3243461, 1.3237472]\n",
            "[1.112181, 1.1115276]\n",
            "[0.9446888, 0.9439794]\n",
            "[0.87385356, 0.87309015]\n",
            "[0.8735743, 0.8728056] 16.048496\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.8735743, 0.8728056] 13.865807\n",
            "New model accuracy: 0.772\n",
            "Training layer 7. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  4.3284452897338374e-05\n",
            "[1.9510612, 1.9341295]\n",
            "[0.725851, 0.70643026]\n",
            "[0.57552034, 0.554743]\n",
            "[0.5294527, 0.5077782]\n",
            "[0.53079754, 0.50842226]\n",
            "[0.4768334, 0.4538861]\n",
            "[0.47460294, 0.45160273] 2.3305912\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.47460294, 0.45160273] 2.3303888\n",
            "New model accuracy: 0.7742\n",
            "Training layer 6. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  1.3978426392555618e-05\n",
            "[1.7499673, 1.7390307]\n",
            "[0.47198603, 0.45999613]\n",
            "[0.44832915, 0.43605894]\n",
            "[0.45100343, 0.43858555]\n",
            "[0.44133785, 0.42880455]\n",
            "[0.43050116, 0.41787267]\n",
            "[0.40765744, 0.3950188] 9.534423\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.40765744, 0.3950188] 9.108634\n",
            "New model accuracy: 0.7746\n",
            "Training layer 5. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  6.543195664573761e-06\n",
            "[1.9197454, 1.8948972]\n",
            "[0.6081159, 0.58207566]\n",
            "[0.5180517, 0.4918021]\n",
            "[0.47560543, 0.44919053]\n",
            "[0.45082015, 0.42423463]\n",
            "[0.41627598, 0.389524]\n",
            "[0.43444523, 0.4076763] 10.823075\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.43444523, 0.4076763] 10.185544\n",
            "New model accuracy: 0.7625\n",
            "Training layer 4. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  3.448374929110365e-06\n",
            "[1.3710792, 1.3514407]\n",
            "[0.67555887, 0.6553117]\n",
            "[0.5707493, 0.5503536]\n",
            "[0.51269376, 0.49217084]\n",
            "[0.49616265, 0.47551036]\n",
            "[0.4839602, 0.4631766]\n",
            "[0.44491255, 0.4241161] 34.91526\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.44491255, 0.4241161] 33.30709\n",
            "New model accuracy: 0.734\n",
            "Training layer 3. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  1e-05\n",
            "Regu coeff:  3.448374929110365e-07\n",
            "[0.44846794, 0.4421623]\n",
            "[0.41652617, 0.4102218]\n",
            "[0.43525913, 0.42895475]\n",
            "[0.43824813, 0.4319435]\n",
            "[0.40838003, 0.402075]\n",
            "[0.39261776, 0.3863122]\n",
            "[0.3902695, 0.38396385] 9.035443\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.3902695, 0.38396385] 9.971636\n",
            "New model accuracy: 0.7327\n",
            "Training layer 2. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  8.129485526533075e-05\n",
            "[1.0215058, 0.38289523]\n",
            "[0.9389915, 0.37288302]\n",
            "[0.91185987, 0.3736896]\n",
            "[0.92488223, 0.40534055]\n",
            "[0.8452678, 0.3401748]\n",
            "[0.86607695, 0.37282243]\n",
            "[0.8567679, 0.36462265] 14.16286\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.8567679, 0.36462265] 13.198684\n",
            "New model accuracy: 0.7327\n",
            "Training layer 1. {[Total loss, MSE loss], eigenvalue}:\n",
            "learning rate(lr_coeff/eig_local):  0.0001\n",
            "Regu coeff:  2.0492737517163012e-05\n",
            "[0.39439422, 0.35370246]\n",
            "[0.40824443, 0.3681991]\n",
            "[0.37669533, 0.3367317]\n",
            "[0.3983381, 0.35841987]\n",
            "[0.4276703, 0.38777688]\n",
            "[0.3938165, 0.3539324]\n",
            "[0.35777658, 0.31789488] 47.489212\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/temp_save.ckpt\n",
            "Selected model performance:  [0.35777658, 0.31789488] 47.48255\n",
            "New model accuracy: 0.7324\n",
            "47.49177\n",
            "13.550325\n",
            "11.562329\n",
            "44.6242\n",
            "70.6239\n",
            "92.05267\n",
            "60.59449\n",
            "500.44116\n",
            "New model with trained L8 saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/Alex_s10_labmix.ckpt\n",
            "New model accuracy: 0.7324\n",
            "Original model accuracy: 0.745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTAaz_x9hc37",
        "colab_type": "text"
      },
      "source": [
        "#### Prune modified model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BY4BI-PqhmEq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "4785ad41-9a85-43f7-c9f0-d58d8c6cccf2"
      },
      "source": [
        "# model_path = \"drive/My Drive/Colab Notebooks/\"+\"AlexNet_new_8.ckpt\"\n",
        "# model_path = file_path+\"ensemble_exp/Alex_seed10.ckpt\"\n",
        "model_path = file_path+\"ensemble_exp/Alex_s10_labmix.ckpt\"\n",
        "# save_name = \"ensemble_exp/Alexpruned_s10_90.ckpt\"\n",
        "save_name = \"ensemble_exp/AlexP_s10_95.ckpt\"\n",
        "ensemble_seed = 10\n",
        "\n",
        "# Set hyperparameters for retraining\n",
        "learning_rate = 5e-3    \n",
        "momentum = 0.9\n",
        "n_epochs = 100 \n",
        "\n",
        "AllSaver = tf.train.Saver()\n",
        "\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "reset_global_step_op = tf.assign(global_step, 0)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=alex_new, labels=y))\n",
        "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, \n",
        "                                       momentum=momentum).minimize(cost,global_step=global_step)\n",
        "\n",
        "# Set gradual pruning parameters\n",
        "pruning_hparams = pruning.get_pruning_hparams()\n",
        "pruning_hparams.begin_pruning_step = 0\n",
        "pruning_hparams.end_pruning_step = 100\n",
        "pruning_hparams.pruning_frequency = 1\n",
        "pruning_hparams.sparsity_function_end_step = 100\n",
        "pruning_hparams.target_sparsity = .95\n",
        "print(\"Pruning Hyperparameters:\", pruning_hparams)\n",
        "\n",
        "# Create a pruning object using the pruning specification, \n",
        "# targe_sparsity seems to have priority over the hparam\n",
        "p = pruning.Pruning(pruning_hparams, global_step=global_step)\n",
        "prune_op = p.conditional_mask_update_op()\n",
        "\n",
        "# Define reduced dataset, use same code used to obtain data for training mod. model \n",
        "dataset_size = int(50000/fraction)\n",
        "random.seed(1)\n",
        "data_idx = [i for i in range(50000)]\n",
        "idx = random.sample(data_idx, dataset_size)\n",
        "# To select exclusive subset of values for each seed, starting from seed 1\n",
        "if ensemble_seed >1:                        \n",
        "    for i in range(ensemble_seed-1):\n",
        "        for j in range(len(idx)):\n",
        "            data_idx.remove(idx[j])\n",
        "        idx = random.sample(data_idx,dataset_size)\n",
        "x_train_ = []\n",
        "y_train_ = []\n",
        "for i in idx:\n",
        "    x_train_.append(x_train[i])\n",
        "    y_train_.append(y_train[i])\n",
        "x_train_ = np.array(x_train_)\n",
        "y_train_ = np.array(y_train_)\n",
        "datagen.fit(x_train_)\n",
        "gen = datagen.flow(x_train_,y_train_,batch_size=batch_size)   \n",
        "\n",
        "with tf.Session() as sess:\n",
        "#     X = tf.placeholder(shape=[None, 70, 70, 3], dtype=tf.float32, name='X')\n",
        "#     alex = AlexNet(X)\n",
        "    init = tf.global_variables_initializer() # needs to be defined after model is generated\n",
        "    sess.run(init)\n",
        "    # Restore original trained weights\n",
        "    newSaver.restore(sess, model_path)\n",
        "        \n",
        "    correct_pred = tf.equal(tf.argmax(alex_new, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print(\"Accuracy of regularized model: \",sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    \n",
        "    sess.run(reset_global_step_op)\n",
        "    print(\"Sparsity before pruning\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
        "    print(\"Starting with retraining\")\n",
        "    \n",
        "    gen = datagen.flow(x_train,y_train,batch_size=batch_size)\n",
        "    for epoch in range(n_epochs):\n",
        "        batches = 0\n",
        "        for ip, op in gen:\n",
        "            batch_x, batch_y = transform_to_input_output(zip(ip,op), dim=n_out)\n",
        "            sess.run(prune_op)\n",
        "            sess.run([optimizer], feed_dict={X: batch_x, y: batch_y})\n",
        "            \n",
        "            batches+=1\n",
        "            if batches >= len(x_train)/batch_size/fraction:\n",
        "                break\n",
        "        if epoch%10 == 0:\n",
        "                print(sess.run([cost],{X:batch_x, y:batch_y}))\n",
        "                print(\"Weight sparsities:\", sess.run(tf.contrib.model_pruning.get_weight_sparsity()))\n",
        "\n",
        "    #Save trained model\n",
        "    save_path = AllSaver.save(sess, file_path+save_name)\n",
        "    print(\"Model saved in path: %s\" % save_path)\n",
        "\n",
        "    print(\"Accuracy after retraining\",sess.run(accuracy, feed_dict={X: x_test, y: y_test}))\n",
        "    \n",
        "\"\"\"\n",
        "sparsity: 0.7 pruning_period: 3 epochs: 50 accuracy: 71.8\n",
        "sparsity: 0.7 pruning_period: 10 epochs: 110 accuracy: 74.03  freq:1 default\n",
        "sparsity: 0.8 pruning_period: 10 epochs: 110 accuracy: 70.25 \n",
        "sparsity: 0.8 pruning_period: 99 epochs: 100 accuracy: 71.03\n",
        "sparsity: 0.8 pruning_period: 60 epochs: 100 accuracy: 71.44  freq: 2\n",
        "sparsity: 0.8 pruning_period: 60 epochs: 150 accuracy: 72.69\n",
        "sparsity: 0.85 pruning_period: 100 epochs: 130 accuracy: 69.91\n",
        "sparsity: 0.85 pruning_period: 100 epochs: 130 accuracy: 69.99 with alex_new_6\n",
        "--------------------------------\n",
        "New model with different loss reduction, acc: 76.28   with alex_new_8\n",
        "sparsity: 0.8 pruning_period: 100 epochs: 50 accuracy: 75.72\n",
        "sparsity: 0.9 pruning_period: 100 epochs: 50 accuracy: 74.08  freq:2\n",
        "sparsity: 0.95 pruning_period: 100 epochs: 50 accuracy: 63.41  freq:2\n",
        "--------------------------------\n",
        "New model with total loss uesd for training, acc: 76.93, AlexNet_noLRN_same3.ckpt \n",
        "sparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 68.47  freq:2\n",
        "sparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 67.75  freq:1\n",
        "--------------------------------\n",
        "New model with total loss uesd for training, acc: 76.93, AlexNet_noLRN_same3.ckpt \n",
        "sparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 68.37  freq:1\n",
        "\n",
        "\"\"\"  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruning Hyperparameters: name=model_pruning,begin_pruning_step=0,end_pruning_step=100,weight_sparsity_map=[''],block_dims_map=[''],threshold_decay=0.0,pruning_frequency=1,nbins=256,block_height=1,block_width=1,block_pooling_function=AVG,initial_sparsity=0.0,target_sparsity=0.95,sparsity_function_begin_step=0,sparsity_function_end_step=100,sparsity_function_exponent=3.0,use_tpu=False\n",
            "INFO:tensorflow:Updating masks.\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/Alex_s10_labmix.ckpt\n",
            "Accuracy of regularized model:  0.729\n",
            "Sparsity before pruning [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Starting with retraining\n",
            "[5.7592244]\n",
            "Weight sparsities: [0.082960285, 0.082962245, 0.082960345, 0.0829611, 0.082960345, 0.082962036, 0.08294678, 0.0828125, 0.082960285, 0.082962245, 0.082960345, 0.0829611, 0.082960345, 0.082962036, 0.08294678, 0.0828125]\n",
            "[1.3689908]\n",
            "Weight sparsities: [0.774076, 0.7740658, 0.77406704, 0.774066, 0.774066, 0.7740631, 0.77407837, 0.77421874, 0.774076, 0.7740658, 0.77406704, 0.774066, 0.774066, 0.7740631, 0.77407837, 0.77421874]\n",
            "[1.7182679]\n",
            "Weight sparsities: [0.945334, 0.94533205, 0.9453317, 0.9453321, 0.9453328, 0.94532776, 0.945343, 0.9453125, 0.945334, 0.94533205, 0.9453328, 0.9453321, 0.9453328, 0.94532776, 0.945343, 0.9453125]\n",
            "[1.5426152]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.4678293]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.3893]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.3878875]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.3316562]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.3574706]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "[1.2424933]\n",
            "Weight sparsities: [0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95, 0.9500115, 0.95000005, 0.9499998, 0.9499994, 0.9500009, 0.94999695, 0.9500122, 0.95]\n",
            "Model saved in path: drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexP_s10_95.ckpt\n",
            "Accuracy after retraining 0.5633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsparsity: 0.7 pruning_period: 3 epochs: 50 accuracy: 71.8\\nsparsity: 0.7 pruning_period: 10 epochs: 110 accuracy: 74.03  freq:1 default\\nsparsity: 0.8 pruning_period: 10 epochs: 110 accuracy: 70.25 \\nsparsity: 0.8 pruning_period: 99 epochs: 100 accuracy: 71.03\\nsparsity: 0.8 pruning_period: 60 epochs: 100 accuracy: 71.44  freq: 2\\nsparsity: 0.8 pruning_period: 60 epochs: 150 accuracy: 72.69\\nsparsity: 0.85 pruning_period: 100 epochs: 130 accuracy: 69.91\\nsparsity: 0.85 pruning_period: 100 epochs: 130 accuracy: 69.99 with alex_new_6\\n--------------------------------\\nNew model with different loss reduction, acc: 76.28   with alex_new_8\\nsparsity: 0.8 pruning_period: 100 epochs: 50 accuracy: 75.72\\nsparsity: 0.9 pruning_period: 100 epochs: 50 accuracy: 74.08  freq:2\\nsparsity: 0.95 pruning_period: 100 epochs: 50 accuracy: 63.41  freq:2\\n--------------------------------\\nNew model with total loss uesd for training, acc: 76.93, AlexNet_noLRN_same3.ckpt \\nsparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 68.47  freq:2\\nsparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 67.75  freq:1\\n--------------------------------\\nNew model with total loss uesd for training, acc: 76.93, AlexNet_noLRN_same3.ckpt \\nsparsity: 0.9 pruning_period: 100 epochs: 100 accuracy: 68.37  freq:1\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OrzoLdqnfs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # print all tensors in checkpoint file\n",
        "# from tensorflow.python.tools import inspect_checkpoint as chkp\n",
        "# chkp.print_tensors_in_checkpoint_file(file_path+save_name, tensor_name='', all_tensors=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhqfKMMj3P0E",
        "colab_type": "text"
      },
      "source": [
        "#### Quantize pruned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5LJ54rA3eSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "00009e5e-3c7d-44aa-8a11-db83634175e6"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "# newSaver = tf.train.Saver({\"W1\":W1,\"B1\":B1,\"W2\":W2,\"B2\":B2,\"W3\":W3,\"B3\":B3,\"W4\":W4,\"B4\":B4,\"W5\":W5,\"B5\":B5,\n",
        "#                            \"W1_\":W1_,\"B1_\":B1_,\"W2_\":W2_,\"B2_\":B2_,\"W3_\":W3_,\"B3_\":B3_,\"W4_\":W4_,\"B4_\":B4_,\"W5_\":W5_,\"B5_\":B5_})\n",
        "model_name = \"ensemble_exp/AlexNet_pruned_s7_90.ckpt\"\n",
        "# model_name = \"AlexNet_noLRN_same4.ckpt\"\n",
        "# saver = tf.train.Saver()\n",
        "saver = newSaver\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    sess.run(init)\n",
        "    # Restore original trained weights\n",
        "    saver.restore(sess, file_path+model_name)\n",
        "\n",
        "    # Print max and min weight values\n",
        "    maxW = sess.run(tf.math.reduce_max(w1))\n",
        "    minW = sess.run(tf.math.reduce_min(w1))\n",
        "    meanW = sess.run(tf.math.reduce_mean(w1))\n",
        "    print(\"{min,max,mean}: {\",minW,maxW,meanW,\"}\")\n",
        "    \n",
        "    # Evaluate performance\n",
        "    correct_pred = tf.equal(tf.argmax(alex_new, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print('Test accuracy before quant: ',sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    \n",
        "#     check = sess.run(tf.equal(parameters[:img_size,:h1],W1))\n",
        "#     print(check)\n",
        "    \n",
        "    multiplier = 1024  #16 for 4 bits, 32 for 8 bits\n",
        "    clip_min = -0.5\n",
        "    clip_max = 0.5\n",
        "    \n",
        "    weights = [w1,w2,w3,w4,w5,w6,w7,w8]\n",
        "    biases = [b1,b2,b3,b4,b5,b6,b7,b8]\n",
        "    quant_ops = []\n",
        "    for i in range(8):\n",
        "        quant_ops.append(weights[i].assign(tf.math.round(tf.clip_by_value(weights[i],clip_min,clip_max)*multiplier)/multiplier))\n",
        "        quant_ops.append(biases[i].assign(tf.math.round(tf.clip_by_value(biases[i],clip_min,clip_max)*multiplier)/multiplier))\n",
        "\n",
        "    for i in range(16):\n",
        "        sess.run(quant_ops[i])\n",
        "        \n",
        "    # quant_op1 = w1.assign(tf.math.round(tf.clip_by_value(w1,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op2 = w2.assign(tf.math.round(tf.clip_by_value(w2,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op3 = w3.assign(tf.math.round(tf.clip_by_value(w3,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op4 = w4.assign(tf.math.round(tf.clip_by_value(w4,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op5 = w5.assign(tf.math.round(tf.clip_by_value(w5,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op6 = w6.assign(tf.math.round(tf.clip_by_value(w6,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op7 = w7.assign(tf.math.round(tf.clip_by_value(w7,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op8 = w8.assign(tf.math.round(tf.clip_by_value(w8,clip_min,clip_max)*multiplier)/multiplier)\n",
        "\n",
        "    # quant_op9 = b1.assign(tf.math.round(tf.clip_by_value(b1,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op10 = b2.assign(tf.math.round(tf.clip_by_value(b2,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op11 = b3.assign(tf.math.round(tf.clip_by_value(b3,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op12 = b4.assign(tf.math.round(tf.clip_by_value(b4,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op13 = b5.assign(tf.math.round(tf.clip_by_value(b5,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op14 = b6.assign(tf.math.round(tf.clip_by_value(b6,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op15 = b7.assign(tf.math.round(tf.clip_by_value(b7,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    # quant_op16 = b8.assign(tf.math.round(tf.clip_by_value(b8,clip_min,clip_max)*multiplier)/multiplier)\n",
        "    \n",
        "    # sess.run(quant_op1)\n",
        "    # sess.run(quant_op2)\n",
        "    # sess.run(quant_op3)\n",
        "    # sess.run(quant_op4)\n",
        "    # sess.run(quant_op5)\n",
        "    # sess.run(quant_op6)\n",
        "    # sess.run(quant_op7)\n",
        "    # sess.run(quant_op8)\n",
        "    # sess.run(quant_op9)\n",
        "    # sess.run(quant_op10)\n",
        "    # sess.run(quant_op11)\n",
        "    # sess.run(quant_op12)\n",
        "    # sess.run(quant_op13)\n",
        "    # sess.run(quant_op14)\n",
        "    # sess.run(quant_op15)\n",
        "    # sess.run(quant_op16)\n",
        "    \n",
        "    # Evaluate performance\n",
        "    correct_pred = tf.equal(tf.argmax(alex_new, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "    print('Test accuracy after quant: ',sess.run(accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "\"\"\"\n",
        "For L1->Ln training:\n",
        "Test accuracy before quant:  0.6817\n",
        "Test accuracy after quant:  0.6668\n",
        "For Ln->L1 training:\n",
        "Test accuracy before quant:  0.6837\n",
        "Test accuracy after quant:  0.6662\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_pruned_s7_90.ckpt\n",
            "{min,max,mean}: { -0.5025205 0.47492906 -0.0019019101 }\n",
            "Test accuracy before quant:  0.674\n",
            "Test accuracy after quant:  0.6724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFor L1->Ln training:\\nTest accuracy before quant:  0.6817\\nTest accuracy after quant:  0.6668\\nFor Ln->L1 training:\\nTest accuracy before quant:  0.6837\\nTest accuracy after quant:  0.6662\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC_HSzi5gHap",
        "colab_type": "text"
      },
      "source": [
        "#### Ensemble Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMYX9qKGgMMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "71c0d978-8000-4915-e6ba-26436b4e98ef"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# all model names in list\n",
        "# model_names = [(\"ensemble_exp/AlexNet_pruned_s\"+str(i+1)+\"_90.ckpt\") for i in range(10)]\n",
        "# model_names = [(\"ensemble_exp/AlexP_s\"+str(i+1)+\"_95.ckpt\") for i in range(10)]\n",
        "model_names = [(\"ensemble_exp/AlexNet_noLRN6_pruned90_s\"+str(i+1)+\".ckpt\") for i\n",
        "               in range(5)]\n",
        "\n",
        "# One hot encoding of model predictions to implement majority vote\n",
        "def one_hot_trans(arr,n_classes=10):\n",
        "        encoded = [[0 for i in range(n_classes)] for j in range(arr.shape[0])]\n",
        "        for i in range(arr.shape[0]):\n",
        "            encoded[i][arr[i]] = 1\n",
        "        return encoded\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "# saver = newSaver\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    sess.run(init)\n",
        "    \n",
        "    # # Gather weights for quantization\n",
        "    # weights = [w1,w2,w3,w4,w5,w6,w7,w8]\n",
        "    # biases = [b1,b2,b3,b4,b5,b6,b7,b8]\n",
        "\n",
        "    # # Define quantization ops\n",
        "    # precision = 32\n",
        "    # clip_min = -0.5\n",
        "    # clip_max = 0.5\n",
        "    # multiplier = (2**precision)/(clip_max-clip_min)\n",
        "    # quant_ops = []\n",
        "    # for i in range(8):\n",
        "    #     quant_ops.append(weights[i].assign(tf.math.round(tf.clip_by_value(weights[i],clip_min,clip_max)*multiplier)/multiplier))\n",
        "    #     quant_ops.append(biases[i].assign(tf.math.round(tf.clip_by_value(biases[i],clip_min,clip_max)*multiplier)/multiplier))\n",
        "    \n",
        "    # Define prediction op\n",
        "    # model_pred = alex_new\n",
        "    model_pred = alex\n",
        "\n",
        "    # Load models and predict\n",
        "    pred = []\n",
        "    for i in range(len(model_names)):\n",
        "        saver.restore(sess, file_path+model_names[i])\n",
        "        indiv_pred = tf.equal(tf.argmax(model_pred, 1), tf.argmax(y, 1))\n",
        "        indiv_accuracy = tf.reduce_mean(tf.cast(indiv_pred, tf.float32))\n",
        "        print('Model accuracy before quant: ',sess.run(indiv_accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "        # Run quantization ops\n",
        "        # for i in range(16):\n",
        "        #     sess.run(quant_ops[i])\n",
        "        pred.append(sess.run(model_pred, feed_dict={X: x_test, y:y_test}))\n",
        "\n",
        "\n",
        "    # Consensus variable using sum of soft predictions\n",
        "    cons = pred[0]      \n",
        "    for k in range(len(pred)-1):\n",
        "        for i in range(len(pred[k+1])):\n",
        "           for j in range(len(pred[k][i])):\n",
        "               cons[i][j] = cons[i][j] + pred[k+1][i][j]\n",
        "\n",
        "    # # Consensus variable using majority vote\n",
        "    # cons = one_hot_trans(np.argmax(pred[0],axis=1))\n",
        "    # for k in range(len(pred)-1):\n",
        "    #     model_pred = one_hot_trans(np.argmax(pred[k+1],axis=1))\n",
        "    #     for i in range(len(pred[k+1])):\n",
        "    #        for j in range(len(pred[k][i])):\n",
        "    #            cons[i][j] = cons[i][j] + model_pred[i][j]\n",
        "\n",
        "    # Evaluate performance\n",
        "    cons_pred = tf.equal(tf.argmax(cons, 1), tf.argmax(y, 1))           # Consensus prediction\n",
        "    # indiv_pred = tf.equal(tf.argmax(pred[-1], 1), tf.argmax(y, 1))\n",
        "\n",
        "    cons_accuracy = tf.reduce_mean(tf.cast(cons_pred, tf.float32))      # Consensus accuracy\n",
        "    # indiv_accuracy = tf.reduce_mean(tf.cast(indiv_pred, tf.float32))\n",
        "    \n",
        "    print('Individual model accuracy after quant: ',sess.run(indiv_accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    print('Consensus model accuracy after quant: ',sess.run(cons_accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "    \n",
        "\"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned90_s1.ckpt\n",
            "Model accuracy before quant:  0.5447\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned90_s2.ckpt\n",
            "Model accuracy before quant:  0.5333\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned90_s3.ckpt\n",
            "Model accuracy before quant:  0.5385\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned90_s4.ckpt\n",
            "Model accuracy before quant:  0.5348\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned90_s5.ckpt\n",
            "Model accuracy before quant:  0.5386\n",
            "Individual model accuracy after quant:  0.5366\n",
            "Consensus model accuracy after quant:  0.6766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL1wH0mOGuUe",
        "colab_type": "text"
      },
      "source": [
        "#### Ensemble with diff architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9gpcm3zjrNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d5d81f9-75ad-4a78-fb8a-e491bd87555e"
      },
      "source": [
        "# reset_graph()\n",
        "# model_names = [(\"ensemble_exp/AlexNet_noLRN\"+str(i+3)+\"_pruned95.ckpt\") for i\n",
        "#                in range(5)]\n",
        "# meta_names = [(\"ensemble_exp/AlexNet_noLRN\"+str(i+3)+\"_pruned95.ckpt.meta\") for i\n",
        "#                in range(5)]   \n",
        "# new_saver = tf.train.import_meta_graph(file_path+meta_names[0]) \n",
        "\n",
        "# with tf.Session() as sess:\n",
        "\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     new_saver.restore(sess, file_path+model_names[0])              \n",
        "# # tf.global_variables()\n",
        "# for op in tf.get_default_graph().get_operations():\n",
        "#     print(str(op.name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9axCPIfZra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o7uqihNZXQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "93cb9095-0cfa-4c0e-9110-f9477bfe350f"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# all model names in list\n",
        "n_models = 6\n",
        "file_path = 'drive/My Drive/Colab Notebooks Old/'        \n",
        "# Pruned models\n",
        "model_names = [(\"ensemble_exp/AlexNet_noLRN\"+str(i+3)+\"_pruned97.ckpt\") for i\n",
        "               in range(n_models) if i != 2]\n",
        "meta_names = [(\"ensemble_exp/AlexNet_noLRN\"+str(i+3)+\"_pruned97.ckpt.meta\") for i\n",
        "               in range(n_models) if i != 2] \n",
        "# # Original models\n",
        "# model_names = [(\"AlexNet_Cifar_trained100_noLRN_\"+str(i+3)+\".ckpt\") for i\n",
        "#                in range(n_models) if i != 2]\n",
        "# meta_names = [(\"AlexNet_Cifar_trained100_noLRN_\"+str(i+3)+\".ckpt.meta\") for i\n",
        "#                in range(n_models) if i != 2] \n",
        "\n",
        "# One hot encoding of model predictions to implement majority vote\n",
        "def one_hot_trans(arr,n_classes=10):\n",
        "        encoded = [[0 for i in range(n_classes)] for j in range(arr.shape[0])]\n",
        "        for i in range(arr.shape[0]):\n",
        "            encoded[i][arr[i]] = 1\n",
        "        return encoded\n",
        "\n",
        "pred = []       # list of output of individual models\n",
        "for i in range(len(model_names)):\n",
        "    reset_graph()\n",
        "    with tf.Session() as sess:\n",
        "        # Load graph and weights           \n",
        "        new_saver = tf.train.import_meta_graph(file_path+meta_names[i])\n",
        "        new_saver.restore(sess, file_path+model_names[i])\n",
        "\n",
        "        # Get required ops->tensors->python variables\n",
        "        graph = tf.get_default_graph()\n",
        "        tensors = graph.get_operations()\n",
        "        req_tensors = [v for v in tensors if (str(v.name) == 'model_output' or \n",
        "                                             str(v.name) == 'Placeholder') or \n",
        "                                             str(v.name) == 'X'] \n",
        "        # print(req_tensors)\n",
        "        X = req_tensors[0].outputs[0]\n",
        "        Y = req_tensors[1].outputs[0]\n",
        "        model_pred = req_tensors[2].outputs[0]\n",
        "        # print(X,y,model_pred)\n",
        "        \n",
        "        # Make and save model predictions\n",
        "        # indiv_pred = tf.equal(tf.argmax(model_pred, 1), tf.argmax(y, 1))\n",
        "        # indiv_accuracy = tf.reduce_mean(tf.cast(indiv_pred, tf.float32))\n",
        "        # print('Model accuracy: ',sess.run(indiv_accuracy, feed_dict={X: x_test, y:y_test}))\n",
        "        # Run quantization ops\n",
        "        # for i in range(16):\n",
        "        #     sess.run(quant_ops[i])\n",
        "        pred.append(sess.run(model_pred, feed_dict={X: x_test, Y:y_test}))\n",
        "\n",
        "# Consensus variable using sum of soft predictions\n",
        "def soft_cons(pred):\n",
        "    cons = pred[0]      \n",
        "    for k in range(len(pred)-1):\n",
        "        for i in range(len(pred[k+1])):\n",
        "            for j in range(len(pred[k][i])):\n",
        "                cons[i][j] = cons[i][j] + pred[k+1][i][j]\n",
        "    return cons\n",
        "\n",
        "# Consensus variable using majority vote\n",
        "def vote_cons(pred):\n",
        "    cons = one_hot_trans(np.argmax(pred[0],axis=1))\n",
        "    for k in range(len(pred)-1):\n",
        "        model_pred = one_hot_trans(np.argmax(pred[k+1],axis=1))\n",
        "        for i in range(len(pred[k+1])):\n",
        "            for j in range(len(pred[k][i])):\n",
        "                cons[i][j] = cons[i][j] + model_pred[i][j]\n",
        "    return cons\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    for i in range(len(pred)):\n",
        "        indiv_pred = tf.equal(tf.argmax(pred[i], 1), tf.argmax(Y, 1))\n",
        "        indiv_accuracy = tf.reduce_mean(tf.cast(indiv_pred, tf.float32))\n",
        "        print('Model accuracy: ',sess.run(indiv_accuracy, feed_dict={Y:y_test}))\n",
        "\n",
        "    acc.append([])      # Store accuracies for plotting curves\n",
        "    print('Models   |Consensus A    |Consensus B')\n",
        "    for i in range(len(pred)):\n",
        "        cons_1 = soft_cons(pred[:i+1])\n",
        "        cons_2 = vote_cons(pred[:i+1])\n",
        "        cons_pred1 = tf.equal(tf.argmax(cons_1, 1), tf.argmax(Y, 1)) \n",
        "        cons_pred2 = tf.equal(tf.argmax(cons_2, 1), tf.argmax(Y, 1)) \n",
        "        cons_accuracy1 = tf.reduce_mean(tf.cast(cons_pred1, tf.float32))\n",
        "        cons_accuracy2 = tf.reduce_mean(tf.cast(cons_pred2, tf.float32))\n",
        "        a1 = sess.run(cons_accuracy1, feed_dict={Y:y_test})\n",
        "        a2 = sess.run(cons_accuracy2, feed_dict={Y:y_test})\n",
        "        print(str(i+1)+'        '+str(a1)+'         '+str(a2))\n",
        "        acc[-1].append(a1)\n",
        "\n",
        "    conf_matr = tf.confusion_matrix(tf.argmax(Y,1),tf.argmax(soft_cons(pred),1))\n",
        "    print('Confusion matrix: \\n',sess.run(conf_matr, feed_dict={Y:y_test}))\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN3_pruned97.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN4_pruned97.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN6_pruned97.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN7_pruned97.ckpt\n",
            "INFO:tensorflow:Restoring parameters from drive/My Drive/Colab Notebooks Old/ensemble_exp/AlexNet_noLRN8_pruned97.ckpt\n",
            "Model accuracy:  0.414\n",
            "Model accuracy:  0.3647\n",
            "Model accuracy:  0.3843\n",
            "Model accuracy:  0.3616\n",
            "Model accuracy:  0.3461\n",
            "Models   |Consensus A    |Consensus B\n",
            "1        0.414         0.414\n",
            "2        0.4514         0.4164\n",
            "3        0.4721         0.4527\n",
            "4        0.475         0.4548\n",
            "5        0.4809         0.4542\n",
            "Confusion matrix: \n",
            " [[578  25  33  14  17  15  15  27 190  86]\n",
            " [  8 622   2   5   0  16  30  18  22 277]\n",
            " [183  27 125  63 166 112 138 104  47  35]\n",
            " [ 36  57  56 168  80 197 187 110  42  67]\n",
            " [ 50   5  54  83 301  44 246 168  25  24]\n",
            " [ 29  38  29 117  51 401 111 137  30  57]\n",
            " [  5  22  30  49  54  37 703  24  13  63]\n",
            " [ 23  30  20  47  43  82  57 625  10  63]\n",
            " [143  68  20  19   6  35  14   7 616  72]\n",
            " [ 28 201   7   6   0  12  27  16  35 668]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AUAOvcIlbJB",
        "colab_type": "text"
      },
      "source": [
        "#### Plot ensemble results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXv_n5hrldpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "98b99ab1-99da-4aed-c632-208f5a719788"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "# print(acc)\n",
        "# acc = [[0.7459, 0.78, 0.7798, 0.7777, 0.7762], [0.6701, 0.7178, 0.7259, 0.7271, 0.7308], [0.5047, 0.5845, 0.6086, 0.6125, 0.6164], [0.414, 0.4514, 0.4721, 0.475, 0.4809]]\n",
        "\n",
        "prnt_sparsities = [0.90,0.95,0.97]\n",
        "labels = [('Pruning sparsity: '+str(i)) for i in prnt_sparsities]\n",
        "labels.insert(0,'Original models')\n",
        "print(labels)\n",
        "\n",
        "fig = plt.figure(1,figsize=(9,6))\n",
        "plt.plot([1,2,3,4,5],acc[0],'k',label=labels[0],marker=\"o\")\n",
        "plt.plot([1,2,3,4,5],acc[1],'r-',label=labels[1],marker=\"x\")\n",
        "plt.plot([1,2,3,4,5],acc[2],'g-',label=labels[2],marker=\"v\")\n",
        "plt.plot([1,2,3,4,5],acc[3],'b-',label=labels[3],marker=\"+\")\n",
        "plt.xticks([1,2,3,4,5])\n",
        "\n",
        "plt.xlabel('Number of models in consensus')\n",
        "plt.ylabel('Test set accuracy')\n",
        "plt.legend()\n",
        "# plt.title('Inference accuracy vs number of models in consensus')\n",
        "fig.savefig('cifar_ensemble.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Original models', 'Pruning sparsity: 0.9', 'Pruning sparsity: 0.95', 'Pruning sparsity: 0.97']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejqZ-DTg6tI_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEEEevgr6y1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "35ebca0d-19a3-4618-fc70-9fa85e71cee7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "orig_compr = [0.25*0.25,0.25*7/32,0.25*6/32,0.25*5/32,0.2*6/32,0.15*0.25,0.15*7/32,0.15*6/32,0.1*8/32]\n",
        "orig_acc   = [71.51,71.68,71.4,70.98,69.41,66.2,66.56,65.87,61.31]\n",
        "\n",
        "mod_compr = [0.25*0.25,0.25*7/32,0.25*5/32,0.2*6/32,0.2*5/32,0.15*5/32,0.1*7/32,0.1*5/32,0.1*4/32]\n",
        "mod_acc   = [75.08,74.97,74.24,72.97,72.42,71.25,68.29,67.17,60.23]\n",
        "\n",
        "fig = plt.figure(1,figsize=(9,6))\n",
        "plt.plot(orig_compr, orig_acc, label='Simplified Deep Compression',marker='o')\n",
        "plt.plot(mod_compr, mod_acc, label='L1BP+HAT',marker='x')\n",
        "\n",
        "# plt.plot([0.7,0.75,0.8,0.85,0.9,0.95,0.96],[0.735,0.7296,0.7184,0.6972,0.6369,0.4878,0.4205], label='Original model',marker='o')\n",
        "# plt.plot([0.7,0.75,0.8,0.85,0.9,0.95,0.96],[0.735,0.734,0.7269,0.6999,0.64,0.5001,0.4502], label='Regularized model',marker='x')\n",
        "plt.xlabel('Model size ratio')\n",
        "plt.ylabel('Test set accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy vs model compression using proposed scheme and simplified Deep Compression')\n",
        "fig.savefig('overall_comparison.pdf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}